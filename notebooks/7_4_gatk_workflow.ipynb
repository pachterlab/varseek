{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow followed according to: https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels\n",
    "\n",
    "Github workflow for GATK4 here: https://github.com/gatk-workflows/gatk4-rnaseq-germline-snps-indels/blob/master/gatk4-rna-best-practices.wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from varseek.utils import convert_chromosome_value_to_int_when_possible, calculate_metrics, draw_confusion_matrix, create_venn_diagram, calculate_sensitivity_specificity, create_stratified_metric_bar_plot, add_vcf_info_to_cosmic_tsv\n",
    "from varseek.constants import complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_fastq(output_path, num_sequences=5000, seq_length=150, quality_score=\"I\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        bases = ['A', 'C', 'G', 'T']\n",
    "        with open(output_path, \"w\") as fastq_file:\n",
    "            for i in range(num_sequences):\n",
    "                # Generate a random sequence of the specified length\n",
    "                sequence = ''.join(random.choices(bases, k=seq_length))\n",
    "                \n",
    "                # Create a quality string of the same length, filled with the specified quality score\n",
    "                quality = quality_score * seq_length\n",
    "                \n",
    "                # Write the FASTQ entry\n",
    "                fastq_file.write(f\"@seq_{i + 1}\\n\")\n",
    "                fastq_file.write(f\"{sequence}\\n\")\n",
    "                fastq_file.write(\"+\\n\")\n",
    "                fastq_file.write(f\"{quality}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_read_fastq = \"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_200mcrs_k59_nov16/synthetic_reads.fq\"  #!!! update path\n",
    "unique_mcrs_df_path = \"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_200mcrs_k59_nov16/unique_mcrs_df.csv\"  #!!! update path\n",
    "gatk_parent = \"/home/jrich/data/varseek_data/gatk_nov16\"  #!!! update for each run\n",
    "# generate_random_fastq(synthetic_read_fastq)\n",
    "\n",
    "threads = 32\n",
    "read_length = 150\n",
    "mutation_source = \"cdna\"  # \"cdna\", \"cds\"\n",
    "\n",
    "cosmic_tsv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37.tsv\"\n",
    "cosmic_cdna_info_csv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37_mutation_workflow_with_cdna.csv\"\n",
    "\n",
    "# if these paths don't exist then they will be created\n",
    "reference_genome_fasta = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa\"\n",
    "reference_genome_gtf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf\"\n",
    "genomes1000_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\"\n",
    "ensembl_germline_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens.vcf\"\n",
    "star_genome_dir = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/star_reference\"\n",
    "\n",
    "STAR = \"/home/jrich/opt/STAR-2.7.11b/source/STAR\"\n",
    "java = \"/home/jrich/opt/java/jdk-17.0.12+7/bin/java\"\n",
    "picard_jar = \"/home/jrich/opt/picard/build/libs/picard.jar\"\n",
    "gatk = \"/home/jrich/opt/gatk-4.6.0.0/gatk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(star_genome_dir, exist_ok=True)\n",
    "\n",
    "alignment_folder = f\"{gatk_parent}/alignment\"\n",
    "os.makedirs(alignment_folder, exist_ok=True)\n",
    "\n",
    "gatk_supporting_files = f\"{gatk_parent}/supporting_files\"\n",
    "os.makedirs(gatk_supporting_files, exist_ok=True)\n",
    "\n",
    "ensembl_germline_vcf_filtered = ensembl_germline_vcf.replace(\".vcf\", \"_filtered.vcf\")\n",
    "\n",
    "out_file_name_prefix = f\"{alignment_folder}/sample_\"\n",
    "\n",
    "vcf_folder = f\"{gatk_parent}/vcfs\"\n",
    "haplotypecaller_folder = f\"{vcf_folder}/haplotypecaller\"\n",
    "mutect2_folder = f\"{vcf_folder}/mutect2\"\n",
    "\n",
    "os.makedirs(vcf_folder, exist_ok=True)\n",
    "os.makedirs(haplotypecaller_folder, exist_ok=True)\n",
    "os.makedirs(mutect2_folder, exist_ok=True)\n",
    "\n",
    "aligned_and_unmapped_bam = f\"{out_file_name_prefix}Aligned.sortedByCoord.out.bam\"\n",
    "aligned_only_bam = f\"{alignment_folder}/aligned_only.bam\"\n",
    "unmapped_bam = f\"{alignment_folder}/unmapped.bam\"\n",
    "merged_bam = f\"{alignment_folder}/merged.bam\"\n",
    "\n",
    "marked_duplicates_bam = f\"{alignment_folder}/marked_duplicates.bam\"\n",
    "marked_dup_metrics_txt = f\"{alignment_folder}/marked_dup_metrics.txt\"\n",
    "\n",
    "split_n_cigar_reads_bam = f\"{alignment_folder}/split_n_cigar_reads.bam\"\n",
    "recal_data_table = f\"{alignment_folder}/recal_data.table\"\n",
    "recalibrated_bam = f\"{alignment_folder}/recalibrated.bam\"\n",
    "covariates_plot = f\"{alignment_folder}/AnalyzeCovariates.pdf\"\n",
    "haplotypecaller_unfiltered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_unfiltered.g.vcf.gz\"\n",
    "\n",
    "haplotypecaller_filtered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered.vcf.gz\"\n",
    "haplotypecaller_filtered_applied_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered_applied.vcf.gz\"\n",
    "\n",
    "panel_of_normals_vcf = f\"{gatk_supporting_files}/1000g_pon.hg38.vcf.gz\"\n",
    "panel_of_normals_vcf_filtered = f\"{gatk_supporting_files}/1000g_pon.hg38_filtered.vcf.gz\"\n",
    "mutect2_unfiltered_vcf = f\"{mutect2_folder}/mutect2_output_unfiltered.g.vcf.gz\"\n",
    "mutect2_filtered_vcf = f\"{mutect2_folder}/mutect2_output_filtered.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(reference_genome_fasta):\n",
    "    !wget -O {reference_genome_fasta}.gz https://ftp.ensembl.org/pub/grch37/release-93/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz && gunzip {reference_genome_fasta}.gz\n",
    "\n",
    "if not os.path.exists(reference_genome_gtf):\n",
    "    !wget -O {reference_genome_gtf}.gz https://ftp.ensembl.org/pub/grch37/release-93/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz && gunzip {reference_genome_gtf}.gz\n",
    "\n",
    "if not os.path.exists(genomes1000_vcf):\n",
    "    !wget -O {genomes1000_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz && gunzip {genomes1000_vcf}.gz\n",
    "    \n",
    "if not os.path.exists(ensembl_germline_vcf):\n",
    "    !wget -O {ensembl_germline_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/homo_sapiens.vcf.gz && gunzip {ensembl_germline_vcf}.gz\n",
    "\n",
    "if not os.path.exists(ensembl_germline_vcf_filtered):\n",
    "    ensembl_germline_vcf_temp1 = ensembl_germline_vcf.replace(\".vcf\", \"_temp1.vcf\")\n",
    "    # ensembl_germline_vcf_temp2 = ensembl_germline_vcf.replace(\".vcf\", \"_temp2.vcf\")\n",
    "    !grep -vP '^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*[WH]|^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*[WH]' $ensembl_germline_vcf > $ensembl_germline_vcf_temp1\n",
    "    !grep -vP '^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t\\t|^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t\\t' $ensembl_germline_vcf_temp1 > $ensembl_germline_vcf_filtered\n",
    "    !rm $ensembl_germline_vcf_temp1\n",
    "\n",
    "# if not os.path.exists(panel_of_normals_vcf):\n",
    "#     !wget -P {gatk_supporting_files} https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz\n",
    "#     !wget -P {gatk_supporting_files} https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz.tbi\n",
    "\n",
    "# if not os.path.exists(panel_of_normals_vcf_filtered):\n",
    "#     decompressed_pon_vcf = panel_of_normals_vcf.replace(\".vcf.gz\", \".vcf\")\n",
    "#     !gunzip -c $panel_of_normals_vcf > $decompressed_pon_vcf\n",
    "    \n",
    "#     # Remove 'chr' prefix from data lines\n",
    "#     !sed -i 's/^chr//' $decompressed_pon_vcf\n",
    "\n",
    "#     # Remove 'chr' prefix from contig headers in the VCF\n",
    "#     !sed -i '/^##contig/s/ID=chr/ID=/' $decompressed_pon_vcf\n",
    "\n",
    "#     # gunzip again\n",
    "#     !bgzip -c $decompressed_pon_vcf > $panel_of_normals_vcf_filtered  # TODO: get bgzip installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mapping to the Reference with STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_length_minus_one = read_length - 1\n",
    "\n",
    "if not os.listdir(star_genome_dir):\n",
    "    !$STAR \\\n",
    "        --runThreadN $threads \\\n",
    "        --runMode genomeGenerate \\\n",
    "        --genomeDir $star_genome_dir \\\n",
    "        --genomeFastaFiles $reference_genome_fasta \\\n",
    "        --sjdbGTFfile $reference_genome_gtf \\\n",
    "        --sjdbOverhang $read_length_minus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/jrich/opt/STAR-2.7.11b/source/STAR --runThreadN 32 --genomeDir /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/star_reference --readFilesIn /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp3_k59/synthetic_reads.fq --sjdbOverhang 149 --outFileNamePrefix /home/jrich/data/varseek_data/gatk_nov15/alignment/sample_ --outSAMtype BAM SortedByCoordinate --outSAMunmapped Within --outSAMmapqUnique 60 --twopassMode Basic\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-22T09:22:47-0700 dator:/home/jrich/opt/STAR-2.7.11b/source\n",
      "Nov 14 15:13:03 ..... started STAR run\n",
      "Nov 14 15:13:03 ..... loading genome\n",
      "Nov 14 15:13:48 ..... started 1st pass mapping\n",
      "Nov 14 15:13:53 ..... finished 1st pass mapping\n",
      "Nov 14 15:13:54 ..... inserting junctions into the genome indices\n",
      "Nov 14 15:15:38 ..... started mapping\n",
      "Nov 14 15:15:44 ..... finished mapping\n",
      "Nov 14 15:15:47 ..... started sorting BAM\n",
      "Nov 14 15:15:48 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "#* --outSAMmapqUnique 60 - change from default of 255 to avoid colliding with some aligners' use of 255 as a special value\n",
    "\n",
    "!$STAR \\\n",
    "    --runThreadN $threads \\\n",
    "    --genomeDir $star_genome_dir \\\n",
    "    --readFilesIn $synthetic_read_fastq \\\n",
    "    --sjdbOverhang $read_length_minus_one \\\n",
    "    --outFileNamePrefix $out_file_name_prefix \\\n",
    "    --outSAMtype BAM SortedByCoordinate \\\n",
    "    --outSAMunmapped Within \\\n",
    "    --outSAMmapqUnique 60 \\\n",
    "    --twopassMode Basic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate unmapped reads into its own BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pysam.AlignmentFile(aligned_and_unmapped_bam, \"rb\") as bam_in: \n",
    "#     # unmapped_header = bam_in.header.to_dict()\n",
    "#     # if 'PG' in unmapped_header:\n",
    "#     #     del unmapped_header['PG']\n",
    "           \n",
    "#     with pysam.AlignmentFile(aligned_only_bam, \"wb\", template=bam_in) as bam_aligned_out, pysam.AlignmentFile(unmapped_bam, \"wb\", template=bam_in) as bam_unmapped_out:\n",
    "#         for read in bam_in:\n",
    "#             if read.is_unmapped:\n",
    "#                 bam_unmapped_out.write(read)  # Write unmapped read to the unmapped BAM file\n",
    "#             else:\n",
    "#                 bam_aligned_out.write(read)  # Write aligned read to the aligned BAM file\n",
    "\n",
    "# print(f\"Unmapped reads written to {unmapped_bam}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:15:51.858 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Thu Nov 14 15:15:51 PST 2024] FastqToSam --FASTQ /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp3_k59/synthetic_reads.fq --OUTPUT /home/jrich/data/varseek_data/gatk_nov15/alignment/unmapped.bam --READ_GROUP_NAME rg1 --SAMPLE_NAME sample1 --LIBRARY_NAME lib1 --PLATFORM_UNIT unit1 --PLATFORM ILLUMINA --SEQUENCING_CENTER center1 --USE_SEQUENTIAL_FASTQS false --SORT_ORDER queryname --MIN_Q 0 --MAX_Q 93 --STRIP_UNPAIRED_MATE_NUMBER false --ALLOW_AND_IGNORE_EMPTY_LINES false --ALLOW_EMPTY_FASTQ false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Thu Nov 14 15:15:52 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "WARNING\t2024-11-14 15:15:52\tFastqToSam\tMaking ambiguous determination about fastq's quality encoding; more than one format possible based on observed qualities.\n",
      "INFO\t2024-11-14 15:15:52\tFastqToSam\tAuto-detected quality format as: Illumina.\n",
      "INFO\t2024-11-14 15:15:52\tFastqToSam\tProcessed 116006 fastq reads\n",
      "[Thu Nov 14 15:15:52 PST 2024] picard.sam.FastqToSam done. Elapsed time: 0.02 minutes.\n",
      "Runtime.totalMemory()=2181038080\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar FastqToSam \\\n",
    "    -FASTQ $synthetic_read_fastq \\\n",
    "    -OUTPUT $unmapped_bam \\\n",
    "    -READ_GROUP_NAME rg1 \\\n",
    "    -SAMPLE_NAME sample1 \\\n",
    "    -LIBRARY_NAME lib1 \\\n",
    "    -PLATFORM_UNIT unit1 \\\n",
    "    -PLATFORM ILLUMINA \\\n",
    "    -SEQUENCING_CENTER center1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MergeBamAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:15:54.009 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Thu Nov 14 15:15:54 PST 2024] CreateSequenceDictionary --OUTPUT /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.dict --REFERENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Thu Nov 14 15:15:54 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "[Thu Nov 14 15:15:54 PST 2024] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=2181038080\n",
      "To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp\n",
      "Exception in thread \"main\" picard.PicardException: file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.dict already exists.  Delete this file and try again, or specify a different output file.\n",
      "\tat picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:227)\n",
      "\tat picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:281)\n",
      "\tat picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:105)\n",
      "\tat picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:115)\n"
     ]
    }
   ],
   "source": [
    "reference_genome_dict = reference_genome_fasta.replace(\".fa\", \".dict\")\n",
    "\n",
    "!$java -jar $picard_jar CreateSequenceDictionary \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -O $reference_genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:15:55.039 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Thu Nov 14 15:15:55 PST 2024] MergeBamAlignment --UNMAPPED_BAM /home/jrich/data/varseek_data/gatk_nov15/alignment/unmapped.bam --ALIGNED_BAM /home/jrich/data/varseek_data/gatk_nov15/alignment/sample_Aligned.sortedByCoord.out.bam --OUTPUT /home/jrich/data/varseek_data/gatk_nov15/alignment/merged.bam --SORT_ORDER coordinate --INCLUDE_SECONDARY_ALIGNMENTS false --VALIDATION_STRINGENCY SILENT --REFERENCE_SEQUENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --ADD_PG_TAG_TO_READS true --PAIRED_RUN true --CLIP_ADAPTERS true --IS_BISULFITE_SEQUENCE false --ALIGNED_READS_ONLY false --MAX_INSERTIONS_OR_DELETIONS 1 --ATTRIBUTES_TO_REVERSE OQ --ATTRIBUTES_TO_REVERSE U2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT E2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT SQ --READ1_TRIM 0 --READ2_TRIM 0 --ALIGNER_PROPER_PAIR_FLAGS false --PRIMARY_ALIGNMENT_STRATEGY BestMapq --CLIP_OVERLAPPING_READS true --HARD_CLIP_OVERLAPPING_READS false --ADD_MATE_CIGAR true --UNMAP_CONTAMINANT_READS false --MIN_UNCLIPPED_BASES 32 --MATCHING_DICTIONARY_TAGS M5 --MATCHING_DICTIONARY_TAGS LN --UNMAPPED_READ_STRATEGY DO_NOT_CHANGE --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Thu Nov 14 15:15:55 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-11-14 15:15:55\tSamAlignmentMerger\tProcessing SAM file(s): [/home/jrich/data/varseek_data/gatk_nov15/alignment/sample_Aligned.sortedByCoord.out.bam]\n",
      "WARNING\t2024-11-14 15:15:55\tSamAlignmentMerger\tException merging bam alignment - attempting to sort aligned reads and try again: Underlying iterator is not queryname sorted: vcrs_2607629_4rW 150b aligned to 1:1233460-1234010. > vcrs_2607629_0rM 150b aligned to 1:1233460-1234010.\n",
      "INFO\t2024-11-14 15:15:55\tSamAlignmentMerger\tFinished reading 118265 total records from alignment SAM/BAM.\n",
      "INFO\t2024-11-14 15:16:12\tAbstractAlignmentMerger\tWrote 118265 alignment records and 56419 unmapped reads.\n",
      "[Thu Nov 14 15:16:12 PST 2024] picard.sam.MergeBamAlignment done. Elapsed time: 0.29 minutes.\n",
      "Runtime.totalMemory()=3590324224\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MergeBamAlignment \\\n",
    "    --ALIGNED_BAM $aligned_and_unmapped_bam \\\n",
    "    --UNMAPPED_BAM $unmapped_bam \\\n",
    "    --OUTPUT $merged_bam \\\n",
    "    --REFERENCE_SEQUENCE $reference_genome_fasta \\\n",
    "    --SORT_ORDER coordinate \\\n",
    "    --INCLUDE_SECONDARY_ALIGNMENTS false \\\n",
    "    --VALIDATION_STRINGENCY SILENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MarkDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:16:13.370 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Thu Nov 14 15:16:13 PST 2024] MarkDuplicates --INPUT /home/jrich/data/varseek_data/gatk_nov15/alignment/merged.bam --OUTPUT /home/jrich/data/varseek_data/gatk_nov15/alignment/marked_duplicates.bam --METRICS_FILE /home/jrich/data/varseek_data/gatk_nov15/alignment/marked_dup_metrics.txt --VALIDATION_STRINGENCY SILENT --CREATE_INDEX true --MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP 50000 --MAX_FILE_HANDLES_FOR_READ_ENDS_MAP 8000 --SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --FLOW_MODE false --FLOW_DUP_STRATEGY FLOW_QUALITY_SUM_STRATEGY --USE_END_IN_UNPAIRED_READS false --USE_UNPAIRED_CLIPPED_END false --UNPAIRED_END_UNCERTAINTY 0 --UNPAIRED_START_UNCERTAINTY 0 --FLOW_SKIP_FIRST_N_FLOWS 0 --FLOW_Q_IS_KNOWN_END false --FLOW_EFFECTIVE_QUALITY_THRESHOLD 15 --ADD_PG_TAG_TO_READS true --REMOVE_DUPLICATES false --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Thu Nov 14 15:16:13 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-11-14 15:16:13\tMarkDuplicates\tStart of doWork freeMemory: 377799248; totalMemory: 402653184; maxMemory: 32178700288\n",
      "INFO\t2024-11-14 15:16:13\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-14 15:16:13\tMarkDuplicates\tWill retain up to 116589493 data points before spilling to disk.\n",
      "WARNING\t2024-11-14 15:16:14\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: vcrs_2607629_0rM. Cause: String 'vcrs_2607629_0rM' did not start with a parsable number.\n",
      "INFO\t2024-11-14 15:16:14\tMarkDuplicates\tRead 59587 records. 0 pairs never matched.\n",
      "INFO\t2024-11-14 15:16:14\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 937086960; totalMemory: 1912602624; maxMemory: 32178700288\n",
      "INFO\t2024-11-14 15:16:14\tMarkDuplicates\tWill retain up to 1005584384 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 7264613792; totalMemory: 15351152640; maxMemory: 32178700288\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tMarking 23353 records as duplicates.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-14 15:16:21\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tBefore output close freeMemory: 1039526608; totalMemory: 1073741824; maxMemory: 32178700288\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-14 15:16:22\tMarkDuplicates\tAfter output close freeMemory: 423988224; totalMemory: 452984832; maxMemory: 32178700288\n",
      "[Thu Nov 14 15:16:22 PST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.15 minutes.\n",
      "Runtime.totalMemory()=452984832\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MarkDuplicates \\\n",
    "      --INPUT $merged_bam \\\n",
    "      --OUTPUT $marked_duplicates_bam \\\n",
    "      --METRICS_FILE $marked_dup_metrics_txt \\\n",
    "      --CREATE_INDEX true \\\n",
    "      --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. SplitNCigarReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar SplitNCigarReads -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov15/alignment/marked_duplicates.bam -O /home/jrich/data/varseek_data/gatk_nov15/alignment/split_n_cigar_reads.bam\n",
      "15:16:39.035 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:16:39.256 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "15:16:39.260 INFO  SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:16:39.260 INFO  SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:16:39.261 INFO  SplitNCigarReads - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:16:39.261 INFO  SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:16:39.261 INFO  SplitNCigarReads - Start Date/Time: November 14, 2024 at 3:16:38 PM PST\n",
      "15:16:39.261 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "15:16:39.261 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "15:16:39.262 INFO  SplitNCigarReads - HTSJDK Version: 4.1.1\n",
      "15:16:39.262 INFO  SplitNCigarReads - Picard Version: 3.2.0\n",
      "15:16:39.263 INFO  SplitNCigarReads - Built for Spark Version: 3.5.0\n",
      "15:16:39.263 INFO  SplitNCigarReads - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:16:39.263 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:16:39.263 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:16:39.264 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:16:39.264 INFO  SplitNCigarReads - Deflater: IntelDeflater\n",
      "15:16:39.264 INFO  SplitNCigarReads - Inflater: IntelInflater\n",
      "15:16:39.264 INFO  SplitNCigarReads - GCS max retries/reopens: 20\n",
      "15:16:39.264 INFO  SplitNCigarReads - Requester pays: disabled\n",
      "15:16:39.265 INFO  SplitNCigarReads - Initializing engine\n",
      "15:16:39.425 INFO  SplitNCigarReads - Done initializing engine\n",
      "15:16:39.449 INFO  ProgressMeter - Starting traversal\n",
      "15:16:39.449 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "15:16:41.030 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "15:16:41.193 INFO  OverhangFixingManager - Overhang Fixing Manager saved 481 reads in the first pass\n",
      "15:16:41.195 INFO  SplitNCigarReads - Starting traversal pass 2\n",
      "15:16:42.411 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "15:16:42.412 INFO  ProgressMeter -             unmapped              0.0                232012        4699770.4\n",
      "15:16:42.413 INFO  ProgressMeter - Traversal complete. Processed 232012 total reads in 0.0 minutes.\n",
      "15:16:43.320 INFO  SplitNCigarReads - Shutting down engine\n",
      "[November 14, 2024 at 3:16:43 PM PST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 0.07 minutes.\n",
      "Runtime.totalMemory()=1224736768\n"
     ]
    }
   ],
   "source": [
    "_ = pysam.faidx(reference_genome_fasta)\n",
    "\n",
    "!$gatk SplitNCigarReads \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $marked_duplicates_bam \\\n",
    "    -O $split_n_cigar_reads_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. BaseRecalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  -I in old version, -F in new version\n",
    "# if not os.path.exists(f\"{ensembl_germline_vcf_filtered}.idx\"):\n",
    "#     !$gatk IndexFeatureFile -I $ensembl_germline_vcf_filtered  # TODO: ~81092000/324780532 processed before error - current error being a duplicate G in REF/ALT column\n",
    "\n",
    "if not os.path.exists(f\"{genomes1000_vcf}.idx\"):\n",
    "    !$gatk IndexFeatureFile -I $genomes1000_vcf\n",
    "\n",
    "# TODO: uncomment once I install bgzip\n",
    "# if not os.path.exists(f\"{panel_of_normals_vcf_filtered}.idx\"):\n",
    "#     !gatk IndexFeatureFile -I $panel_of_normals_vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar BaseRecalibrator -I /home/jrich/data/varseek_data/gatk_nov15/alignment/split_n_cigar_reads.bam -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --use-original-qualities --known-sites /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf -O /home/jrich/data/varseek_data/gatk_nov15/alignment/recal_data.table\n",
      "15:19:05.498 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:19:05.638 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "15:19:05.643 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:19:05.643 INFO  BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:19:05.643 INFO  BaseRecalibrator - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:19:05.643 INFO  BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:19:05.644 INFO  BaseRecalibrator - Start Date/Time: November 14, 2024 at 3:19:05 PM PST\n",
      "15:19:05.644 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "15:19:05.644 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "15:19:05.645 INFO  BaseRecalibrator - HTSJDK Version: 4.1.1\n",
      "15:19:05.645 INFO  BaseRecalibrator - Picard Version: 3.2.0\n",
      "15:19:05.645 INFO  BaseRecalibrator - Built for Spark Version: 3.5.0\n",
      "15:19:05.645 INFO  BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:19:05.646 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:19:05.646 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:19:05.646 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:19:05.646 INFO  BaseRecalibrator - Deflater: IntelDeflater\n",
      "15:19:05.646 INFO  BaseRecalibrator - Inflater: IntelInflater\n",
      "15:19:05.646 INFO  BaseRecalibrator - GCS max retries/reopens: 20\n",
      "15:19:05.647 INFO  BaseRecalibrator - Requester pays: disabled\n",
      "15:19:05.647 INFO  BaseRecalibrator - Initializing engine\n",
      "15:19:06.178 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\n",
      "15:19:06.411 WARN  IndexUtils - Feature file \"file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file\n",
      "15:19:06.506 INFO  BaseRecalibrator - Done initializing engine\n",
      "15:19:06.512 INFO  BaseRecalibrationEngine - The covariates being used here: \n",
      "15:19:06.512 INFO  BaseRecalibrationEngine - \tReadGroupCovariate\n",
      "15:19:06.512 INFO  BaseRecalibrationEngine - \tQualityScoreCovariate\n",
      "15:19:06.512 INFO  BaseRecalibrationEngine - \tContextCovariate\n",
      "15:19:06.513 INFO  BaseRecalibrationEngine - \tCycleCovariate\n",
      "15:19:06.517 INFO  ProgressMeter - Starting traversal\n",
      "15:19:06.518 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "15:19:11.687 INFO  BaseRecalibrator - 56466 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "39282 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "95748 total reads filtered out of 157727 reads processed\n",
      "15:19:11.691 INFO  ProgressMeter -          9:136319537              0.1                 61979         719431.2\n",
      "15:19:11.691 INFO  ProgressMeter - Traversal complete. Processed 61979 total reads in 0.1 minutes.\n",
      "15:19:11.709 INFO  BaseRecalibrator - Calculating quantized quality scores...\n",
      "15:19:11.737 INFO  BaseRecalibrator - Writing recalibration report...\n",
      "15:19:11.827 INFO  BaseRecalibrator - ...done!\n",
      "15:19:11.828 INFO  BaseRecalibrator - BaseRecalibrator was able to recalibrate 61979 reads\n",
      "15:19:11.828 INFO  BaseRecalibrator - Shutting down engine\n",
      "[November 14, 2024 at 3:19:11 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.11 minutes.\n",
      "Runtime.totalMemory()=1224736768\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# TODO: when I fix !$gatk IndexFeatureFile -I $ensembl_germline_vcf_filtered, add back --known-sites $ensembl_germline_vcf_filtered\n",
    "!$gatk BaseRecalibrator \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    --use-original-qualities \\\n",
    "    --known-sites $genomes1000_vcf \\\n",
    "    -O $recal_data_table\n",
    "\n",
    "# -known-sites ${dbSNP_vcf} \\\n",
    "# -known-sites ${sep=\" --known-sites \" known_indels_sites_VCFs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar ApplyBQSR --add-output-sam-program-record -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov15/alignment/split_n_cigar_reads.bam --use-original-qualities --bqsr-recal-file /home/jrich/data/varseek_data/gatk_nov15/alignment/recal_data.table -O /home/jrich/data/varseek_data/gatk_nov15/alignment/recalibrated.bam\n",
      "15:19:14.190 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:19:14.328 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "15:19:14.332 INFO  ApplyBQSR - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:19:14.333 INFO  ApplyBQSR - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:19:14.333 INFO  ApplyBQSR - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:19:14.333 INFO  ApplyBQSR - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:19:14.333 INFO  ApplyBQSR - Start Date/Time: November 14, 2024 at 3:19:14 PM PST\n",
      "15:19:14.333 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "15:19:14.334 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "15:19:14.334 INFO  ApplyBQSR - HTSJDK Version: 4.1.1\n",
      "15:19:14.335 INFO  ApplyBQSR - Picard Version: 3.2.0\n",
      "15:19:14.335 INFO  ApplyBQSR - Built for Spark Version: 3.5.0\n",
      "15:19:14.335 INFO  ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:19:14.335 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:19:14.336 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:19:14.336 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:19:14.336 INFO  ApplyBQSR - Deflater: IntelDeflater\n",
      "15:19:14.336 INFO  ApplyBQSR - Inflater: IntelInflater\n",
      "15:19:14.336 INFO  ApplyBQSR - GCS max retries/reopens: 20\n",
      "15:19:14.336 INFO  ApplyBQSR - Requester pays: disabled\n",
      "15:19:14.337 INFO  ApplyBQSR - Initializing engine\n",
      "15:19:14.511 INFO  ApplyBQSR - Done initializing engine\n",
      "15:19:14.531 INFO  ProgressMeter - Starting traversal\n",
      "15:19:14.531 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "15:19:17.457 INFO  ApplyBQSR - 0 read(s) filtered by: WellformedReadFilter \n",
      "\n",
      "15:19:17.457 INFO  ProgressMeter -             unmapped              0.0                157727        3234319.9\n",
      "15:19:17.458 INFO  ProgressMeter - Traversal complete. Processed 157727 total reads in 0.0 minutes.\n",
      "15:19:17.516 INFO  ApplyBQSR - Shutting down engine\n",
      "[November 14, 2024 at 3:19:17 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.06 minutes.\n",
      "Runtime.totalMemory()=1224736768\n"
     ]
    }
   ],
   "source": [
    "!$gatk ApplyBQSR \\\n",
    "    --add-output-sam-program-record \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    --use-original-qualities \\\n",
    "    --bqsr-recal-file $recal_data_table \\\n",
    "    -O $recalibrated_bam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. AnalyzeCovariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar AnalyzeCovariates -bqsr /home/jrich/data/varseek_data/gatk_nov15/alignment/recal_data.table -plots /home/jrich/data/varseek_data/gatk_nov15/alignment/AnalyzeCovariates.pdf\n",
      "15:19:19.635 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:19:19.798 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "15:19:19.803 INFO  AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:19:19.803 INFO  AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:19:19.803 INFO  AnalyzeCovariates - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:19:19.804 INFO  AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:19:19.804 INFO  AnalyzeCovariates - Start Date/Time: November 14, 2024 at 3:19:19 PM PST\n",
      "15:19:19.804 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "15:19:19.804 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "15:19:19.805 INFO  AnalyzeCovariates - HTSJDK Version: 4.1.1\n",
      "15:19:19.805 INFO  AnalyzeCovariates - Picard Version: 3.2.0\n",
      "15:19:19.806 INFO  AnalyzeCovariates - Built for Spark Version: 3.5.0\n",
      "15:19:19.806 INFO  AnalyzeCovariates - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:19:19.806 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:19:19.806 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:19:19.807 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:19:19.807 INFO  AnalyzeCovariates - Deflater: IntelDeflater\n",
      "15:19:19.807 INFO  AnalyzeCovariates - Inflater: IntelInflater\n",
      "15:19:19.807 INFO  AnalyzeCovariates - GCS max retries/reopens: 20\n",
      "15:19:19.807 INFO  AnalyzeCovariates - Requester pays: disabled\n",
      "15:19:19.808 INFO  AnalyzeCovariates - Initializing engine\n",
      "15:19:19.808 INFO  AnalyzeCovariates - Done initializing engine\n",
      "15:19:19.873 INFO  AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates9506792963394308921.csv'\n",
      "15:19:19.904 INFO  AnalyzeCovariates - Generating plots file '/home/jrich/data/varseek_data/gatk_nov15/alignment/AnalyzeCovariates.pdf'\n",
      "15:19:20.537 INFO  AnalyzeCovariates - Shutting down engine\n",
      "[November 14, 2024 at 3:19:20 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.\n",
      "Runtime.totalMemory()=285212672\n",
      "org.broadinstitute.hellbender.utils.R.RScriptExecutorException: \n",
      "Rscript exited with 1\n",
      "Command Line: Rscript -e tempLibDir = '/tmp/Rlib.3963338006938615706';source('/tmp/BQSR.1544659907463432169.R'); /tmp/AnalyzeCovariates9506792963394308921.csv /home/jrich/data/varseek_data/gatk_nov15/alignment/recal_data.table /home/jrich/data/varseek_data/gatk_nov15/alignment/AnalyzeCovariates.pdf\n",
      "Stdout: \n",
      "Stderr: Error in library(\"ggplot2\") : there is no package called ‘ggplot2’\n",
      "Calls: source -> withVisible -> eval -> eval -> library\n",
      "Execution halted\n",
      "\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18)\n",
      "\tat org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:125)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217)\n",
      "\tat org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166)\n",
      "\tat org.broadinstitute.hellbender.Main.mainEntry(Main.java:209)\n",
      "\tat org.broadinstitute.hellbender.Main.main(Main.java:306)\n"
     ]
    }
   ],
   "source": [
    "!$gatk AnalyzeCovariates \\\n",
    "    -bqsr $recal_data_table \\\n",
    "    -plots $covariates_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8a. HaplotypeCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar HaplotypeCaller -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov15/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz --standard-min-confidence-threshold-for-calling 20 -dont-use-soft-clipped-bases\n",
      "15:19:22.873 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:19:23.067 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "15:19:23.071 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:19:23.072 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:19:23.072 INFO  HaplotypeCaller - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:19:23.072 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:19:23.073 INFO  HaplotypeCaller - Start Date/Time: November 14, 2024 at 3:19:22 PM PST\n",
      "15:19:23.074 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "15:19:23.074 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "15:19:23.075 INFO  HaplotypeCaller - HTSJDK Version: 4.1.1\n",
      "15:19:23.075 INFO  HaplotypeCaller - Picard Version: 3.2.0\n",
      "15:19:23.075 INFO  HaplotypeCaller - Built for Spark Version: 3.5.0\n",
      "15:19:23.075 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:19:23.076 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:19:23.076 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:19:23.076 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:19:23.076 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "15:19:23.077 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "15:19:23.077 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "15:19:23.077 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "15:19:23.077 INFO  HaplotypeCaller - Initializing engine\n",
      "15:19:23.292 INFO  HaplotypeCaller - Done initializing engine\n",
      "15:19:23.305 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "15:19:23.307 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "15:19:23.309 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "15:19:23.309 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "15:19:23.311 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "15:19:23.320 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "15:19:23.347 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "15:19:23.348 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "15:19:23.348 INFO  IntelPairHmm - Available threads: 88\n",
      "15:19:23.348 INFO  IntelPairHmm - Requested threads: 4\n",
      "15:19:23.348 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "15:19:23.382 INFO  ProgressMeter - Starting traversal\n",
      "15:19:23.382 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "15:19:33.387 INFO  ProgressMeter -           1:70793701              0.2                235980        1415880.0\n",
      "15:19:43.383 INFO  ProgressMeter -          1:147569701              0.3                491900        1475700.0\n",
      "15:19:53.382 INFO  ProgressMeter -          1:223964701              0.5                746550        1493100.0\n",
      "15:20:03.382 INFO  ProgressMeter -          10:41352901              0.7                968680        1453020.0\n",
      "15:20:13.382 INFO  ProgressMeter -         10:104943901              0.8               1180650        1416780.0\n",
      "15:20:23.382 INFO  ProgressMeter -          11:33681001              1.0               1394890        1394890.0\n",
      "15:20:33.382 INFO  ProgressMeter -          11:98358001              1.2               1610480        1380411.4\n",
      "15:20:43.382 INFO  ProgressMeter -          12:31382401              1.3               1837250        1377937.5\n",
      "15:20:53.382 INFO  ProgressMeter -          12:97073401              1.5               2056220        1370813.3\n",
      "15:21:03.382 INFO  ProgressMeter -          13:29647501              1.7               2277640        1366584.0\n",
      "15:21:13.382 INFO  ProgressMeter -          13:94816501              1.8               2494870        1360838.2\n",
      "15:21:23.382 INFO  ProgressMeter -          14:46498501              2.0               2717710        1358855.0\n",
      "15:21:33.382 INFO  ProgressMeter -           15:1254901              2.2               2924730        1349875.4\n",
      "15:21:43.383 INFO  ProgressMeter -          15:64497901              2.3               3135540        1343793.3\n",
      "15:21:53.383 INFO  ProgressMeter -          16:16974301              2.5               3318900        1327551.1\n",
      "15:22:03.383 INFO  ProgressMeter -          16:80097301              2.7               3529310        1323483.0\n",
      "15:22:13.383 INFO  ProgressMeter -          17:57686401              2.8               3755790        1325565.1\n",
      "15:22:23.383 INFO  ProgressMeter -          18:42017101              3.0               3974210        1324729.3\n",
      "15:22:33.383 INFO  ProgressMeter -          19:26465701              3.2               4182630        1320823.6\n",
      "15:22:43.383 INFO  ProgressMeter -           2:29589601              3.3               4390140        1317035.4\n",
      "15:22:53.383 INFO  ProgressMeter -           2:94431601              3.5               4606280        1316073.7\n",
      "15:23:03.383 INFO  ProgressMeter -          2:154914601              3.7               4807890        1311236.8\n",
      "15:23:13.383 INFO  ProgressMeter -          2:217476601              3.8               5016430        1308628.2\n",
      "15:23:23.383 INFO  ProgressMeter -          20:38357101              4.0               5230030        1307502.1\n",
      "15:23:33.383 INFO  ProgressMeter -          21:43380301              4.2               5456860        1309641.2\n",
      "15:23:43.383 INFO  ProgressMeter -            3:7257601              4.3               5667900        1307971.9\n",
      "15:23:53.383 INFO  ProgressMeter -           3:70521357              4.5               5878780        1306390.7\n",
      "15:24:03.383 INFO  ProgressMeter -          3:134190357              4.7               6091010        1305211.8\n",
      "15:24:13.383 INFO  ProgressMeter -            4:1108801              4.8               6307480        1304991.4\n",
      "15:24:23.383 INFO  ProgressMeter -           4:67942801              5.0               6530260        1306047.6\n",
      "15:24:33.383 INFO  ProgressMeter -          4:133030801              5.2               6747220        1305909.3\n",
      "15:24:43.383 INFO  ProgressMeter -          4:181234801              5.3               6907900        1295227.2\n",
      "15:24:53.383 INFO  ProgressMeter -           5:53539501              5.5               7119430        1294437.9\n",
      "15:25:03.383 INFO  ProgressMeter -          5:117790501              5.7               7333600        1294160.9\n",
      "15:25:13.383 INFO  ProgressMeter -          5:179833501              5.8               7540410        1292638.0\n",
      "15:25:23.383 INFO  ProgressMeter -           6:66466201              6.0               7765570        1294258.1\n",
      "15:25:33.383 INFO  ProgressMeter -          6:129642728              6.2               7976160        1293427.9\n",
      "15:25:43.383 INFO  ProgressMeter -           7:29459401              6.3               8212600        1296722.9\n",
      "15:25:53.383 INFO  ProgressMeter -          7:100466401              6.5               8449290        1299887.4\n",
      "15:26:03.383 INFO  ProgressMeter -            8:9847501              6.7               8677690        1301650.2\n",
      "15:26:13.383 INFO  ProgressMeter -           8:78256501              6.8               8905720        1303272.9\n",
      "15:26:23.384 INFO  ProgressMeter -          8:143296501              7.0               9122520        1303214.0\n",
      "15:26:33.383 INFO  ProgressMeter -           9:65485201              7.2               9351030        1304791.8\n",
      "15:26:43.383 INFO  ProgressMeter -          9:132322201              7.3               9573820        1305517.9\n",
      "15:26:53.383 INFO  ProgressMeter -           X:65374801              7.5               9821430        1309521.1\n",
      "15:27:03.383 INFO  ProgressMeter -          X:135223801              7.7              10054260        1311422.4\n",
      "15:27:13.383 INFO  ProgressMeter -           Y:34727101              7.8              10236840        1306827.9\n",
      "15:27:19.047 INFO  HaplotypeCaller - 539 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "39234 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "39773 total reads filtered out of 101308 reads processed\n",
      "15:27:19.047 INFO  ProgressMeter -      GL000207.1:3601              7.9              10339392        1304202.6\n",
      "15:27:19.047 INFO  ProgressMeter - Traversal complete. Processed 10339392 total regions in 7.9 minutes.\n",
      "15:27:19.051 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0\n",
      "15:27:19.051 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0\n",
      "15:27:19.052 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.00 sec\n",
      "15:27:19.053 INFO  HaplotypeCaller - Shutting down engine\n",
      "[November 14, 2024 at 3:27:19 PM PST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 7.94 minutes.\n",
      "Runtime.totalMemory()=1126170624\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!$gatk --java-options \"-Xmx4g\" HaplotypeCaller  \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $haplotypecaller_unfiltered_vcf \\\n",
    "    --standard-min-confidence-threshold-for-calling 20 \\\n",
    "    -dont-use-soft-clipped-bases \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.5a. MergeVcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_vcf = haplotypecaller_merged.vcf\n",
    "# \n",
    "# !$java -jar $picard_jar MergeVcfs \\\n",
    "#     --INPUT $vcf1 \\\n",
    "#     --INPUT $vcf2 \\\n",
    "#     --OUTPUT $merged_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9a. VariantFiltration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar VariantFiltration -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz --window 35 --cluster 3 --filter-name FS --filter FS > 30.0 --filter-name QD --filter QD < 2.0\n",
      "15:27:21.813 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:27:21.968 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "15:27:21.973 INFO  VariantFiltration - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:27:21.973 INFO  VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:27:21.973 INFO  VariantFiltration - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:27:21.973 INFO  VariantFiltration - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:27:21.974 INFO  VariantFiltration - Start Date/Time: November 14, 2024 at 3:27:21 PM PST\n",
      "15:27:21.974 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "15:27:21.974 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "15:27:21.975 INFO  VariantFiltration - HTSJDK Version: 4.1.1\n",
      "15:27:21.975 INFO  VariantFiltration - Picard Version: 3.2.0\n",
      "15:27:21.975 INFO  VariantFiltration - Built for Spark Version: 3.5.0\n",
      "15:27:21.975 INFO  VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:27:21.975 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:27:21.975 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:27:21.976 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:27:21.976 INFO  VariantFiltration - Deflater: IntelDeflater\n",
      "15:27:21.976 INFO  VariantFiltration - Inflater: IntelInflater\n",
      "15:27:21.976 INFO  VariantFiltration - GCS max retries/reopens: 20\n",
      "15:27:21.976 INFO  VariantFiltration - Requester pays: disabled\n",
      "15:27:21.977 INFO  VariantFiltration - Initializing engine\n",
      "15:27:22.154 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz\n",
      "15:27:22.180 INFO  VariantFiltration - Done initializing engine\n",
      "15:27:22.272 INFO  ProgressMeter - Starting traversal\n",
      "15:27:22.273 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "15:27:22.276 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "15:27:22.277 INFO  ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.\n",
      "15:27:22.279 INFO  VariantFiltration - Shutting down engine\n",
      "[November 14, 2024 at 3:27:22 PM PST] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# cosmic_vcf = \"\"\n",
    "\n",
    "!$gatk VariantFiltration \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $haplotypecaller_unfiltered_vcf \\\n",
    "    -O $haplotypecaller_filtered_vcf \\\n",
    "    --window 35 \\\n",
    "    --cluster 3 \\\n",
    "    --filter-name \"FS\" \\\n",
    "    --filter \"FS > 30.0\" \\\n",
    "    --filter-name \"QD\" \\\n",
    "    --filter \"QD < 2.0\"\n",
    "\n",
    "    # --mask $cosmic_vcf \\\n",
    "    # --mask-name \"COSMIC\" \\\n",
    "    # --filter-not-in-mask \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10a. Do the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar SelectVariants -V /home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz --exclude-filtered true -O /home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_filtered_applied.vcf.gz\n",
      "15:27:24.486 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:27:24.659 INFO  SelectVariants - ------------------------------------------------------------\n",
      "15:27:24.668 INFO  SelectVariants - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:27:24.668 INFO  SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:27:24.669 INFO  SelectVariants - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:27:24.669 INFO  SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:27:24.671 INFO  SelectVariants - Start Date/Time: November 14, 2024 at 3:27:24 PM PST\n",
      "15:27:24.672 INFO  SelectVariants - ------------------------------------------------------------\n",
      "15:27:24.672 INFO  SelectVariants - ------------------------------------------------------------\n",
      "15:27:24.674 INFO  SelectVariants - HTSJDK Version: 4.1.1\n",
      "15:27:24.674 INFO  SelectVariants - Picard Version: 3.2.0\n",
      "15:27:24.674 INFO  SelectVariants - Built for Spark Version: 3.5.0\n",
      "15:27:24.674 INFO  SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:27:24.675 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:27:24.675 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:27:24.675 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:27:24.676 INFO  SelectVariants - Deflater: IntelDeflater\n",
      "15:27:24.676 INFO  SelectVariants - Inflater: IntelInflater\n",
      "15:27:24.676 INFO  SelectVariants - GCS max retries/reopens: 20\n",
      "15:27:24.676 INFO  SelectVariants - Requester pays: disabled\n",
      "15:27:24.677 INFO  SelectVariants - Initializing engine\n",
      "15:27:24.854 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov15/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz\n",
      "15:27:24.894 INFO  SelectVariants - Done initializing engine\n",
      "15:27:24.930 INFO  ProgressMeter - Starting traversal\n",
      "15:27:24.930 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "15:27:24.936 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "15:27:24.936 INFO  ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.\n",
      "15:27:24.939 INFO  SelectVariants - Shutting down engine\n",
      "[November 14, 2024 at 3:27:24 PM PST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "!$gatk SelectVariants \\\n",
    "     -V $haplotypecaller_filtered_vcf \\\n",
    "     --exclude-filtered true \\\n",
    "     -O $haplotypecaller_filtered_applied_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8b. Mutect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar Mutect2 -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov15/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk_nov15/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz --min-base-quality-score 20\n",
      "15:27:27.258 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:27:27.417 INFO  Mutect2 - ------------------------------------------------------------\n",
      "15:27:27.421 INFO  Mutect2 - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:27:27.421 INFO  Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:27:27.421 INFO  Mutect2 - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:27:27.422 INFO  Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:27:27.422 INFO  Mutect2 - Start Date/Time: November 14, 2024 at 3:27:27 PM PST\n",
      "15:27:27.422 INFO  Mutect2 - ------------------------------------------------------------\n",
      "15:27:27.422 INFO  Mutect2 - ------------------------------------------------------------\n",
      "15:27:27.423 INFO  Mutect2 - HTSJDK Version: 4.1.1\n",
      "15:27:27.424 INFO  Mutect2 - Picard Version: 3.2.0\n",
      "15:27:27.424 INFO  Mutect2 - Built for Spark Version: 3.5.0\n",
      "15:27:27.424 INFO  Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:27:27.424 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:27:27.425 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:27:27.425 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:27:27.425 INFO  Mutect2 - Deflater: IntelDeflater\n",
      "15:27:27.425 INFO  Mutect2 - Inflater: IntelInflater\n",
      "15:27:27.425 INFO  Mutect2 - GCS max retries/reopens: 20\n",
      "15:27:27.425 INFO  Mutect2 - Requester pays: disabled\n",
      "15:27:27.426 INFO  Mutect2 - Initializing engine\n",
      "15:27:27.660 INFO  Mutect2 - Done initializing engine\n",
      "15:27:27.668 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "15:27:27.670 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "15:27:27.672 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "15:27:27.672 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "15:27:27.683 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "15:27:27.711 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "15:27:27.711 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "15:27:27.712 INFO  IntelPairHmm - Available threads: 88\n",
      "15:27:27.712 INFO  IntelPairHmm - Requested threads: 4\n",
      "15:27:27.712 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "15:27:27.744 INFO  ProgressMeter - Starting traversal\n",
      "15:27:27.744 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "15:27:37.751 INFO  ProgressMeter -           1:42914701              0.2                143050         858300.0\n",
      "15:27:47.745 INFO  ProgressMeter -           1:84008701              0.3                280030         840090.0\n",
      "15:27:57.745 INFO  ProgressMeter -          1:130073701              0.5                433580         867160.0\n",
      "15:28:07.745 INFO  ProgressMeter -          1:184238701              0.7                614130         921195.0\n",
      "15:28:17.744 INFO  ProgressMeter -          1:240860701              0.8                802870         963444.0\n",
      "15:28:27.744 INFO  ProgressMeter -          10:44679901              1.0                979770         979770.0\n",
      "15:28:37.745 INFO  ProgressMeter -          10:97050901              1.2               1154340         989434.3\n",
      "15:28:47.744 INFO  ProgressMeter -          11:13029001              1.3               1326050         994537.5\n",
      "15:28:57.744 INFO  ProgressMeter -          11:67056001              1.5               1506140        1004093.3\n",
      "15:29:07.745 INFO  ProgressMeter -         11:118770001              1.7               1678520        1007112.0\n",
      "15:29:17.744 INFO  ProgressMeter -          12:38708401              1.8               1861670        1015456.4\n",
      "15:29:27.744 INFO  ProgressMeter -          12:92147401              2.0               2039800        1019900.0\n",
      "15:29:37.744 INFO  ProgressMeter -           13:9934501              2.2               2211930        1020890.8\n",
      "15:29:47.744 INFO  ProgressMeter -          13:66733501              2.3               2401260        1029111.4\n",
      "15:29:57.744 INFO  ProgressMeter -           14:3886501              2.5               2575670        1030268.0\n",
      "15:30:07.744 INFO  ProgressMeter -          14:59332501              2.7               2760490        1035183.8\n",
      "15:30:17.744 INFO  ProgressMeter -           15:5052901              2.8               2937390        1036725.9\n",
      "15:30:27.744 INFO  ProgressMeter -          15:59838901              3.0               3120010        1040003.3\n",
      "15:30:37.744 INFO  ProgressMeter -           16:3771301              3.2               3274890        1034175.8\n",
      "15:30:47.744 INFO  ProgressMeter -          16:59217301              3.3               3459710        1037913.0\n",
      "15:30:57.744 INFO  ProgressMeter -          17:23939401              3.5               3643300        1040942.9\n",
      "15:31:07.744 INFO  ProgressMeter -          17:78842401              3.7               3826310        1043539.1\n",
      "15:31:17.744 INFO  ProgressMeter -          18:52523101              3.8               4009230        1045886.1\n",
      "15:31:27.744 INFO  ProgressMeter -          19:26075701              4.0               4181330        1045332.5\n",
      "15:31:37.744 INFO  ProgressMeter -           2:23856601              4.2               4371030        1049047.2\n",
      "15:31:47.745 INFO  ProgressMeter -           2:74262601              4.3               4539050        1047473.1\n",
      "15:31:57.744 INFO  ProgressMeter -          2:113628601              4.5               4670270        1037837.8\n",
      "15:32:07.744 INFO  ProgressMeter -          2:160113601              4.7               4825220        1033975.7\n",
      "15:32:17.744 INFO  ProgressMeter -          2:205038601              4.8               4974970        1029304.1\n",
      "15:32:27.744 INFO  ProgressMeter -          20:12536101              5.0               5143960        1028792.0\n",
      "15:32:37.744 INFO  ProgressMeter -           21:5790301              5.2               5331560        1031914.8\n",
      "15:32:47.744 INFO  ProgressMeter -          22:15191401              5.3               5523330        1035624.4\n",
      "15:32:57.745 INFO  ProgressMeter -            3:7707601              5.5               5669400        1030800.0\n",
      "15:33:07.744 INFO  ProgressMeter -           3:54375362              5.7               5824960        1027934.1\n",
      "15:33:17.745 INFO  ProgressMeter -          3:100281362              5.8               5977980        1024796.6\n",
      "15:33:27.745 INFO  ProgressMeter -          3:152982362              6.0               6153650        1025608.3\n",
      "15:33:37.744 INFO  ProgressMeter -           4:10510801              6.2               6338820        1027916.8\n",
      "15:33:47.744 INFO  ProgressMeter -           4:71104801              6.3               6540800        1032757.9\n",
      "15:33:57.744 INFO  ProgressMeter -          4:127153801              6.5               6727630        1035020.0\n",
      "15:34:07.744 INFO  ProgressMeter -          4:178759801              6.7               6899650        1034947.5\n",
      "15:34:17.744 INFO  ProgressMeter -           5:46723501              6.8               7096710        1038542.9\n",
      "15:34:27.744 INFO  ProgressMeter -          5:102787501              7.0               7283590        1040512.9\n",
      "15:34:37.744 INFO  ProgressMeter -          5:159550501              7.2               7472800        1042716.3\n",
      "15:34:47.744 INFO  ProgressMeter -           6:38281201              7.3               7671620        1046130.0\n",
      "15:34:57.744 INFO  ProgressMeter -           6:94495201              7.5               7859000        1047866.7\n",
      "15:35:07.744 INFO  ProgressMeter -          6:148758733              7.7               8039880        1048680.0\n",
      "15:35:17.744 INFO  ProgressMeter -           7:35402401              7.8               8232410        1050946.0\n",
      "15:35:27.745 INFO  ProgressMeter -           7:93695401              8.0               8426720        1053340.0\n",
      "15:35:37.745 INFO  ProgressMeter -          7:141581401              8.2               8586340        1051388.6\n",
      "15:35:47.744 INFO  ProgressMeter -           8:36307501              8.3               8765890        1051906.8\n",
      "15:35:57.744 INFO  ProgressMeter -           8:85063501              8.5               8928410        1050401.2\n",
      "15:36:07.745 INFO  ProgressMeter -          8:138268501              8.7               9105760        1050664.6\n",
      "15:36:17.744 INFO  ProgressMeter -           9:51646201              8.8               9304900        1053384.9\n",
      "15:36:27.744 INFO  ProgressMeter -          9:106354201              9.0               9487260        1054140.0\n",
      "15:36:37.744 INFO  ProgressMeter -            X:8002501              9.2               9630190        1050566.2\n",
      "15:36:47.744 INFO  ProgressMeter -           X:56254501              9.3               9791030        1049038.9\n",
      "15:36:57.745 INFO  ProgressMeter -          X:104104501              9.5               9950530        1047424.2\n",
      "15:37:07.745 INFO  ProgressMeter -          X:153565501              9.7              10115400        1046420.7\n",
      "15:37:17.744 INFO  ProgressMeter -           Y:46015801              9.8              10274470        1044861.4\n",
      "15:37:21.654 INFO  Mutect2 - 539 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "39234 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: ReadLengthReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "39773 total reads filtered out of 101308 reads processed\n",
      "15:37:21.655 INFO  ProgressMeter -      GL000207.1:3301              9.9              10339393        1044541.4\n",
      "15:37:21.655 INFO  ProgressMeter - Traversal complete. Processed 10339393 total regions in 9.9 minutes.\n",
      "15:37:21.754 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0\n",
      "15:37:21.754 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0\n",
      "15:37:21.755 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.00 sec\n",
      "15:37:21.756 INFO  Mutect2 - Shutting down engine\n",
      "[November 14, 2024 at 3:37:21 PM PST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 9.91 minutes.\n",
      "Runtime.totalMemory()=2835349504\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# consider adding --disable-read-filter\n",
    "# TODO: add --panel-of-normals $panel_of_normals_vcf_filtered once I install bgzip\n",
    "!$gatk Mutect2 \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $mutect2_unfiltered_vcf \\\n",
    "    --min-base-quality-score 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9b. FilterMutectCalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar FilterMutectCalls -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk_nov15/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk_nov15/vcfs/mutect2/mutect2_output_filtered.vcf.gz\n",
      "15:37:24.361 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "15:37:24.551 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "15:37:24.556 INFO  FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "15:37:24.556 INFO  FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "15:37:24.556 INFO  FilterMutectCalls - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "15:37:24.556 INFO  FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "15:37:24.557 INFO  FilterMutectCalls - Start Date/Time: November 14, 2024 at 3:37:24 PM PST\n",
      "15:37:24.557 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "15:37:24.557 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "15:37:24.558 INFO  FilterMutectCalls - HTSJDK Version: 4.1.1\n",
      "15:37:24.558 INFO  FilterMutectCalls - Picard Version: 3.2.0\n",
      "15:37:24.559 INFO  FilterMutectCalls - Built for Spark Version: 3.5.0\n",
      "15:37:24.559 INFO  FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "15:37:24.559 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "15:37:24.559 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "15:37:24.560 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "15:37:24.560 INFO  FilterMutectCalls - Deflater: IntelDeflater\n",
      "15:37:24.560 INFO  FilterMutectCalls - Inflater: IntelInflater\n",
      "15:37:24.560 INFO  FilterMutectCalls - GCS max retries/reopens: 20\n",
      "15:37:24.560 INFO  FilterMutectCalls - Requester pays: disabled\n",
      "15:37:24.561 INFO  FilterMutectCalls - Initializing engine\n",
      "15:37:24.761 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov15/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz\n",
      "15:37:24.843 INFO  FilterMutectCalls - Done initializing engine\n",
      "15:37:25.078 INFO  ProgressMeter - Starting traversal\n",
      "15:37:25.079 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "15:37:25.080 INFO  FilterMutectCalls - Starting pass 0 through the variants\n",
      "15:37:25.085 INFO  FilterMutectCalls - Finished pass 0 through the variants\n",
      "15:37:25.176 INFO  FilterMutectCalls - Starting pass 1 through the variants\n",
      "15:37:25.178 INFO  FilterMutectCalls - Finished pass 1 through the variants\n",
      "15:37:25.180 INFO  FilterMutectCalls - Starting pass 2 through the variants\n",
      "15:37:25.182 INFO  FilterMutectCalls - Finished pass 2 through the variants\n",
      "15:37:25.182 INFO  FilterMutectCalls - Starting pass 3 through the variants\n",
      "15:37:25.184 INFO  FilterMutectCalls - Finished pass 3 through the variants\n",
      "15:37:25.195 INFO  FilterMutectCalls - No variants filtered by: AllowAllVariantsVariantFilter\n",
      "15:37:25.196 INFO  FilterMutectCalls - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "15:37:25.197 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "15:37:25.197 INFO  ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.\n",
      "15:37:25.201 INFO  FilterMutectCalls - Shutting down engine\n",
      "[November 14, 2024 at 3:37:25 PM PST] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# # if multiple stats files:\n",
    "# !$gatk MergeMutectStats -stats unfiltered1.vcf.stats -stats unfiltered2.vcf.stats -O unfiltered.vcf.stats\n",
    "\n",
    "# stats_file = f\"{mutect2_unfiltered_vcf}.stats\"\n",
    "# --stats $stats_file\n",
    "!$gatk FilterMutectCalls \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $mutect2_unfiltered_vcf \\\n",
    "    -O $mutect2_filtered_vcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sample_vcf(output_path):\n",
    "#     with open(output_path, \"w\") as vcf_file:\n",
    "#         # Write VCF headers\n",
    "#         vcf_file.write(\"##fileformat=VCFv4.2\\n\")\n",
    "#         vcf_file.write(\"##source=SampleVCFGenerator\\n\")\n",
    "#         vcf_file.write(\"##reference=GRCh37\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=DP,Number=1,Type=Integer,Description=\\\"Total Depth\\\">\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=AF,Number=A,Type=Float,Description=\\\"Allele Frequency\\\">\\n\")\n",
    "#         vcf_file.write(\"##FILTER=<ID=PASS,Description=\\\"All filters passed\\\">\\n\")\n",
    "#         vcf_file.write(\"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\")\n",
    "#         vcf_file.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tsample1\\n\")\n",
    "        \n",
    "#         # Write sample variant entries\n",
    "#         variants = [\n",
    "#             (\"1\", 123456, \".\", \"G\", \"A\", 50, \"PASS\", \"DP=100;AF=0.5\", \"GT\", \"0/1\"),\n",
    "#             (\"1\", 234567, \".\", \"C\", \"T\", 60, \"PASS\", \"DP=200;AF=0.3\", \"GT\", \"1/1\"),\n",
    "#             (\"2\", 345678, \".\", \"T\", \"G\", 70, \"PASS\", \"DP=150;AF=0.1\", \"GT\", \"0/1\"),\n",
    "#             (\"X\", 456789, \".\", \"A\", \"C\", 80, \"PASS\", \"DP=120;AF=0.05\", \"GT\", \"0/0\")\n",
    "#         ]\n",
    "        \n",
    "#         for chrom, pos, var_id, ref, alt, qual, fltr, info, fmt, sample in variants:\n",
    "#             vcf_file.write(f\"{chrom}\\t{pos}\\t{var_id}\\t{ref}\\t{alt}\\t{qual}\\t{fltr}\\t{info}\\t{fmt}\\t{sample}\\n\")\n",
    "\n",
    "# # Usage\n",
    "# create_sample_vcf(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")\n",
    "\n",
    "# df_sample = vcf_to_dataframe(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUMP TO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3710.59s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3831.54s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3837.80s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "3844.11s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    }
   ],
   "source": [
    "from varseek.utils import vcf_to_dataframe\n",
    "\n",
    "# Convert VCF to DataFrame\n",
    "df_hap = vcf_to_dataframe(haplotypecaller_filtered_applied_vcf, additional_columns = False)\n",
    "df_mut = vcf_to_dataframe(mutect2_filtered_vcf, additional_columns = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df = add_vcf_info_to_cosmic_tsv(cosmic_tsv=cosmic_tsv, reference_genome_fasta=reference_genome_fasta, cosmic_df_out = None, cosmic_cdna_info_csv = cosmic_cdna_info_csv, mutation_source = \"cdna\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188830/1989552023.py:2: DtypeWarning: Columns (21,36,38,49,50,54,56) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unique_mcrs_df = pd.read_csv(unique_mcrs_df_path)\n"
     ]
    }
   ],
   "source": [
    "# load in unique_mcrs_df\n",
    "unique_mcrs_df = pd.read_csv(unique_mcrs_df_path)\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_vk', 'FP': 'FP_vk', 'TN': 'TN_vk', 'FN': 'FN_vk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df = cosmic_df[(cosmic_df['POS'].astype(int) >= 3699230) & (cosmic_df['POS'].astype(int) <= 3699239)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_tp = unique_mcrs_df.loc[unique_mcrs_df['TP_vk']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CHROM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_188830/2360849419.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  take the intersection of COSMIC and STAR dfs based on CHROM, POS, REF, ALT - but keep the ID from the COSMIC vcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m mut_cosmic_merged_df = pd.merge(df_mut, cosmic_df, \n\u001b[0m\u001b[1;32m      3\u001b[0m                      \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CHROM'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'POS'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'REF'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ALT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      suffixes=('_df1', '_df2'))\n",
      "\u001b[0;32m~/miniconda3/envs/varseek2/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mindicator\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 110\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/varseek2/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    699\u001b[0m         (\n\u001b[1;32m    700\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;31m# to avoid incompatible dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/varseek2/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m                         \u001b[0mlk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1179\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1180\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                         \u001b[0;31m# work-around for merge_asof(left_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/varseek2/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m             )\n\u001b[1;32m   1849\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CHROM'"
     ]
    }
   ],
   "source": [
    "#  take the intersection of COSMIC and STAR dfs based on CHROM, POS, REF, ALT - but keep the ID from the COSMIC vcf\n",
    "mut_cosmic_merged_df = pd.merge(df_mut, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "mut_cosmic_merged_df = mut_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_mut = set(mut_cosmic_merged_df['ID'])\n",
    "\n",
    "\n",
    "\n",
    "hap_cosmic_merged_df = pd.merge(df_hap, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "hap_cosmic_merged_df = hap_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_hap = set(hap_cosmic_merged_df['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_mutations_mutect = len(df_mut)\n",
    "number_of_cosmic_mutations_mutect = len(mut_cosmic_merged_df)\n",
    "number_of_mutations_haplotypecaller = len(df_hap)\n",
    "number_of_cosmic_mutations_haplotypecaller = len(hap_cosmic_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_mutect2'] = unique_mcrs_df['reference_header'].isin(id_set_mut)  #!!! ensure 'reference_header' is correct here  # keep in mind that my IDs are the mutation headers (ENST...), NOT mcrs headers or mcrs ids\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "\n",
    "mutect_stat_path = f\"{gatk_parent}/reference_metrics_mutect2.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = mutect_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_mutect2'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_mutect2.png\")\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'mutect_fp_{i}' for i in range(1, number_of_mutations_mutect - number_of_cosmic_mutations_mutect + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(mutect_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_mutect2.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_mutect2', 'FP': 'FP_gatk_mutect2', 'TN': 'TN_gatk_mutect2', 'FN': 'FN_gatk_mutect2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_haplotypecaller'] = unique_mcrs_df['reference_header'].isin(id_set_hap)\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "\n",
    "haplotypecaller_stat_path = f\"{gatk_parent}/reference_metrics_haplotypecaller.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = haplotypecaller_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_haplotypecaller'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_haplotypecaller.png\")\n",
    "\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'haplotypecaller_fp_{i}' for i in range(1, number_of_mutations_haplotypecaller - number_of_cosmic_mutations_haplotypecaller + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(haplotypecaller_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_haplotypecaller.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_haplotypecaller', 'FP': 'FP_gatk_haplotypecaller', 'TN': 'TN_gatk_haplotypecaller', 'FN': 'FN_gatk_haplotypecaller'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varseek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

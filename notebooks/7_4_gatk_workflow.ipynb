{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow followed according to: https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels\n",
    "\n",
    "Github workflow for GATK4 here: https://github.com/gatk-workflows/gatk4-rnaseq-germline-snps-indels/blob/master/gatk4-rna-best-practices.wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from varseek.varseek_build import add_mutation_type\n",
    "from varseek.utils import convert_chromosome_value_to_int_when_possible, calculate_metrics, draw_confusion_matrix, create_venn_diagram, calculate_sensitivity_specificity, create_stratified_metric_bar_plot\n",
    "from varseek.constants import complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_fastq(output_path, num_sequences=5000, seq_length=150, quality_score=\"I\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        bases = ['A', 'C', 'G', 'T']\n",
    "        with open(output_path, \"w\") as fastq_file:\n",
    "            for i in range(num_sequences):\n",
    "                # Generate a random sequence of the specified length\n",
    "                sequence = ''.join(random.choices(bases, k=seq_length))\n",
    "                \n",
    "                # Create a quality string of the same length, filled with the specified quality score\n",
    "                quality = quality_score * seq_length\n",
    "                \n",
    "                # Write the FASTQ entry\n",
    "                fastq_file.write(f\"@seq_{i + 1}\\n\")\n",
    "                fastq_file.write(f\"{sequence}\\n\")\n",
    "                fastq_file.write(\"+\\n\")\n",
    "                fastq_file.write(f\"{quality}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_read_fastq = \"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\"  #!!! update path\n",
    "unique_mcrs_df_path = \"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/unique_mcrs_df.csv\"  #!!! update path\n",
    "# generate_random_fastq(synthetic_read_fastq)\n",
    "\n",
    "gatk_parent = \"/home/jrich/data/varseek_data/gatk_nov14\"\n",
    "threads = 32\n",
    "read_length = 150\n",
    "mutation_source = \"cdna\"  # \"cdna\", \"cds\"\n",
    "\n",
    "cosmic_tsv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37.tsv\"\n",
    "cosmic_cdna_info_csv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37_mutation_workflow_with_cdna.csv\"\n",
    "\n",
    "# if these paths don't exist then they will be created\n",
    "reference_genome_fasta = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa\"\n",
    "reference_genome_gtf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf\"\n",
    "genomes1000_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\"\n",
    "ensembl_germline_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens.vcf\"\n",
    "star_genome_dir = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/star_reference\"\n",
    "\n",
    "STAR = \"/home/jrich/opt/STAR-2.7.11b/source/STAR\"\n",
    "java = \"/home/jrich/opt/java/jdk-17.0.12+7/bin/java\"\n",
    "picard_jar = \"/home/jrich/opt/picard/build/libs/picard.jar\"\n",
    "gatk = \"/home/jrich/opt/gatk-4.6.0.0/gatk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(star_genome_dir, exist_ok=True)\n",
    "\n",
    "alignment_folder = f\"{gatk_parent}/alignment\"\n",
    "os.makedirs(alignment_folder, exist_ok=True)\n",
    "\n",
    "gatk_supporting_files = f\"{gatk_parent}/supporting_files\"\n",
    "os.makedirs(gatk_supporting_files, exist_ok=True)\n",
    "\n",
    "ensembl_germline_vcf_filtered = ensembl_germline_vcf.replace(\".vcf\", \"_filtered.vcf\")\n",
    "\n",
    "out_file_name_prefix = f\"{alignment_folder}/sample_\"\n",
    "\n",
    "vcf_folder = f\"{gatk_parent}/vcfs\"\n",
    "haplotypecaller_folder = f\"{vcf_folder}/haplotypecaller\"\n",
    "mutect2_folder = f\"{vcf_folder}/mutect2\"\n",
    "\n",
    "os.makedirs(vcf_folder, exist_ok=True)\n",
    "os.makedirs(haplotypecaller_folder, exist_ok=True)\n",
    "os.makedirs(mutect2_folder, exist_ok=True)\n",
    "\n",
    "aligned_and_unmapped_bam = f\"{out_file_name_prefix}Aligned.sortedByCoord.out.bam\"\n",
    "aligned_only_bam = f\"{alignment_folder}/aligned_only.bam\"\n",
    "unmapped_bam = f\"{alignment_folder}/unmapped.bam\"\n",
    "merged_bam = f\"{alignment_folder}/merged.bam\"\n",
    "\n",
    "marked_duplicates_bam = f\"{alignment_folder}/marked_duplicates.bam\"\n",
    "marked_dup_metrics_txt = f\"{alignment_folder}/marked_dup_metrics.txt\"\n",
    "\n",
    "split_n_cigar_reads_bam = f\"{alignment_folder}/split_n_cigar_reads.bam\"\n",
    "recal_data_table = f\"{alignment_folder}/recal_data.table\"\n",
    "recalibrated_bam = f\"{alignment_folder}/recalibrated.bam\"\n",
    "covariates_plot = f\"{alignment_folder}/AnalyzeCovariates.pdf\"\n",
    "haplotypecaller_unfiltered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_unfiltered.g.vcf.gz\"\n",
    "\n",
    "haplotypecaller_filtered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered.vcf.gz\"\n",
    "haplotypecaller_filtered_applied_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered_applied.vcf.gz\"\n",
    "\n",
    "panel_of_normals_vcf = f\"{gatk_supporting_files}/1000g_pon.hg38.vcf.gz\"\n",
    "panel_of_normals_vcf_filtered = f\"{gatk_supporting_files}/1000g_pon.hg38_filtered.vcf.gz\"\n",
    "mutect2_unfiltered_vcf = f\"{mutect2_folder}/mutect2_output_unfiltered.g.vcf.gz\"\n",
    "mutect2_filtered_vcf = f\"{mutect2_folder}/mutect2_output_filtered.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(reference_genome_fasta):\n",
    "    !wget -O {reference_genome_fasta}.gz https://ftp.ensembl.org/pub/grch37/release-93/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz && gunzip {reference_genome_fasta}.gz\n",
    "\n",
    "if not os.path.exists(reference_genome_gtf):\n",
    "    !wget -O {reference_genome_gtf}.gz https://ftp.ensembl.org/pub/grch37/release-93/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz && gunzip {reference_genome_gtf}.gz\n",
    "\n",
    "if not os.path.exists(genomes1000_vcf):\n",
    "    !wget -O {genomes1000_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz && gunzip {genomes1000_vcf}.gz\n",
    "    \n",
    "if not os.path.exists(ensembl_germline_vcf):\n",
    "    !wget -O {ensembl_germline_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/homo_sapiens.vcf.gz && gunzip {ensembl_germline_vcf}.gz\n",
    "\n",
    "if not os.path.exists(ensembl_germline_vcf_filtered):\n",
    "    ensembl_germline_vcf_temp1 = ensembl_germline_vcf.replace(\".vcf\", \"_temp1.vcf\")\n",
    "    # ensembl_germline_vcf_temp2 = ensembl_germline_vcf.replace(\".vcf\", \"_temp2.vcf\")\n",
    "    !grep -vP '^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*[WH]|^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*[WH]' $ensembl_germline_vcf > $ensembl_germline_vcf_temp1\n",
    "    !grep -vP '^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t\\t|^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t\\t' $ensembl_germline_vcf_temp1 > $ensembl_germline_vcf_filtered\n",
    "    !rm $ensembl_germline_vcf_temp1\n",
    "\n",
    "if not os.path.exists(panel_of_normals_vcf):\n",
    "    !wget -P {gatk_supporting_files} https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz\n",
    "    !wget -P {gatk_supporting_files} https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz.tbi\n",
    "\n",
    "if not os.path.exists(panel_of_normals_vcf_filtered):\n",
    "    !cp $panel_of_normals_vcf $panel_of_normals_vcf_filtered\n",
    "    # Remove 'chr' prefix from data lines\n",
    "    !sed -i 's/^chr//' $panel_of_normals_vcf_filtered\n",
    "\n",
    "    # Remove 'chr' prefix from contig headers in the VCF\n",
    "    !sed -i '/^##contig/s/ID=chr/ID=/' $panel_of_normals_vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(panel_of_normals_vcf_filtered):\n",
    "    decompressed_pon_vcf = panel_of_normals_vcf.replace(\".vcf.gz\", \".vcf\")\n",
    "    !gunzip -c $panel_of_normals_vcf > $decompressed_pon_vcf\n",
    "    \n",
    "    # Remove 'chr' prefix from data lines\n",
    "    !sed -i 's/^chr//' $decompressed_pon_vcf\n",
    "\n",
    "    # Remove 'chr' prefix from contig headers in the VCF\n",
    "    !sed -i '/^##contig/s/ID=chr/ID=/' $decompressed_pon_vcf\n",
    "\n",
    "    # gunzip again\n",
    "    !bgzip -c $decompressed_pon_vcf > $panel_of_normals_vcf_filtered  # TODO: get bgzip installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mapping to the Reference with STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/jrich/opt/STAR-2.7.11b/source/STAR --runThreadN 32 --runMode genomeGenerate --genomeDir /home/jrich/data/varseek_data/gatk_nov14/reference --genomeFastaFiles /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --sjdbGTFfile /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --sjdbOverhang 149\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-22T09:22:47-0700 dator:/home/jrich/opt/STAR-2.7.11b/source\n",
      "Nov 13 16:03:34 ..... started STAR run\n",
      "Nov 13 16:03:34 ... starting to generate Genome files\n",
      "Nov 13 16:04:34 ..... processing annotations GTF\n",
      "Nov 13 16:05:02 ... starting to sort Suffix Array. This may take a long time...\n",
      "Nov 13 16:05:23 ... sorting Suffix Array chunks and saving them to disk...\n",
      "Nov 13 16:13:18 ... loading chunks from disk, packing SA...\n",
      "Nov 13 16:14:36 ... finished generating suffix array\n",
      "Nov 13 16:14:36 ... generating Suffix Array index\n",
      "Nov 13 16:18:23 ... completed Suffix Array index\n",
      "Nov 13 16:18:24 ..... inserting junctions into the genome indices\n",
      "Nov 13 16:22:04 ... writing Genome to disk ...\n",
      "Nov 13 16:22:07 ... writing Suffix Array to disk ...\n",
      "Nov 13 16:22:36 ... writing SAindex to disk\n",
      "Nov 13 16:22:40 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "read_length_minus_one = read_length - 1\n",
    "\n",
    "if not os.listdir(star_genome_dir):\n",
    "    !$STAR \\\n",
    "        --runThreadN $threads \\\n",
    "        --runMode genomeGenerate \\\n",
    "        --genomeDir $star_genome_dir \\\n",
    "        --genomeFastaFiles $reference_genome_fasta \\\n",
    "        --sjdbGTFfile $reference_genome_gtf \\\n",
    "        --sjdbOverhang $read_length_minus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/jrich/opt/STAR-2.7.11b/source/STAR --runThreadN 32 --genomeDir /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/star_reference --readFilesIn /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq --sjdbOverhang 149 --outFileNamePrefix /home/jrich/data/varseek_data/gatk_nov14/alignment/sample_ --outSAMtype BAM SortedByCoordinate --outSAMunmapped Within --outSAMmapqUnique 60 --twopassMode Basic\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-22T09:22:47-0700 dator:/home/jrich/opt/STAR-2.7.11b/source\n",
      "Nov 13 16:37:04 ..... started STAR run\n",
      "Nov 13 16:37:04 ..... loading genome\n",
      "Nov 13 16:37:25 ..... started 1st pass mapping\n",
      "Nov 13 16:37:30 ..... finished 1st pass mapping\n",
      "Nov 13 16:37:31 ..... inserting junctions into the genome indices\n",
      "Nov 13 16:39:14 ..... started mapping\n",
      "Nov 13 16:39:19 ..... finished mapping\n",
      "Nov 13 16:39:23 ..... started sorting BAM\n",
      "Nov 13 16:39:24 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "#* --outSAMmapqUnique 60 - change from default of 255 to avoid colliding with some aligners' use of 255 as a special value\n",
    "\n",
    "!$STAR \\\n",
    "    --runThreadN $threads \\\n",
    "    --genomeDir $star_genome_dir \\\n",
    "    --readFilesIn $synthetic_read_fastq \\\n",
    "    --sjdbOverhang $read_length_minus_one \\\n",
    "    --outFileNamePrefix $out_file_name_prefix \\\n",
    "    --outSAMtype BAM SortedByCoordinate \\\n",
    "    --outSAMunmapped Within \\\n",
    "    --outSAMmapqUnique 60 \\\n",
    "    --twopassMode Basic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate unmapped reads into its own BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pysam.AlignmentFile(aligned_and_unmapped_bam, \"rb\") as bam_in: \n",
    "#     # unmapped_header = bam_in.header.to_dict()\n",
    "#     # if 'PG' in unmapped_header:\n",
    "#     #     del unmapped_header['PG']\n",
    "           \n",
    "#     with pysam.AlignmentFile(aligned_only_bam, \"wb\", template=bam_in) as bam_aligned_out, pysam.AlignmentFile(unmapped_bam, \"wb\", template=bam_in) as bam_unmapped_out:\n",
    "#         for read in bam_in:\n",
    "#             if read.is_unmapped:\n",
    "#                 bam_unmapped_out.write(read)  # Write unmapped read to the unmapped BAM file\n",
    "#             else:\n",
    "#                 bam_aligned_out.write(read)  # Write aligned read to the aligned BAM file\n",
    "\n",
    "# print(f\"Unmapped reads written to {unmapped_bam}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:25.641 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Nov 13 16:39:25 PST 2024] FastqToSam --FASTQ /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq --OUTPUT /home/jrich/data/varseek_data/gatk_nov14/alignment/unmapped.bam --READ_GROUP_NAME rg1 --SAMPLE_NAME sample1 --LIBRARY_NAME lib1 --PLATFORM_UNIT unit1 --PLATFORM ILLUMINA --SEQUENCING_CENTER center1 --USE_SEQUENTIAL_FASTQS false --SORT_ORDER queryname --MIN_Q 0 --MAX_Q 93 --STRIP_UNPAIRED_MATE_NUMBER false --ALLOW_AND_IGNORE_EMPTY_LINES false --ALLOW_EMPTY_FASTQ false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Nov 13 16:39:25 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "WARNING\t2024-11-13 16:39:25\tFastqToSam\tMaking ambiguous determination about fastq's quality encoding; more than one format possible based on observed qualities.\n",
      "INFO\t2024-11-13 16:39:25\tFastqToSam\tAuto-detected quality format as: Illumina.\n",
      "INFO\t2024-11-13 16:39:26\tFastqToSam\tProcessed 59197 fastq reads\n",
      "[Wed Nov 13 16:39:26 PST 2024] picard.sam.FastqToSam done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=2181038080\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar FastqToSam \\\n",
    "    -FASTQ $synthetic_read_fastq \\\n",
    "    -OUTPUT $unmapped_bam \\\n",
    "    -READ_GROUP_NAME rg1 \\\n",
    "    -SAMPLE_NAME sample1 \\\n",
    "    -LIBRARY_NAME lib1 \\\n",
    "    -PLATFORM_UNIT unit1 \\\n",
    "    -PLATFORM ILLUMINA \\\n",
    "    -SEQUENCING_CENTER center1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MergeBamAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:27.377 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Nov 13 16:39:27 PST 2024] CreateSequenceDictionary --OUTPUT /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.dict --REFERENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Nov 13 16:39:27 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "[Wed Nov 13 16:39:27 PST 2024] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=2181038080\n",
      "To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp\n",
      "Exception in thread \"main\" picard.PicardException: file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.dict already exists.  Delete this file and try again, or specify a different output file.\n",
      "\tat picard.sam.CreateSequenceDictionary.doWork(CreateSequenceDictionary.java:227)\n",
      "\tat picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:281)\n",
      "\tat picard.cmdline.PicardCommandLine.instanceMain(PicardCommandLine.java:105)\n",
      "\tat picard.cmdline.PicardCommandLine.main(PicardCommandLine.java:115)\n"
     ]
    }
   ],
   "source": [
    "reference_genome_dict = reference_genome_fasta.replace(\".fa\", \".dict\")\n",
    "\n",
    "!$java -jar $picard_jar CreateSequenceDictionary \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -O $reference_genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:28.662 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Nov 13 16:39:28 PST 2024] MergeBamAlignment --UNMAPPED_BAM /home/jrich/data/varseek_data/gatk_nov14/alignment/unmapped.bam --ALIGNED_BAM /home/jrich/data/varseek_data/gatk_nov14/alignment/sample_Aligned.sortedByCoord.out.bam --OUTPUT /home/jrich/data/varseek_data/gatk_nov14/alignment/merged.bam --SORT_ORDER coordinate --INCLUDE_SECONDARY_ALIGNMENTS false --VALIDATION_STRINGENCY SILENT --REFERENCE_SEQUENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --ADD_PG_TAG_TO_READS true --PAIRED_RUN true --CLIP_ADAPTERS true --IS_BISULFITE_SEQUENCE false --ALIGNED_READS_ONLY false --MAX_INSERTIONS_OR_DELETIONS 1 --ATTRIBUTES_TO_REVERSE OQ --ATTRIBUTES_TO_REVERSE U2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT E2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT SQ --READ1_TRIM 0 --READ2_TRIM 0 --ALIGNER_PROPER_PAIR_FLAGS false --PRIMARY_ALIGNMENT_STRATEGY BestMapq --CLIP_OVERLAPPING_READS true --HARD_CLIP_OVERLAPPING_READS false --ADD_MATE_CIGAR true --UNMAP_CONTAMINANT_READS false --MIN_UNCLIPPED_BASES 32 --MATCHING_DICTIONARY_TAGS M5 --MATCHING_DICTIONARY_TAGS LN --UNMAPPED_READ_STRATEGY DO_NOT_CHANGE --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Nov 13 16:39:28 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-11-13 16:39:28\tSamAlignmentMerger\tProcessing SAM file(s): [/home/jrich/data/varseek_data/gatk_nov14/alignment/sample_Aligned.sortedByCoord.out.bam]\n",
      "WARNING\t2024-11-13 16:39:28\tSamAlignmentMerger\tException merging bam alignment - attempting to sort aligned reads and try again: Underlying iterator is not queryname sorted: vcrs_3969939_149fM 150b aligned to 1:3697852-3699234. > vcrs_3969939_0rW 150b aligned to 1:3697852-3699235.\n",
      "INFO\t2024-11-13 16:39:29\tSamAlignmentMerger\tFinished reading 59334 total records from alignment SAM/BAM.\n",
      "INFO\t2024-11-13 16:39:38\tAbstractAlignmentMerger\tWrote 59334 alignment records and 0 unmapped reads.\n",
      "[Wed Nov 13 16:39:38 PST 2024] picard.sam.MergeBamAlignment done. Elapsed time: 0.17 minutes.\n",
      "Runtime.totalMemory()=2181038080\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MergeBamAlignment \\\n",
    "    --ALIGNED_BAM $aligned_and_unmapped_bam \\\n",
    "    --UNMAPPED_BAM $unmapped_bam \\\n",
    "    --OUTPUT $merged_bam \\\n",
    "    --REFERENCE_SEQUENCE $reference_genome_fasta \\\n",
    "    --SORT_ORDER coordinate \\\n",
    "    --INCLUDE_SECONDARY_ALIGNMENTS false \\\n",
    "    --VALIDATION_STRINGENCY SILENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MarkDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:39:39.877 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Nov 13 16:39:39 PST 2024] MarkDuplicates --INPUT /home/jrich/data/varseek_data/gatk_nov14/alignment/merged.bam --OUTPUT /home/jrich/data/varseek_data/gatk_nov14/alignment/marked_duplicates.bam --METRICS_FILE /home/jrich/data/varseek_data/gatk_nov14/alignment/marked_dup_metrics.txt --VALIDATION_STRINGENCY SILENT --CREATE_INDEX true --MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP 50000 --MAX_FILE_HANDLES_FOR_READ_ENDS_MAP 8000 --SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --FLOW_MODE false --FLOW_DUP_STRATEGY FLOW_QUALITY_SUM_STRATEGY --USE_END_IN_UNPAIRED_READS false --USE_UNPAIRED_CLIPPED_END false --UNPAIRED_END_UNCERTAINTY 0 --UNPAIRED_START_UNCERTAINTY 0 --FLOW_SKIP_FIRST_N_FLOWS 0 --FLOW_Q_IS_KNOWN_END false --FLOW_EFFECTIVE_QUALITY_THRESHOLD 15 --ADD_PG_TAG_TO_READS true --REMOVE_DUPLICATES false --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Nov 13 16:39:40 PST 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-11-13 16:39:40\tMarkDuplicates\tStart of doWork freeMemory: 377797880; totalMemory: 402653184; maxMemory: 32178700288\n",
      "INFO\t2024-11-13 16:39:40\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-13 16:39:40\tMarkDuplicates\tWill retain up to 116589493 data points before spilling to disk.\n",
      "WARNING\t2024-11-13 16:39:40\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: vcrs_3969939_0rW. Cause: String 'vcrs_3969939_0rW' did not start with a parsable number.\n",
      "INFO\t2024-11-13 16:39:41\tMarkDuplicates\tRead 59197 records. 0 pairs never matched.\n",
      "INFO\t2024-11-13 16:39:41\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 904151704; totalMemory: 1879048192; maxMemory: 32178700288\n",
      "INFO\t2024-11-13 16:39:41\tMarkDuplicates\tWill retain up to 1005584384 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 7247836656; totalMemory: 15334375424; maxMemory: 32178700288\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tMarking 15333 records as duplicates.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-13 16:39:45\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tBefore output close freeMemory: 873878664; totalMemory: 905969664; maxMemory: 32178700288\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-13 16:39:46\tMarkDuplicates\tAfter output close freeMemory: 306803728; totalMemory: 335544320; maxMemory: 32178700288\n",
      "[Wed Nov 13 16:39:46 PST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.12 minutes.\n",
      "Runtime.totalMemory()=335544320\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MarkDuplicates \\\n",
    "      --INPUT $merged_bam \\\n",
    "      --OUTPUT $marked_duplicates_bam \\\n",
    "      --METRICS_FILE $marked_dup_metrics_txt \\\n",
    "      --CREATE_INDEX true \\\n",
    "      --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. SplitNCigarReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar SplitNCigarReads -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov14/alignment/marked_duplicates.bam -O /home/jrich/data/varseek_data/gatk_nov14/alignment/split_n_cigar_reads.bam\n",
      "16:40:01.392 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "16:40:01.543 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "16:40:01.548 INFO  SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "16:40:01.548 INFO  SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "16:40:01.548 INFO  SplitNCigarReads - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "16:40:01.548 INFO  SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "16:40:01.549 INFO  SplitNCigarReads - Start Date/Time: November 13, 2024 at 4:40:01 PM PST\n",
      "16:40:01.549 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "16:40:01.549 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "16:40:01.550 INFO  SplitNCigarReads - HTSJDK Version: 4.1.1\n",
      "16:40:01.550 INFO  SplitNCigarReads - Picard Version: 3.2.0\n",
      "16:40:01.550 INFO  SplitNCigarReads - Built for Spark Version: 3.5.0\n",
      "16:40:01.551 INFO  SplitNCigarReads - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "16:40:01.551 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "16:40:01.551 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "16:40:01.551 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "16:40:01.552 INFO  SplitNCigarReads - Deflater: IntelDeflater\n",
      "16:40:01.552 INFO  SplitNCigarReads - Inflater: IntelInflater\n",
      "16:40:01.552 INFO  SplitNCigarReads - GCS max retries/reopens: 20\n",
      "16:40:01.552 INFO  SplitNCigarReads - Requester pays: disabled\n",
      "16:40:01.553 INFO  SplitNCigarReads - Initializing engine\n",
      "16:40:01.732 INFO  SplitNCigarReads - Done initializing engine\n",
      "16:40:01.810 INFO  ProgressMeter - Starting traversal\n",
      "16:40:01.811 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "16:40:03.237 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "16:40:03.242 INFO  OverhangFixingManager - Overhang Fixing Manager saved 6 reads in the first pass\n",
      "16:40:03.248 INFO  SplitNCigarReads - Starting traversal pass 2\n",
      "16:40:04.360 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "16:40:04.362 INFO  ProgressMeter -          X:111020046              0.0                118394        2786834.1\n",
      "16:40:04.362 INFO  ProgressMeter - Traversal complete. Processed 118394 total reads in 0.0 minutes.\n",
      "16:40:04.931 INFO  SplitNCigarReads - Shutting down engine\n",
      "[November 13, 2024 at 4:40:04 PM PST] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 0.06 minutes.\n",
      "Runtime.totalMemory()=1224736768\n"
     ]
    }
   ],
   "source": [
    "_ = pysam.faidx(reference_genome_fasta)\n",
    "\n",
    "!$gatk SplitNCigarReads \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $marked_duplicates_bam \\\n",
    "    -O $split_n_cigar_reads_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. BaseRecalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -I in old version, -F in new version\n",
    "if not os.path.exists(f\"{ensembl_germline_vcf_filtered}.idx\"):\n",
    "    !$gatk IndexFeatureFile -I $ensembl_germline_vcf_filtered  # TODO: ~81092000/324780532 processed before error - current error being a duplicate G in REF/ALT column\n",
    "\n",
    "if not os.path.exists(f\"{genomes1000_vcf}.idx\"):\n",
    "    !$gatk IndexFeatureFile -I $genomes1000_vcf\n",
    "\n",
    "# TODO: uncomment once I install bgzip\n",
    "# if not os.path.exists(f\"{panel_of_normals_vcf_filtered}.idx\"):\n",
    "#     !gatk IndexFeatureFile -I $panel_of_normals_vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar BaseRecalibrator -I /home/jrich/data/varseek_data/gatk_nov14/alignment/split_n_cigar_reads.bam -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --use-original-qualities --known-sites /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf -O /home/jrich/data/varseek_data/gatk_nov14/alignment/recal_data.table\n",
      "17:20:50.383 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:20:50.521 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "17:20:50.524 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:20:50.524 INFO  BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:20:50.524 INFO  BaseRecalibrator - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:20:50.524 INFO  BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:20:50.524 INFO  BaseRecalibrator - Start Date/Time: November 13, 2024 at 5:20:50 PM PST\n",
      "17:20:50.524 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "17:20:50.524 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "17:20:50.525 INFO  BaseRecalibrator - HTSJDK Version: 4.1.1\n",
      "17:20:50.525 INFO  BaseRecalibrator - Picard Version: 3.2.0\n",
      "17:20:50.525 INFO  BaseRecalibrator - Built for Spark Version: 3.5.0\n",
      "17:20:50.526 INFO  BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:20:50.526 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:20:50.526 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:20:50.526 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:20:50.526 INFO  BaseRecalibrator - Deflater: IntelDeflater\n",
      "17:20:50.526 INFO  BaseRecalibrator - Inflater: IntelInflater\n",
      "17:20:50.527 INFO  BaseRecalibrator - GCS max retries/reopens: 20\n",
      "17:20:50.527 INFO  BaseRecalibrator - Requester pays: disabled\n",
      "17:20:50.527 INFO  BaseRecalibrator - Initializing engine\n",
      "17:20:50.789 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\n",
      "17:20:51.040 WARN  IndexUtils - Feature file \"file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file\n",
      "17:20:51.108 INFO  BaseRecalibrator - Done initializing engine\n",
      "17:20:51.112 INFO  BaseRecalibrationEngine - The covariates being used here: \n",
      "17:20:51.113 INFO  BaseRecalibrationEngine - \tReadGroupCovariate\n",
      "17:20:51.113 INFO  BaseRecalibrationEngine - \tQualityScoreCovariate\n",
      "17:20:51.113 INFO  BaseRecalibrationEngine - \tContextCovariate\n",
      "17:20:51.113 INFO  BaseRecalibrationEngine - \tCycleCovariate\n",
      "17:20:51.116 INFO  ProgressMeter - Starting traversal\n",
      "17:20:51.117 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "17:20:59.620 INFO  BaseRecalibrator - 0 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "27511 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "27511 total reads filtered out of 103693 reads processed\n",
      "17:20:59.624 INFO  ProgressMeter -          X:135485403              0.1                 76182         537502.4\n",
      "17:20:59.624 INFO  ProgressMeter - Traversal complete. Processed 76182 total reads in 0.1 minutes.\n",
      "17:20:59.643 INFO  BaseRecalibrator - Calculating quantized quality scores...\n",
      "17:20:59.652 INFO  BaseRecalibrator - Writing recalibration report...\n",
      "17:20:59.802 INFO  BaseRecalibrator - ...done!\n",
      "17:20:59.804 INFO  BaseRecalibrator - BaseRecalibrator was able to recalibrate 76182 reads\n",
      "17:20:59.804 INFO  BaseRecalibrator - Shutting down engine\n",
      "[November 13, 2024 at 5:20:59 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.16 minutes.\n",
      "Runtime.totalMemory()=1224736768\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# TODO: when I fix !$gatk IndexFeatureFile -I $ensembl_germline_vcf_filtered, add back --known-sites $ensembl_germline_vcf_filtered\n",
    "!$gatk BaseRecalibrator \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    --use-original-qualities \\\n",
    "    --known-sites $genomes1000_vcf \\\n",
    "    -O $recal_data_table\n",
    "\n",
    "# -known-sites ${dbSNP_vcf} \\\n",
    "# -known-sites ${sep=\" --known-sites \" known_indels_sites_VCFs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar ApplyBQSR --add-output-sam-program-record -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov14/alignment/split_n_cigar_reads.bam --use-original-qualities --bqsr-recal-file /home/jrich/data/varseek_data/gatk_nov14/alignment/recal_data.table -O /home/jrich/data/varseek_data/gatk_nov14/alignment/recalibrated.bam\n",
      "17:21:02.157 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:21:02.306 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "17:21:02.311 INFO  ApplyBQSR - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:21:02.311 INFO  ApplyBQSR - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:21:02.311 INFO  ApplyBQSR - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:21:02.311 INFO  ApplyBQSR - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:21:02.312 INFO  ApplyBQSR - Start Date/Time: November 13, 2024 at 5:21:02 PM PST\n",
      "17:21:02.312 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "17:21:02.312 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "17:21:02.313 INFO  ApplyBQSR - HTSJDK Version: 4.1.1\n",
      "17:21:02.313 INFO  ApplyBQSR - Picard Version: 3.2.0\n",
      "17:21:02.313 INFO  ApplyBQSR - Built for Spark Version: 3.5.0\n",
      "17:21:02.313 INFO  ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:21:02.314 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:21:02.314 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:21:02.314 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:21:02.314 INFO  ApplyBQSR - Deflater: IntelDeflater\n",
      "17:21:02.314 INFO  ApplyBQSR - Inflater: IntelInflater\n",
      "17:21:02.315 INFO  ApplyBQSR - GCS max retries/reopens: 20\n",
      "17:21:02.315 INFO  ApplyBQSR - Requester pays: disabled\n",
      "17:21:02.315 INFO  ApplyBQSR - Initializing engine\n",
      "17:21:02.510 INFO  ApplyBQSR - Done initializing engine\n",
      "17:21:02.569 INFO  ProgressMeter - Starting traversal\n",
      "17:21:02.570 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "17:21:04.347 INFO  ApplyBQSR - 0 read(s) filtered by: WellformedReadFilter \n",
      "\n",
      "17:21:04.348 INFO  ProgressMeter -          X:135482199              0.0                103693        3501170.5\n",
      "17:21:04.348 INFO  ProgressMeter - Traversal complete. Processed 103693 total reads in 0.0 minutes.\n",
      "17:21:04.399 INFO  ApplyBQSR - Shutting down engine\n",
      "[November 13, 2024 at 5:21:04 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.04 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "!$gatk ApplyBQSR \\\n",
    "    --add-output-sam-program-record \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    --use-original-qualities \\\n",
    "    --bqsr-recal-file $recal_data_table \\\n",
    "    -O $recalibrated_bam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. AnalyzeCovariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar AnalyzeCovariates -bqsr /home/jrich/data/varseek_data/gatk_nov14/alignment/recal_data.table -plots /home/jrich/data/varseek_data/gatk_nov14/alignment/AnalyzeCovariates.pdf\n",
      "17:21:06.375 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:21:06.528 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "17:21:06.533 INFO  AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:21:06.533 INFO  AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:21:06.534 INFO  AnalyzeCovariates - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:21:06.534 INFO  AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:21:06.534 INFO  AnalyzeCovariates - Start Date/Time: November 13, 2024 at 5:21:06 PM PST\n",
      "17:21:06.534 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "17:21:06.534 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "17:21:06.535 INFO  AnalyzeCovariates - HTSJDK Version: 4.1.1\n",
      "17:21:06.535 INFO  AnalyzeCovariates - Picard Version: 3.2.0\n",
      "17:21:06.536 INFO  AnalyzeCovariates - Built for Spark Version: 3.5.0\n",
      "17:21:06.536 INFO  AnalyzeCovariates - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:21:06.536 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:21:06.537 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:21:06.537 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:21:06.537 INFO  AnalyzeCovariates - Deflater: IntelDeflater\n",
      "17:21:06.537 INFO  AnalyzeCovariates - Inflater: IntelInflater\n",
      "17:21:06.537 INFO  AnalyzeCovariates - GCS max retries/reopens: 20\n",
      "17:21:06.538 INFO  AnalyzeCovariates - Requester pays: disabled\n",
      "17:21:06.538 INFO  AnalyzeCovariates - Initializing engine\n",
      "17:21:06.538 INFO  AnalyzeCovariates - Done initializing engine\n",
      "17:21:06.604 INFO  AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates429224007015058701.csv'\n",
      "17:21:06.636 INFO  AnalyzeCovariates - Generating plots file '/home/jrich/data/varseek_data/gatk_nov14/alignment/AnalyzeCovariates.pdf'\n",
      "17:21:07.161 INFO  AnalyzeCovariates - Shutting down engine\n",
      "[November 13, 2024 at 5:21:07 PM PST] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n",
      "org.broadinstitute.hellbender.utils.R.RScriptExecutorException: \n",
      "Rscript exited with 1\n",
      "Command Line: Rscript -e tempLibDir = '/tmp/Rlib.5481749819526362280';source('/tmp/BQSR.6628033901184511923.R'); /tmp/AnalyzeCovariates429224007015058701.csv /home/jrich/data/varseek_data/gatk_nov14/alignment/recal_data.table /home/jrich/data/varseek_data/gatk_nov14/alignment/AnalyzeCovariates.pdf\n",
      "Stdout: \n",
      "Stderr: Error in library(\"ggplot2\") : there is no package called ‘ggplot2’\n",
      "Calls: source -> withVisible -> eval -> eval -> library\n",
      "Execution halted\n",
      "\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:79)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:18)\n",
      "\tat org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:112)\n",
      "\tat org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:125)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329)\n",
      "\tat org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217)\n",
      "\tat org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166)\n",
      "\tat org.broadinstitute.hellbender.Main.mainEntry(Main.java:209)\n",
      "\tat org.broadinstitute.hellbender.Main.main(Main.java:306)\n"
     ]
    }
   ],
   "source": [
    "!$gatk AnalyzeCovariates \\\n",
    "    -bqsr $recal_data_table \\\n",
    "    -plots $covariates_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8a. HaplotypeCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar HaplotypeCaller -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov14/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz --standard-min-confidence-threshold-for-calling 20 -dont-use-soft-clipped-bases\n",
      "17:21:09.266 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:21:09.420 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "17:21:09.424 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:21:09.424 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:21:09.424 INFO  HaplotypeCaller - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:21:09.424 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:21:09.425 INFO  HaplotypeCaller - Start Date/Time: November 13, 2024 at 5:21:09 PM PST\n",
      "17:21:09.425 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "17:21:09.425 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "17:21:09.426 INFO  HaplotypeCaller - HTSJDK Version: 4.1.1\n",
      "17:21:09.426 INFO  HaplotypeCaller - Picard Version: 3.2.0\n",
      "17:21:09.426 INFO  HaplotypeCaller - Built for Spark Version: 3.5.0\n",
      "17:21:09.427 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:21:09.427 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:21:09.427 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:21:09.427 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:21:09.428 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "17:21:09.428 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "17:21:09.428 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "17:21:09.428 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "17:21:09.428 INFO  HaplotypeCaller - Initializing engine\n",
      "17:21:09.604 INFO  HaplotypeCaller - Done initializing engine\n",
      "17:21:09.620 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "17:21:09.623 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "17:21:09.625 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "17:21:09.625 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "17:21:09.627 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "17:21:09.636 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "17:21:09.693 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "17:21:09.694 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "17:21:09.696 INFO  IntelPairHmm - Available threads: 88\n",
      "17:21:09.696 INFO  IntelPairHmm - Requested threads: 4\n",
      "17:21:09.696 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "17:21:09.763 INFO  ProgressMeter - Starting traversal\n",
      "17:21:09.764 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "17:21:11.407 WARN  InbreedingCoeff - InbreedingCoeff will not be calculated at position 1:3699235 and possibly subsequent; at least 10 samples must have called genotypes\n",
      "17:21:19.764 INFO  ProgressMeter -           1:56850774              0.2                189530        1137180.0\n",
      "17:21:29.764 INFO  ProgressMeter -          1:126840699              0.3                422850        1268550.0\n",
      "17:21:39.764 INFO  ProgressMeter -          1:195608912              0.5                652100        1304200.0\n",
      "17:21:49.765 INFO  ProgressMeter -           10:8616170              0.7                859660        1289457.8\n",
      "17:21:59.765 INFO  ProgressMeter -          10:70262412              0.8               1065160        1278166.4\n",
      "17:22:09.765 INFO  ProgressMeter -         10:127423091              1.0               1255700        1255679.1\n",
      "17:22:19.765 INFO  ProgressMeter -          11:54746033              1.2               1465250        1255910.6\n",
      "17:22:29.765 INFO  ProgressMeter -         11:115088491              1.3               1666410        1249791.9\n",
      "17:22:39.765 INFO  ProgressMeter -          12:40374384              1.5               1867390        1244912.8\n",
      "17:22:49.765 INFO  ProgressMeter -         12:100904656              1.7               2069170        1241489.6\n",
      "17:22:59.765 INFO  ProgressMeter -          13:28659901              1.8               2274550        1240652.4\n",
      "17:23:09.765 INFO  ProgressMeter -          13:87192697              2.0               2469670        1234824.7\n",
      "17:23:19.765 INFO  ProgressMeter -          14:30935226              2.2               2666050        1230475.2\n",
      "17:23:29.765 INFO  ProgressMeter -          14:94494932              2.3               2877920        1233385.5\n",
      "17:23:39.765 INFO  ProgressMeter -          15:52283565              2.5               3095060        1238015.7\n",
      "17:23:49.765 INFO  ProgressMeter -          16:13179301              2.7               3306500        1239929.8\n",
      "17:23:59.765 INFO  ProgressMeter -          16:77592524              2.8               3521230        1242779.7\n",
      "17:24:09.765 INFO  ProgressMeter -          17:51064724              3.0               3734020        1244666.4\n",
      "17:24:19.765 INFO  ProgressMeter -          18:33281748              3.2               3945410        1245912.4\n",
      "17:24:29.765 INFO  ProgressMeter -           19:4899430              3.3               4111070        1233314.8\n",
      "17:24:39.765 INFO  ProgressMeter -            2:1971601              3.5               4298460        1228125.6\n",
      "17:24:49.765 INFO  ProgressMeter -           2:65848777              3.7               4511390        1230373.5\n",
      "17:24:59.766 INFO  ProgressMeter -          2:127344121              3.8               4716380        1230354.7\n",
      "17:25:09.765 INFO  ProgressMeter -          2:188213906              4.0               4919290        1229817.4\n",
      "17:25:19.765 INFO  ProgressMeter -           20:4794301              4.2               5118580        1228454.3\n",
      "17:25:29.765 INFO  ProgressMeter -          20:62997614              4.3               5312610        1225982.2\n",
      "17:25:39.765 INFO  ProgressMeter -          22:12222601              4.5               5513890        1225304.4\n",
      "17:25:49.765 INFO  ProgressMeter -           3:25372616              4.7               5728750        1227584.9\n",
      "17:25:59.765 INFO  ProgressMeter -           3:88185203              4.8               5938150        1228578.5\n",
      "17:26:09.765 INFO  ProgressMeter -          3:151694020              5.0               6149850        1229965.9\n",
      "17:26:19.765 INFO  ProgressMeter -           4:16403724              5.2               6358980        1230766.4\n",
      "17:26:29.765 INFO  ProgressMeter -           4:78425015              5.3               6565730        1231070.5\n",
      "17:26:39.765 INFO  ProgressMeter -          4:142948522              5.5               6780820        1232872.6\n",
      "17:26:49.765 INFO  ProgressMeter -           5:13112101              5.7               6985220        1232682.3\n",
      "17:26:59.765 INFO  ProgressMeter -           5:78836864              5.8               7204310        1235021.0\n",
      "17:27:09.765 INFO  ProgressMeter -          5:141984138              6.0               7414820        1235799.9\n",
      "17:27:19.765 INFO  ProgressMeter -           6:26114016              6.2               7631650        1237561.5\n",
      "17:27:29.765 INFO  ProgressMeter -           6:80422098              6.3               7812690        1233579.4\n",
      "17:27:39.765 INFO  ProgressMeter -          6:141873870              6.5               8017530        1233463.0\n",
      "17:27:49.765 INFO  ProgressMeter -           7:32331319              6.7               8222800        1233416.9\n",
      "17:27:59.765 INFO  ProgressMeter -           7:96201319              6.8               8435700        1234489.7\n",
      "17:28:09.765 INFO  ProgressMeter -          7:158648305              7.0               8643880        1234837.1\n",
      "17:28:19.765 INFO  ProgressMeter -           8:66933971              7.2               8868640        1237481.8\n",
      "17:28:29.765 INFO  ProgressMeter -          8:131238971              7.3               9082990        1238586.7\n",
      "17:28:39.765 INFO  ProgressMeter -           9:49809590              7.5               9299450        1239923.9\n",
      "17:28:49.765 INFO  ProgressMeter -          9:113975879              7.7               9513340        1240867.7\n",
      "17:28:59.765 INFO  ProgressMeter -           X:38338049              7.8               9732000        1242380.3\n",
      "17:29:09.765 INFO  ProgressMeter -          X:101333063              8.0               9942000        1242747.4\n",
      "17:29:19.765 INFO  ProgressMeter -            Y:6399001              8.2              10143130        1242013.4\n",
      "17:29:29.765 INFO  ProgressMeter -     GL000199.1:45301              8.3              10330250        1239627.5\n",
      "17:29:30.281 INFO  HaplotypeCaller - 241 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "27436 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "27677 total reads filtered out of 103693 reads processed\n",
      "17:29:30.281 INFO  ProgressMeter -      GL000207.1:1501              8.3              10340109        1239531.4\n",
      "17:29:30.281 INFO  ProgressMeter - Traversal complete. Processed 10340109 total regions in 8.3 minutes.\n",
      "17:29:30.302 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.015703222\n",
      "17:29:30.302 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.193217087\n",
      "17:29:30.302 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.06 sec\n",
      "17:29:30.303 INFO  HaplotypeCaller - Shutting down engine\n",
      "[November 13, 2024 at 5:29:30 PM PST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 8.35 minutes.\n",
      "Runtime.totalMemory()=1761607680\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!$gatk --java-options \"-Xmx4g\" HaplotypeCaller  \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $haplotypecaller_unfiltered_vcf \\\n",
    "    --standard-min-confidence-threshold-for-calling 20 \\\n",
    "    -dont-use-soft-clipped-bases \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.5a. MergeVcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_vcf = haplotypecaller_merged.vcf\n",
    "# \n",
    "# !$java -jar $picard_jar MergeVcfs \\\n",
    "#     --INPUT $vcf1 \\\n",
    "#     --INPUT $vcf2 \\\n",
    "#     --OUTPUT $merged_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9a. VariantFiltration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar VariantFiltration -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz --window 35 --cluster 3 --filter-name FS --filter FS > 30.0 --filter-name QD --filter QD < 2.0\n",
      "17:29:32.759 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:29:32.909 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "17:29:32.914 INFO  VariantFiltration - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:29:32.914 INFO  VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:29:32.914 INFO  VariantFiltration - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:29:32.915 INFO  VariantFiltration - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:29:32.915 INFO  VariantFiltration - Start Date/Time: November 13, 2024 at 5:29:32 PM PST\n",
      "17:29:32.915 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "17:29:32.915 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "17:29:32.916 INFO  VariantFiltration - HTSJDK Version: 4.1.1\n",
      "17:29:32.916 INFO  VariantFiltration - Picard Version: 3.2.0\n",
      "17:29:32.916 INFO  VariantFiltration - Built for Spark Version: 3.5.0\n",
      "17:29:32.917 INFO  VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:29:32.917 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:29:32.917 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:29:32.917 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:29:32.918 INFO  VariantFiltration - Deflater: IntelDeflater\n",
      "17:29:32.918 INFO  VariantFiltration - Inflater: IntelInflater\n",
      "17:29:32.918 INFO  VariantFiltration - GCS max retries/reopens: 20\n",
      "17:29:32.918 INFO  VariantFiltration - Requester pays: disabled\n",
      "17:29:32.919 INFO  VariantFiltration - Initializing engine\n",
      "17:29:33.095 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz\n",
      "17:29:33.173 INFO  VariantFiltration - Done initializing engine\n",
      "17:29:33.304 INFO  ProgressMeter - Starting traversal\n",
      "17:29:33.305 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "17:29:33.432 INFO  ProgressMeter -             unmapped              0.0                   198          93543.3\n",
      "17:29:33.433 INFO  ProgressMeter - Traversal complete. Processed 198 total variants in 0.0 minutes.\n",
      "17:29:33.455 INFO  VariantFiltration - Shutting down engine\n",
      "[November 13, 2024 at 5:29:33 PM PST] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# cosmic_vcf = \"\"\n",
    "\n",
    "!$gatk VariantFiltration \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $haplotypecaller_unfiltered_vcf \\\n",
    "    -O $haplotypecaller_filtered_vcf \\\n",
    "    --window 35 \\\n",
    "    --cluster 3 \\\n",
    "    --filter-name \"FS\" \\\n",
    "    --filter \"FS > 30.0\" \\\n",
    "    --filter-name \"QD\" \\\n",
    "    --filter \"QD < 2.0\"\n",
    "\n",
    "    # --mask $cosmic_vcf \\\n",
    "    # --mask-name \"COSMIC\" \\\n",
    "    # --filter-not-in-mask \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10a. Do the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar SelectVariants -V /home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz --exclude-filtered true -O /home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_filtered_applied.vcf.gz\n",
      "17:29:35.629 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:29:35.778 INFO  SelectVariants - ------------------------------------------------------------\n",
      "17:29:35.783 INFO  SelectVariants - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:29:35.783 INFO  SelectVariants - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:29:35.783 INFO  SelectVariants - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:29:35.783 INFO  SelectVariants - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:29:35.783 INFO  SelectVariants - Start Date/Time: November 13, 2024 at 5:29:35 PM PST\n",
      "17:29:35.784 INFO  SelectVariants - ------------------------------------------------------------\n",
      "17:29:35.784 INFO  SelectVariants - ------------------------------------------------------------\n",
      "17:29:35.785 INFO  SelectVariants - HTSJDK Version: 4.1.1\n",
      "17:29:35.785 INFO  SelectVariants - Picard Version: 3.2.0\n",
      "17:29:35.785 INFO  SelectVariants - Built for Spark Version: 3.5.0\n",
      "17:29:35.785 INFO  SelectVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:29:35.785 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:29:35.786 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:29:35.786 INFO  SelectVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:29:35.786 INFO  SelectVariants - Deflater: IntelDeflater\n",
      "17:29:35.786 INFO  SelectVariants - Inflater: IntelInflater\n",
      "17:29:35.786 INFO  SelectVariants - GCS max retries/reopens: 20\n",
      "17:29:35.787 INFO  SelectVariants - Requester pays: disabled\n",
      "17:29:35.787 INFO  SelectVariants - Initializing engine\n",
      "17:29:35.923 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov14/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz\n",
      "17:29:35.996 INFO  SelectVariants - Done initializing engine\n",
      "17:29:36.032 INFO  ProgressMeter - Starting traversal\n",
      "17:29:36.033 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "17:29:36.105 INFO  ProgressMeter -             unmapped              0.0                   198         167323.9\n",
      "17:29:36.105 INFO  ProgressMeter - Traversal complete. Processed 198 total variants in 0.0 minutes.\n",
      "17:29:36.131 INFO  SelectVariants - Shutting down engine\n",
      "[November 13, 2024 at 5:29:36 PM PST] org.broadinstitute.hellbender.tools.walkers.variantutils.SelectVariants done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "!$gatk SelectVariants \\\n",
    "     -V $haplotypecaller_filtered_vcf \\\n",
    "     --exclude-filtered true \\\n",
    "     -O $haplotypecaller_filtered_applied_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8b. Mutect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar Mutect2 -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk_nov14/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk_nov14/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz --min-base-quality-score 20\n",
      "17:55:14.532 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "17:55:14.684 INFO  Mutect2 - ------------------------------------------------------------\n",
      "17:55:14.688 INFO  Mutect2 - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "17:55:14.689 INFO  Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "17:55:14.689 INFO  Mutect2 - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "17:55:14.689 INFO  Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "17:55:14.689 INFO  Mutect2 - Start Date/Time: November 13, 2024 at 5:55:14 PM PST\n",
      "17:55:14.689 INFO  Mutect2 - ------------------------------------------------------------\n",
      "17:55:14.689 INFO  Mutect2 - ------------------------------------------------------------\n",
      "17:55:14.690 INFO  Mutect2 - HTSJDK Version: 4.1.1\n",
      "17:55:14.691 INFO  Mutect2 - Picard Version: 3.2.0\n",
      "17:55:14.691 INFO  Mutect2 - Built for Spark Version: 3.5.0\n",
      "17:55:14.691 INFO  Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "17:55:14.691 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "17:55:14.692 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "17:55:14.692 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "17:55:14.692 INFO  Mutect2 - Deflater: IntelDeflater\n",
      "17:55:14.692 INFO  Mutect2 - Inflater: IntelInflater\n",
      "17:55:14.693 INFO  Mutect2 - GCS max retries/reopens: 20\n",
      "17:55:14.693 INFO  Mutect2 - Requester pays: disabled\n",
      "17:55:14.693 INFO  Mutect2 - Initializing engine\n",
      "17:55:14.861 INFO  Mutect2 - Done initializing engine\n",
      "17:55:14.870 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "17:55:14.872 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "17:55:14.874 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "17:55:14.874 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "17:55:14.883 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "17:55:14.910 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "17:55:14.910 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "17:55:14.910 INFO  IntelPairHmm - Available threads: 88\n",
      "17:55:14.910 INFO  IntelPairHmm - Requested threads: 4\n",
      "17:55:14.910 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "17:55:14.947 INFO  ProgressMeter - Starting traversal\n",
      "17:55:14.947 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "17:55:24.947 INFO  ProgressMeter -           1:48842561              0.2                162840         977040.0\n",
      "17:55:34.947 INFO  ProgressMeter -          1:105536689              0.3                351840        1055520.0\n",
      "17:55:44.947 INFO  ProgressMeter -          1:163582644              0.5                545350        1090700.0\n",
      "17:55:54.947 INFO  ProgressMeter -          1:221838859              0.7                739550        1109325.0\n",
      "17:56:04.947 INFO  ProgressMeter -          10:21534275              0.8                902740        1083288.0\n",
      "17:56:14.947 INFO  ProgressMeter -          10:76731996              1.0               1086740        1086740.0\n",
      "17:56:24.947 INFO  ProgressMeter -         10:125880178              1.2               1250570        1071917.1\n",
      "17:56:34.947 INFO  ProgressMeter -          11:41412218              1.3               1420810        1065607.5\n",
      "17:56:44.948 INFO  ProgressMeter -          11:84792166              1.5               1565430        1043620.0\n",
      "17:56:54.948 INFO  ProgressMeter -         11:130188678              1.7               1716760        1030056.0\n",
      "17:57:04.947 INFO  ProgressMeter -          12:49762571              1.8               1898700        1035654.5\n",
      "17:57:14.947 INFO  ProgressMeter -         12:101667843              2.0               2071730        1035865.0\n",
      "17:57:24.947 INFO  ProgressMeter -          13:20113501              2.2               2246080        1036652.3\n",
      "17:57:34.947 INFO  ProgressMeter -          13:73620384              2.3               2424450        1039050.0\n",
      "17:57:44.947 INFO  ProgressMeter -           14:4287301              2.5               2577240        1030896.0\n",
      "17:57:54.953 INFO  ProgressMeter -          14:59061319              2.7               2759830        1034897.4\n",
      "17:58:04.953 INFO  ProgressMeter -           15:5112301              2.8               2937840        1036848.1\n",
      "17:58:14.953 INFO  ProgressMeter -          15:60199952              3.0               3121470        1040455.3\n",
      "17:58:24.953 INFO  ProgressMeter -           16:8216401              3.2               3289980        1038908.2\n",
      "17:58:34.953 INFO  ProgressMeter -          16:64349382              3.3               3477100        1043098.7\n",
      "17:58:44.953 INFO  ProgressMeter -          17:29502601              3.5               3662140        1046295.8\n",
      "17:58:54.953 INFO  ProgressMeter -           18:3565201              3.7               3846370        1048981.4\n",
      "17:59:04.953 INFO  ProgressMeter -          18:57862548              3.8               4027370        1050590.9\n",
      "17:59:14.953 INFO  ProgressMeter -          19:30936487              4.0               4197910        1049451.3\n",
      "17:59:24.953 INFO  ProgressMeter -           2:26457564              4.2               4380120        1051203.6\n",
      "17:59:34.953 INFO  ProgressMeter -           2:79759932              4.3               4557800        1051775.7\n",
      "17:59:44.953 INFO  ProgressMeter -          2:132670008              4.5               4734170        1052014.4\n",
      "17:59:54.953 INFO  ProgressMeter -          2:185886206              4.7               4911570        1052456.7\n",
      "18:00:04.953 INFO  ProgressMeter -          2:238523703              4.8               5087050        1052471.3\n",
      "18:00:14.953 INFO  ProgressMeter -          20:50025599              5.0               5269410        1053860.9\n",
      "18:00:24.953 INFO  ProgressMeter -          21:39081731              5.2               5443030        1053469.3\n",
      "18:00:34.956 INFO  ProgressMeter -          22:47252928              5.3               5630710        1055728.4\n",
      "18:00:44.956 INFO  ProgressMeter -           3:50574701              5.5               5812820        1056847.5\n",
      "18:00:54.956 INFO  ProgressMeter -          3:103255405              5.7               5988430        1056753.8\n",
      "18:01:04.956 INFO  ProgressMeter -          3:157276689              5.8               6168520        1057433.4\n",
      "18:01:14.956 INFO  ProgressMeter -           4:13036824              6.0               6347810        1057941.9\n",
      "18:01:24.956 INFO  ProgressMeter -           4:69536704              6.2               6536150        1059890.4\n",
      "18:01:34.956 INFO  ProgressMeter -          4:122922322              6.3               6714120        1060099.1\n",
      "18:01:44.956 INFO  ProgressMeter -          4:175977945              6.5               6890980        1060126.3\n",
      "18:01:54.956 INFO  ProgressMeter -           5:40441602              6.7               7076380        1061433.1\n",
      "18:02:04.956 INFO  ProgressMeter -           5:95488364              6.8               7259870        1062396.7\n",
      "18:02:14.956 INFO  ProgressMeter -          5:148711038              7.0               7437300        1062448.7\n",
      "18:02:24.956 INFO  ProgressMeter -           6:21777301              7.2               7617250        1062849.8\n",
      "18:02:34.956 INFO  ProgressMeter -           6:76815318              7.3               7800720        1063712.8\n",
      "18:02:44.956 INFO  ProgressMeter -          6:130336770              7.5               7979130        1063862.7\n",
      "18:02:54.956 INFO  ProgressMeter -           7:11136374              7.7               8152190        1063308.3\n",
      "18:03:04.956 INFO  ProgressMeter -           7:67657206              7.8               8340610        1064738.3\n",
      "18:03:14.956 INFO  ProgressMeter -          7:119608206              8.0               8513780        1064202.5\n",
      "18:03:24.956 INFO  ProgressMeter -           8:13731632              8.2               8691350        1064227.4\n",
      "18:03:34.956 INFO  ProgressMeter -           8:69654958              8.3               8877770        1065313.2\n",
      "18:03:44.956 INFO  ProgressMeter -          8:120240958              8.5               9046390        1064262.4\n",
      "18:03:54.956 INFO  ProgressMeter -           9:29129226              8.7               9230570        1065047.3\n",
      "18:04:04.958 INFO  ProgressMeter -           9:69197677              8.8               9364140        1060071.3\n",
      "18:04:14.958 INFO  ProgressMeter -          9:107455979              9.0               9491670        1054610.5\n",
      "18:04:24.957 INFO  ProgressMeter -           X:16054776              9.2               9657780        1053556.8\n",
      "18:04:34.958 INFO  ProgressMeter -           X:70815327              9.3               9840330        1054302.2\n",
      "18:04:44.957 INFO  ProgressMeter -          X:122521851              9.5              10012700        1053949.9\n",
      "18:04:54.957 INFO  ProgressMeter -           Y:17685901              9.7              10180820        1053170.1\n",
      "18:05:04.894 INFO  Mutect2 - 241 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "27436 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: ReadLengthReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "27677 total reads filtered out of 103693 reads processed\n",
      "18:05:04.894 INFO  ProgressMeter -      GL000207.1:2401              9.8              10340176        1051637.8\n",
      "18:05:04.894 INFO  ProgressMeter - Traversal complete. Processed 10340176 total regions in 9.8 minutes.\n",
      "18:05:04.920 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.014706173000000001\n",
      "18:05:04.920 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.18054360700000002\n",
      "18:05:04.920 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.05 sec\n",
      "18:05:04.921 INFO  Mutect2 - Shutting down engine\n",
      "[November 13, 2024 at 6:05:04 PM PST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 9.84 minutes.\n",
      "Runtime.totalMemory()=2751463424\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# consider adding --disable-read-filter\n",
    "# TODO: add --panel-of-normals $panel_of_normals_vcf_filtered once I install bgzip\n",
    "!$gatk Mutect2 \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $mutect2_unfiltered_vcf \\\n",
    "    --min-base-quality-score 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9b. FilterMutectCalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar FilterMutectCalls -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk_nov14/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk_nov14/vcfs/mutect2/mutect2_output_filtered.vcf.gz\n",
      "18:05:07.315 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "18:05:07.462 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "18:05:07.466 INFO  FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "18:05:07.466 INFO  FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "18:05:07.466 INFO  FilterMutectCalls - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "18:05:07.467 INFO  FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "18:05:07.467 INFO  FilterMutectCalls - Start Date/Time: November 13, 2024 at 6:05:07 PM PST\n",
      "18:05:07.467 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "18:05:07.467 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "18:05:07.468 INFO  FilterMutectCalls - HTSJDK Version: 4.1.1\n",
      "18:05:07.468 INFO  FilterMutectCalls - Picard Version: 3.2.0\n",
      "18:05:07.469 INFO  FilterMutectCalls - Built for Spark Version: 3.5.0\n",
      "18:05:07.469 INFO  FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "18:05:07.469 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "18:05:07.469 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "18:05:07.470 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "18:05:07.470 INFO  FilterMutectCalls - Deflater: IntelDeflater\n",
      "18:05:07.470 INFO  FilterMutectCalls - Inflater: IntelInflater\n",
      "18:05:07.470 INFO  FilterMutectCalls - GCS max retries/reopens: 20\n",
      "18:05:07.470 INFO  FilterMutectCalls - Requester pays: disabled\n",
      "18:05:07.471 INFO  FilterMutectCalls - Initializing engine\n",
      "18:05:07.644 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk_nov14/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz\n",
      "18:05:07.722 INFO  FilterMutectCalls - Done initializing engine\n",
      "18:05:07.790 INFO  ProgressMeter - Starting traversal\n",
      "18:05:07.792 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "18:05:07.795 INFO  FilterMutectCalls - Starting pass 0 through the variants\n",
      "18:05:08.078 INFO  FilterMutectCalls - Finished pass 0 through the variants\n",
      "18:05:08.139 INFO  FilterMutectCalls - Starting pass 1 through the variants\n",
      "18:05:08.220 INFO  FilterMutectCalls - Finished pass 1 through the variants\n",
      "18:05:08.236 INFO  FilterMutectCalls - Starting pass 2 through the variants\n",
      "18:05:08.297 INFO  FilterMutectCalls - Finished pass 2 through the variants\n",
      "18:05:08.297 INFO  FilterMutectCalls - Starting pass 3 through the variants\n",
      "18:05:08.412 INFO  FilterMutectCalls - Finished pass 3 through the variants\n",
      "18:05:08.418 INFO  FilterMutectCalls - No variants filtered by: AllowAllVariantsVariantFilter\n",
      "18:05:08.419 INFO  FilterMutectCalls - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "18:05:08.419 INFO  ProgressMeter -             unmapped              0.0                   784          75023.9\n",
      "18:05:08.419 INFO  ProgressMeter - Traversal complete. Processed 784 total variants in 0.0 minutes.\n",
      "18:05:08.438 INFO  FilterMutectCalls - Shutting down engine\n",
      "[November 13, 2024 at 6:05:08 PM PST] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.02 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# # if multiple stats files:\n",
    "# !$gatk MergeMutectStats -stats unfiltered1.vcf.stats -stats unfiltered2.vcf.stats -O unfiltered.vcf.stats\n",
    "\n",
    "# stats_file = f\"{mutect2_unfiltered_vcf}.stats\"\n",
    "# --stats $stats_file\n",
    "!$gatk FilterMutectCalls \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $mutect2_unfiltered_vcf \\\n",
    "    -O $mutect2_filtered_vcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_sample_vcf(output_path):\n",
    "#     with open(output_path, \"w\") as vcf_file:\n",
    "#         # Write VCF headers\n",
    "#         vcf_file.write(\"##fileformat=VCFv4.2\\n\")\n",
    "#         vcf_file.write(\"##source=SampleVCFGenerator\\n\")\n",
    "#         vcf_file.write(\"##reference=GRCh37\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=DP,Number=1,Type=Integer,Description=\\\"Total Depth\\\">\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=AF,Number=A,Type=Float,Description=\\\"Allele Frequency\\\">\\n\")\n",
    "#         vcf_file.write(\"##FILTER=<ID=PASS,Description=\\\"All filters passed\\\">\\n\")\n",
    "#         vcf_file.write(\"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\")\n",
    "#         vcf_file.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tsample1\\n\")\n",
    "        \n",
    "#         # Write sample variant entries\n",
    "#         variants = [\n",
    "#             (\"1\", 123456, \".\", \"G\", \"A\", 50, \"PASS\", \"DP=100;AF=0.5\", \"GT\", \"0/1\"),\n",
    "#             (\"1\", 234567, \".\", \"C\", \"T\", 60, \"PASS\", \"DP=200;AF=0.3\", \"GT\", \"1/1\"),\n",
    "#             (\"2\", 345678, \".\", \"T\", \"G\", 70, \"PASS\", \"DP=150;AF=0.1\", \"GT\", \"0/1\"),\n",
    "#             (\"X\", 456789, \".\", \"A\", \"C\", 80, \"PASS\", \"DP=120;AF=0.05\", \"GT\", \"0/0\")\n",
    "#         ]\n",
    "        \n",
    "#         for chrom, pos, var_id, ref, alt, qual, fltr, info, fmt, sample in variants:\n",
    "#             vcf_file.write(f\"{chrom}\\t{pos}\\t{var_id}\\t{ref}\\t{alt}\\t{qual}\\t{fltr}\\t{info}\\t{fmt}\\t{sample}\\n\")\n",
    "\n",
    "# # Usage\n",
    "# create_sample_vcf(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")\n",
    "\n",
    "# df_sample = vcf_to_dataframe(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JUMP TO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert gatk output vcf to pandas df\n",
    "def vcf_to_dataframe(vcf_file):\n",
    "    \"\"\"Convert a VCF file to a Pandas DataFrame.\"\"\"\n",
    "    vcf = pysam.VariantFile(vcf_file)\n",
    "    \n",
    "    # List to store VCF rows\n",
    "    vcf_data = []\n",
    "    \n",
    "    # Fetch each record in the VCF\n",
    "    for record in vcf.fetch():\n",
    "        # For each record, extract the desired fields\n",
    "        vcf_row = {\n",
    "            'CHROM': record.chrom,\n",
    "            'POS': record.pos,\n",
    "            'ID': record.id,\n",
    "            'REF': record.ref,\n",
    "            'ALT': ','.join(record.alts),  # ALT can be multiple\n",
    "        }\n",
    "        \n",
    "        # Append the row to the list\n",
    "        vcf_data.append(vcf_row)\n",
    "    \n",
    "    # Convert the list to a Pandas DataFrame\n",
    "    df = pd.DataFrame(vcf_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert VCF to DataFrame\n",
    "df_hap = vcf_to_dataframe(haplotypecaller_filtered_applied_vcf)\n",
    "df_mut = vcf_to_dataframe(mutect2_filtered_vcf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in COSMIC tsv with columns CHROM, POS, ID, REF, ALT\n",
    "cosmic_df = pd.read_csv(cosmic_tsv, sep=\"\\t\", usecols=[\"Mutation genome position GRCh37\", \"GENOMIC_WT_ALLELE_SEQ\", \"GENOMIC_MUT_ALLELE_SEQ\", \"ACCESSION_NUMBER\", \"Mutation CDS\", \"MUTATION_URL\"])\n",
    "\n",
    "if mutation_source == \"cdna\":\n",
    "    cosmic_cdna_info_df = pd.read_csv(cosmic_cdna_info_csv, usecols=[\"mutation_id\", \"mutation\"])\n",
    "    cosmic_cdna_info_df = cosmic_cdna_info_df.rename(columns={\"mutation\": \"Mutation cDNA\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df = add_mutation_type(cosmic_df, \"Mutation CDS\")\n",
    "\n",
    "cosmic_df[\"ACCESSION_NUMBER\"] = cosmic_df[\"ACCESSION_NUMBER\"].str.split(\".\").str[0]\n",
    "\n",
    "cosmic_df[['CHROM', 'GENOME_POS']] = cosmic_df['Mutation genome position GRCh37'].str.split(':', expand=True)\n",
    "# cosmic_df['CHROM'] = cosmic_df['CHROM'].apply(convert_chromosome_value_to_int_when_possible)\n",
    "cosmic_df[['POS', 'GENOME_END_POS']] = cosmic_df['GENOME_POS'].str.split('-', expand=True)\n",
    "\n",
    "cosmic_df = cosmic_df.rename(\n",
    "    columns={\n",
    "        \"GENOMIC_WT_ALLELE_SEQ\": \"REF\",\n",
    "        \"GENOMIC_MUT_ALLELE_SEQ\": \"ALT\",\n",
    "        \"MUTATION_URL\": \"mutation_id\"\n",
    "    }\n",
    ")\n",
    "\n",
    "if mutation_source == \"cds\":\n",
    "    cosmic_df['ID'] = cosmic_df['ACCESSION_NUMBER'] + \":\" + cosmic_df['Mutation CDS']\n",
    "elif mutation_source == \"cdna\":\n",
    "    cosmic_df[\"mutation_id\"] = cosmic_df[\"mutation_id\"].str.extract(r\"id=(\\d+)\")\n",
    "    cosmic_df['mutation_id'] = cosmic_df['mutation_id'].astype(int, errors='raise')\n",
    "    cosmic_df = cosmic_df.merge(cosmic_cdna_info_df[['mutation_id', 'Mutation cDNA']], on='mutation_id', how='left')\n",
    "    cosmic_df['ID'] = cosmic_df['ACCESSION_NUMBER'] + \":\" + cosmic_df['Mutation cDNA']\n",
    "    cosmic_df.drop(columns=[\"Mutation cDNA\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145075/2323330122.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf_df = pd.read_csv(reference_genome_gtf, sep='\\t', comment='#', header=None, names=[\n"
     ]
    }
   ],
   "source": [
    "# # commented out because this was only used when considering strand below for reverse-complementing, but the line below is irrelevant now\n",
    "# gtf_df = pd.read_csv(reference_genome_gtf, sep='\\t', comment='#', header=None, names=[\n",
    "# 'seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'])\n",
    "\n",
    "# gtf_df = gtf_df[gtf_df['feature'] == 'transcript']\n",
    "\n",
    "# gtf_df['transcript_id'] = gtf_df['attribute'].str.extract('transcript_id \"([^\"]+)\"')\n",
    "\n",
    "# gtf_df = gtf_df.dropna(subset=['transcript_id'])\n",
    "\n",
    "# gtf_df = gtf_df[['transcript_id', 'strand']].rename(\n",
    "#     columns={'transcript_id': 'ACCESSION_NUMBER'})\n",
    "\n",
    "# cosmic_df = pd.merge(cosmic_df, gtf_df, on='ACCESSION_NUMBER', how='left')\n",
    "# cosmic_df['strand'] = cosmic_df['strand'].fillna('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df = cosmic_df.dropna(subset=['CHROM', 'POS'])\n",
    "cosmic_df = cosmic_df.dropna(subset=['ID'])  # a result of intron mutations and COSMIC duplicates that get dropped before cDNA determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15776/15776 [00:00<00:00, 58213.07it/s]\n",
      "100%|██████████| 120017/120017 [00:01<00:00, 78237.73it/s]\n",
      "1it [00:00, 1311.95it/s]\n",
      "1it [00:00, 2912.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# reference_genome_fasta\n",
    "reference_genome = pysam.FastaFile(reference_genome_fasta)\n",
    "\n",
    "def get_nucleotide_from_reference(chromosome, position):\n",
    "    # pysam is 0-based, so subtract 1 from the position\n",
    "    return reference_genome.fetch(chromosome, int(position) - 1, int(position))\n",
    "\n",
    "def get_complement(nucleotide_sequence):\n",
    "    return ''.join([complement[nuc] for nuc in nucleotide_sequence])\n",
    "\n",
    "# Insertion, get original nucleotide (not in COSMIC df)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'insertion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'insertion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['POS'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Deletion, get new nucleotide (not in COSMIC df)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['POS']) - 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Duplication\n",
    "cosmic_df.loc[cosmic_df['mutation_type'] == 'duplication', 'original_nucleotide'] = cosmic_df.loc[cosmic_df['ID'].str.contains('dup', na=False), 'ALT'].str[-1]\n",
    "\n",
    "# deal with start of 1, insertion\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'insertion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'insertion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['GENOME_END_POS'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# deal with start of 1, deletion\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['GENOME_END_POS']) + 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# # deal with (-) strand - commented out because the vcf should all be relative to the forward strand, not the cdna\n",
    "# cosmic_df.loc[cosmic_df['strand'] == '-', 'original_nucleotide'] = cosmic_df.loc[cosmic_df['strand'] == '-', 'original_nucleotide'].apply(get_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ins and dup, starting position not 1\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'ref_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'alt_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide'] + cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'ALT']\n",
    "\n",
    "# ins and dup, starting position 1\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'ref_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'alt_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'ALT'] + cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "\n",
    "\n",
    "# del, starting position not 1\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'ref_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide'] + cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'REF']\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'alt_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide']\n",
    "\n",
    "# del, starting position 1\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'ref_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'REF'] + cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'alt_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120017/120017 [00:00<00:00, 822792.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Deletion, update position (should refer to 1 BEFORE the deletion)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), 'POS'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), 'POS'\n",
    "].progress_apply(\n",
    "    lambda pos: int(pos) - 1\n",
    ")\n",
    "\n",
    "# deal with start of 1, deletion update position (should refer to 1 after the deletion)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), 'POS'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), 'GENOME_END_POS'\n",
    "].astype(int) + 1\n",
    "\n",
    "# Insertion, update position when pos=1 (should refer to 1)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'insertion'), 'POS'\n",
    "] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df['ref_updated'] = cosmic_df['ref_updated'].fillna(cosmic_df['REF'])\n",
    "cosmic_df['alt_updated'] = cosmic_df['alt_updated'].fillna(cosmic_df['ALT'])\n",
    "cosmic_df.rename(columns={'ALT': 'alt_cosmic', 'alt_updated': 'ALT', 'REF': 'ref_cosmic', 'ref_updated': 'REF'}, inplace=True)\n",
    "cosmic_df.drop(columns=[\"Mutation genome position GRCh37\", \"GENOME_POS\", \"GENOME_END_POS\", \"ACCESSION_NUMBER\", \"Mutation CDS\", \"mutation_id\", 'ref_cosmic', 'alt_cosmic', 'original_nucleotide', 'mutation_type'], inplace=True)  # 'strand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_with_na = cosmic_df.isna().any(axis=1).sum()\n",
    "assert num_rows_with_na == 0, f\"Number of rows with NA values: {num_rows_with_na}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_146735/1989552023.py:2: DtypeWarning: Columns (19,34,36,47,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  unique_mcrs_df = pd.read_csv(unique_mcrs_df_path)\n"
     ]
    }
   ],
   "source": [
    "# load in unique_mcrs_df\n",
    "unique_mcrs_df = pd.read_csv(unique_mcrs_df_path)\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_vk', 'FP': 'FP_vk', 'TN': 'TN_vk', 'FN': 'FN_vk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3997100</th>\n",
       "      <td>1</td>\n",
       "      <td>3699235</td>\n",
       "      <td>ENST00000378251:c.1431A&gt;G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997119</th>\n",
       "      <td>1</td>\n",
       "      <td>3699238</td>\n",
       "      <td>ENST00000378251:c.1428G&gt;A</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997222</th>\n",
       "      <td>1</td>\n",
       "      <td>3699233</td>\n",
       "      <td>ENST00000378251:c.1433A&gt;G</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CHROM      POS                         ID REF ALT\n",
       "3997100     1  3699235  ENST00000378251:c.1431A>G   T   C\n",
       "3997119     1  3699238  ENST00000378251:c.1428G>A   C   T\n",
       "3997222     1  3699233  ENST00000378251:c.1433A>G   T   C"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtered_df = cosmic_df[(cosmic_df['POS'].astype(int) >= 3699230) & (cosmic_df['POS'].astype(int) <= 3699239)]\n",
    "# filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHROM</th>\n",
       "      <th>POS</th>\n",
       "      <th>ID</th>\n",
       "      <th>REF</th>\n",
       "      <th>ALT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3699235</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9324106</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>21795263</td>\n",
       "      <td>None</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>27426829</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>TC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>31905881</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>X</td>\n",
       "      <td>83411147</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>X</td>\n",
       "      <td>100749525</td>\n",
       "      <td>None</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>X</td>\n",
       "      <td>111020088</td>\n",
       "      <td>None</td>\n",
       "      <td>GC</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>X</td>\n",
       "      <td>111020093</td>\n",
       "      <td>None</td>\n",
       "      <td>A</td>\n",
       "      <td>AC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>X</td>\n",
       "      <td>135485456</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CHROM        POS    ID REF ALT\n",
       "0       1    3699235  None   T   C\n",
       "1       1    9324106  None   C   T\n",
       "2       1   21795263  None   C   A\n",
       "3       1   27426829  None   T  TC\n",
       "4       1   31905881  None   G   T\n",
       "..    ...        ...   ...  ..  ..\n",
       "191     X   83411147  None   T   A\n",
       "192     X  100749525  None   T   C\n",
       "193     X  111020088  None  GC   G\n",
       "194     X  111020093  None   A  AC\n",
       "195     X  135485456  None   G   A\n",
       "\n",
       "[196 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_mut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  take the intersection of COSMIC and STAR dfs based on CHROM, POS, REF, ALT - but keep the ID from the COSMIC vcf\n",
    "mut_cosmic_merged_df = pd.merge(df_mut, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "mut_cosmic_merged_df = mut_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_mut = set(mut_cosmic_merged_df['ID'])\n",
    "\n",
    "\n",
    "\n",
    "hap_cosmic_merged_df = pd.merge(df_hap, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "hap_cosmic_merged_df = hap_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_hap = set(hap_cosmic_merged_df['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_mutations_mutect = len(df_mut)\n",
    "number_of_cosmic_mutations_mutect = len(mut_cosmic_merged_df)\n",
    "number_of_mutations_haplotypecaller = len(df_hap)\n",
    "number_of_cosmic_mutations_haplotypecaller = len(hap_cosmic_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_mutect2'] = unique_mcrs_df['reference_header'].isin(id_set_mut)  #!!! ensure 'reference_header' is correct here  # keep in mind that my IDs are the mutation headers (ENST...), NOT mcrs headers or mcrs ids\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "\n",
    "mutect_stat_path = f\"{gatk_parent}/reference_metrics_mutect2.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = mutect_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_mutect2'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_mutect2.png\")\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'mutect_fp_{i}' for i in range(1, number_of_mutations_mutect - number_of_cosmic_mutations_mutect + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(mutect_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_mutect2.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_mutect2', 'FP': 'FP_gatk_mutect2', 'TN': 'TN_gatk_mutect2', 'FN': 'FN_gatk_mutect2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_haplotypecaller'] = unique_mcrs_df['reference_header'].isin(id_set_hap)\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "\n",
    "haplotypecaller_stat_path = f\"{gatk_parent}/reference_metrics_haplotypecaller.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = haplotypecaller_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_haplotypecaller'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_haplotypecaller.png\")\n",
    "\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'haplotypecaller_fp_{i}' for i in range(1, number_of_mutations_haplotypecaller - number_of_cosmic_mutations_haplotypecaller + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(haplotypecaller_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_haplotypecaller.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_haplotypecaller', 'FP': 'FP_gatk_haplotypecaller', 'TN': 'TN_gatk_haplotypecaller', 'FN': 'FN_gatk_haplotypecaller'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cartf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

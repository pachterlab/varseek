{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflow followed according to: https://gatk.broadinstitute.org/hc/en-us/articles/360035531192-RNAseq-short-variant-discovery-SNPs-Indels\n",
    "\n",
    "Github workflow for GATK4 here: https://github.com/gatk-workflows/gatk4-rnaseq-germline-snps-indels/blob/master/gatk4-rna-best-practices.wdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pysam\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from varseek.varseek_build import add_mutation_type\n",
    "from varseek.utils import convert_chromosome_value_to_int_when_possible, calculate_metrics, draw_confusion_matrix, create_venn_diagram, calculate_sensitivity_specificity, create_stratified_metric_bar_plot\n",
    "from varseek.constants import complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_fastq(output_path, num_sequences=5000, seq_length=150, quality_score=\"I\"):\n",
    "    if not os.path.exists(output_path):\n",
    "        if not os.path.exists(os.path.dirname(output_path)):\n",
    "            os.makedirs(os.path.dirname(output_path))\n",
    "        bases = ['A', 'C', 'G', 'T']\n",
    "        with open(output_path, \"w\") as fastq_file:\n",
    "            for i in range(num_sequences):\n",
    "                # Generate a random sequence of the specified length\n",
    "                sequence = ''.join(random.choices(bases, k=seq_length))\n",
    "                \n",
    "                # Create a quality string of the same length, filled with the specified quality score\n",
    "                quality = quality_score * seq_length\n",
    "                \n",
    "                # Write the FASTQ entry\n",
    "                fastq_file.write(f\"@seq_{i + 1}\\n\")\n",
    "                fastq_file.write(f\"{sequence}\\n\")\n",
    "                fastq_file.write(\"+\\n\")\n",
    "                fastq_file.write(f\"{quality}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_read_fastq = \"/home/jrich/data/varseek_data/synthetic_data/synthetic_reads.fastq\"  #!!! update path\n",
    "unique_mcrs_df_path = \"/home/jrich/data/varseek_data/unique_mcrs.csv\"  #!!! update path\n",
    "generate_random_fastq(synthetic_read_fastq)  #!!! ERASE AND REPLACE THE ABOVE PATH WITH REAL DATA\n",
    "\n",
    "out_dir_base = \"/home/jrich/data/varseek_data\"\n",
    "threads = 32\n",
    "read_length = 150\n",
    "mutation_source = \"cdna\"  # \"cdna\", \"cds\"\n",
    "\n",
    "cosmic_tsv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37.tsv\"\n",
    "cosmic_cdna_info_csv = \"/home/jrich/data/varseek_data/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37_mutation_workflow_with_cdna.csv\"\n",
    "\n",
    "# if these paths don't exist then they will be created\n",
    "reference_genome_fasta = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa\"\n",
    "reference_genome_gtf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf\"\n",
    "genomes1000_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\"\n",
    "ensembl_germline_vcf = \"/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens.vcf\"\n",
    "\n",
    "STAR = \"/home/jrich/opt/STAR-2.7.11b/source/STAR\"\n",
    "java = \"/home/jrich/opt/java/jdk-17.0.12+7/bin/java\"\n",
    "picard_jar = \"/home/jrich/opt/picard/build/libs/picard.jar\"\n",
    "gatk = \"/home/jrich/opt/gatk-4.6.0.0/gatk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gatk_parent = f\"{out_dir_base}/gatk\"\n",
    "\n",
    "genome_dir = f\"{gatk_parent}/reference\"\n",
    "os.makedirs(genome_dir, exist_ok=True)\n",
    "\n",
    "alignment_folder = f\"{gatk_parent}/alignment\"\n",
    "os.makedirs(alignment_folder, exist_ok=True)\n",
    "\n",
    "gatk_supporting_files = f\"{gatk_parent}/supporting_files\"\n",
    "os.makedirs(alignment_folder, exist_ok=True)\n",
    "\n",
    "ensembl_germline_vcf_filtered = ensembl_germline_vcf.replace(\".vcf\", \"_filtered.vcf\")\n",
    "\n",
    "out_file_name_prefix = f\"{alignment_folder}/sample_\"\n",
    "\n",
    "vcf_folder = f\"{gatk_parent}/vcfs\"\n",
    "haplotypecaller_folder = f\"{vcf_folder}/haplotypecaller\"\n",
    "mutect2_folder = f\"{vcf_folder}/mutect2\"\n",
    "\n",
    "os.makedirs(vcf_folder, exist_ok=True)\n",
    "os.makedirs(haplotypecaller_folder, exist_ok=True)\n",
    "os.makedirs(mutect2_folder, exist_ok=True)\n",
    "\n",
    "aligned_and_unmapped_bam = f\"{out_file_name_prefix}Aligned.sortedByCoord.out.bam\"\n",
    "aligned_only_bam = f\"{alignment_folder}/aligned_only.bam\"\n",
    "unmapped_bam = f\"{alignment_folder}/unmapped.bam\"\n",
    "merged_bam = f\"{alignment_folder}/merged.bam\"\n",
    "\n",
    "marked_duplicates_bam = f\"{alignment_folder}/marked_duplicates.bam\"\n",
    "marked_dup_metrics_txt = f\"{alignment_folder}/marked_dup_metrics.txt\"\n",
    "\n",
    "split_n_cigar_reads_bam = f\"{alignment_folder}/split_n_cigar_reads.bam\"\n",
    "recal_data_table = f\"{alignment_folder}/recal_data.table\"\n",
    "recalibrated_bam = f\"{alignment_folder}/recalibrated.bam\"\n",
    "covariates_plot = f\"{alignment_folder}/AnalyzeCovariates.pdf\"\n",
    "haplotypecaller_unfiltered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_unfiltered.g.vcf.gz\"\n",
    "\n",
    "haplotypecaller_filtered_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered.vcf.gz\"\n",
    "haplotypecaller_filtered_applied_vcf = f\"{haplotypecaller_folder}/haplotypecaller_output_filtered_applied.vcf.gz\"\n",
    "\n",
    "panel_of_normals_vcf = f\"{gatk_supporting_files}/1000g_pon.hg38.vcf.gz\"\n",
    "mutect2_unfiltered_vcf = f\"{mutect2_folder}/mutect2_output_unfiltered.g.vcf.gz\"\n",
    "mutect2_filtered_vcf = f\"{mutect2_folder}/mutect2_output_filtered.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(reference_genome_fasta):\n",
    "    !wget -O {reference_genome_fasta}.gz https://ftp.ensembl.org/pub/grch37/release-93/fasta/homo_sapiens/dna/Homo_sapiens.GRCh37.dna.primary_assembly.fa.gz && gunzip {reference_genome_fasta}.gz\n",
    "\n",
    "if not os.path.exists(reference_genome_gtf):\n",
    "    !wget -O {reference_genome_gtf}.gz https://ftp.ensembl.org/pub/grch37/release-93/gtf/homo_sapiens/Homo_sapiens.GRCh37.87.gtf.gz && gunzip {reference_genome_gtf}.gz\n",
    "\n",
    "if not os.path.exists(genomes1000_vcf):\n",
    "    !wget -O {genomes1000_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/1000GENOMES-phase_3.vcf.gz && gunzip {genomes1000_vcf}.gz\n",
    "    \n",
    "if not os.path.exists(ensembl_germline_vcf):\n",
    "    !wget -O {ensembl_germline_vcf}.gz https://ftp.ensembl.org/pub/grch37/release-93/variation/vcf/homo_sapiens/homo_sapiens.vcf.gz && gunzip {ensembl_germline_vcf}.gz\n",
    "\n",
    "if not os.path.exists(ensembl_germline_vcf_filtered):\n",
    "    # !awk 'BEGIN { FS = \"\\t\" } $4 !~ /W/ && $5 !~ /W/' $ensembl_germline_vcf > $ensembl_germline_vcf_filtered\n",
    "    !grep -vP '^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*W|^[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*\\t[^\\t]*W' $ensembl_germline_vcf > $ensembl_germline_vcf_filtered\n",
    "\n",
    "if not os.path.exists(panel_of_normals_vcf):\n",
    "    !wget https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz {gatk_supporting_files}\n",
    "    !wget https://storage.googleapis.com/gatk-best-practices/somatic-hg38/1000g_pon.hg38.vcf.gz.tbi {gatk_supporting_files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Mapping to the Reference with STAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/jrich/opt/STAR-2.7.11b/source/STAR --runThreadN 32 --runMode genomeGenerate --genomeDir /home/jrich/data/varseek_data/gatk/reference --genomeFastaFiles /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --sjdbGTFfile /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf --sjdbOverhang 149\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-22T09:22:47-0700 dator:/home/jrich/opt/STAR-2.7.11b/source\n",
      "Oct 30 09:24:08 ..... started STAR run\n",
      "Oct 30 09:24:08 ... starting to generate Genome files\n",
      "Oct 30 09:25:00 ..... processing annotations GTF\n",
      "Oct 30 09:25:25 ... starting to sort Suffix Array. This may take a long time...\n",
      "Oct 30 09:25:42 ... sorting Suffix Array chunks and saving them to disk...\n",
      "Oct 30 09:33:31 ... loading chunks from disk, packing SA...\n",
      "Oct 30 09:34:55 ... finished generating suffix array\n",
      "Oct 30 09:34:55 ... generating Suffix Array index\n",
      "Oct 30 09:38:55 ... completed Suffix Array index\n",
      "Oct 30 09:38:55 ..... inserting junctions into the genome indices\n",
      "Oct 30 09:42:30 ... writing Genome to disk ...\n",
      "Oct 30 09:42:33 ... writing Suffix Array to disk ...\n",
      "Oct 30 09:42:56 ... writing SAindex to disk\n",
      "Oct 30 09:43:01 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "read_length_minus_one = read_length - 1\n",
    "\n",
    "!$STAR \\\n",
    "    --runThreadN $threads \\\n",
    "    --runMode genomeGenerate \\\n",
    "    --genomeDir $genome_dir \\\n",
    "    --genomeFastaFiles $reference_genome_fasta \\\n",
    "    --sjdbGTFfile $reference_genome_gtf \\\n",
    "    --sjdbOverhang $read_length_minus_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t/home/jrich/opt/STAR-2.7.11b/source/STAR --runThreadN 32 --genomeDir /home/jrich/data/varseek_data/gatk/reference --readFilesIn /home/jrich/data/varseek_data/synthetic_data/synthetic_reads.fastq --sjdbOverhang 149 --outFileNamePrefix /home/jrich/data/varseek_data/gatk/alignment/sample_ --outSAMtype BAM SortedByCoordinate --outSAMunmapped Within --outSAMmapqUnique 60 --twopassMode Basic\n",
      "\tSTAR version: 2.7.11b   compiled: 2024-07-22T09:22:47-0700 dator:/home/jrich/opt/STAR-2.7.11b/source\n",
      "Oct 30 09:43:02 ..... started STAR run\n",
      "Oct 30 09:43:02 ..... loading genome\n",
      "Oct 30 09:43:24 ..... started 1st pass mapping\n",
      "Oct 30 09:43:28 ..... finished 1st pass mapping\n",
      "Oct 30 09:43:29 ..... inserting junctions into the genome indices\n",
      "Oct 30 09:45:04 ..... started mapping\n",
      "Oct 30 09:45:10 ..... finished mapping\n",
      "Oct 30 09:45:14 ..... started sorting BAM\n",
      "Oct 30 09:45:14 ..... finished successfully\n"
     ]
    }
   ],
   "source": [
    "#* --outSAMmapqUnique 60 - change from default of 255 to avoid colliding with some aligners' use of 255 as a special value\n",
    "\n",
    "!$STAR \\\n",
    "    --runThreadN $threads \\\n",
    "    --genomeDir $genome_dir \\\n",
    "    --readFilesIn $synthetic_read_fastq \\\n",
    "    --sjdbOverhang $read_length_minus_one \\\n",
    "    --outFileNamePrefix $out_file_name_prefix \\\n",
    "    --outSAMtype BAM SortedByCoordinate \\\n",
    "    --outSAMunmapped Within \\\n",
    "    --outSAMmapqUnique 60 \\\n",
    "    --twopassMode Basic\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate unmapped reads into its own BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pysam.AlignmentFile(aligned_and_unmapped_bam, \"rb\") as bam_in: \n",
    "#     # unmapped_header = bam_in.header.to_dict()\n",
    "#     # if 'PG' in unmapped_header:\n",
    "#     #     del unmapped_header['PG']\n",
    "           \n",
    "#     with pysam.AlignmentFile(aligned_only_bam, \"wb\", template=bam_in) as bam_aligned_out, pysam.AlignmentFile(unmapped_bam, \"wb\", template=bam_in) as bam_unmapped_out:\n",
    "#         for read in bam_in:\n",
    "#             if read.is_unmapped:\n",
    "#                 bam_unmapped_out.write(read)  # Write unmapped read to the unmapped BAM file\n",
    "#             else:\n",
    "#                 bam_aligned_out.write(read)  # Write aligned read to the aligned BAM file\n",
    "\n",
    "# print(f\"Unmapped reads written to {unmapped_bam}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:45:17.964 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Oct 30 09:45:18 PDT 2024] FastqToSam --FASTQ /home/jrich/data/varseek_data/synthetic_data/synthetic_reads.fastq --OUTPUT /home/jrich/data/varseek_data/gatk/alignment/unmapped.bam --READ_GROUP_NAME rg1 --SAMPLE_NAME sample1 --LIBRARY_NAME lib1 --PLATFORM_UNIT unit1 --PLATFORM ILLUMINA --SEQUENCING_CENTER center1 --USE_SEQUENTIAL_FASTQS false --SORT_ORDER queryname --MIN_Q 0 --MAX_Q 93 --STRIP_UNPAIRED_MATE_NUMBER false --ALLOW_AND_IGNORE_EMPTY_LINES false --ALLOW_EMPTY_FASTQ false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Oct 30 09:45:18 PDT 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "WARNING\t2024-10-30 09:45:18\tFastqToSam\tMaking ambiguous determination about fastq's quality encoding; more than one format possible based on observed qualities.\n",
      "INFO\t2024-10-30 09:45:18\tFastqToSam\tAuto-detected quality format as: Illumina.\n",
      "INFO\t2024-10-30 09:45:18\tFastqToSam\tProcessed 5000 fastq reads\n",
      "[Wed Oct 30 09:45:18 PDT 2024] picard.sam.FastqToSam done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=2181038080\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar FastqToSam \\\n",
    "    -FASTQ $synthetic_read_fastq \\\n",
    "    -OUTPUT $unmapped_bam \\\n",
    "    -READ_GROUP_NAME rg1 \\\n",
    "    -SAMPLE_NAME sample1 \\\n",
    "    -LIBRARY_NAME lib1 \\\n",
    "    -PLATFORM_UNIT unit1 \\\n",
    "    -PLATFORM ILLUMINA \\\n",
    "    -SEQUENCING_CENTER center1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. MergeBamAlignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:45:19.462 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Oct 30 09:45:19 PDT 2024] CreateSequenceDictionary --OUTPUT /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.dict --REFERENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --TRUNCATE_NAMES_AT_WHITESPACE true --NUM_SEQUENCES 2147483647 --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Oct 30 09:45:19 PDT 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "[Wed Oct 30 09:45:35 PDT 2024] picard.sam.CreateSequenceDictionary done. Elapsed time: 0.28 minutes.\n",
      "Runtime.totalMemory()=2650800128\n"
     ]
    }
   ],
   "source": [
    "reference_genome_dict = reference_genome_fasta.replace(\".fa\", \".dict\")\n",
    "\n",
    "!$java -jar $picard_jar CreateSequenceDictionary \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -O $reference_genome_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:45:37.369 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Oct 30 09:45:37 PDT 2024] MergeBamAlignment --UNMAPPED_BAM /home/jrich/data/varseek_data/gatk/alignment/unmapped.bam --ALIGNED_BAM /home/jrich/data/varseek_data/gatk/alignment/sample_Aligned.sortedByCoord.out.bam --OUTPUT /home/jrich/data/varseek_data/gatk/alignment/merged.bam --SORT_ORDER coordinate --INCLUDE_SECONDARY_ALIGNMENTS false --VALIDATION_STRINGENCY SILENT --REFERENCE_SEQUENCE /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --ADD_PG_TAG_TO_READS true --PAIRED_RUN true --CLIP_ADAPTERS true --IS_BISULFITE_SEQUENCE false --ALIGNED_READS_ONLY false --MAX_INSERTIONS_OR_DELETIONS 1 --ATTRIBUTES_TO_REVERSE OQ --ATTRIBUTES_TO_REVERSE U2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT E2 --ATTRIBUTES_TO_REVERSE_COMPLEMENT SQ --READ1_TRIM 0 --READ2_TRIM 0 --ALIGNER_PROPER_PAIR_FLAGS false --PRIMARY_ALIGNMENT_STRATEGY BestMapq --CLIP_OVERLAPPING_READS true --HARD_CLIP_OVERLAPPING_READS false --ADD_MATE_CIGAR true --UNMAP_CONTAMINANT_READS false --MIN_UNCLIPPED_BASES 32 --MATCHING_DICTIONARY_TAGS M5 --MATCHING_DICTIONARY_TAGS LN --UNMAPPED_READ_STRATEGY DO_NOT_CHANGE --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Oct 30 09:45:37 PDT 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-10-30 09:45:37\tSamAlignmentMerger\tProcessing SAM file(s): [/home/jrich/data/varseek_data/gatk/alignment/sample_Aligned.sortedByCoord.out.bam]\n",
      "INFO\t2024-10-30 09:45:37\tAbstractAlignmentMerger\tWrote 0 alignment records and 5000 unmapped reads.\n",
      "[Wed Oct 30 09:45:37 PDT 2024] picard.sam.MergeBamAlignment done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=2181038080\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MergeBamAlignment \\\n",
    "    --ALIGNED_BAM $aligned_and_unmapped_bam \\\n",
    "    --UNMAPPED_BAM $unmapped_bam \\\n",
    "    --OUTPUT $merged_bam \\\n",
    "    --REFERENCE_SEQUENCE $reference_genome_fasta \\\n",
    "    --SORT_ORDER coordinate \\\n",
    "    --INCLUDE_SECONDARY_ALIGNMENTS false \\\n",
    "    --VALIDATION_STRINGENCY SILENT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. MarkDuplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09:45:38.909 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/picard/build/libs/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Wed Oct 30 09:45:38 PDT 2024] MarkDuplicates --INPUT /home/jrich/data/varseek_data/gatk/alignment/merged.bam --OUTPUT /home/jrich/data/varseek_data/gatk/alignment/marked_duplicates.bam --METRICS_FILE /home/jrich/data/varseek_data/gatk/alignment/marked_dup_metrics.txt --VALIDATION_STRINGENCY SILENT --CREATE_INDEX true --MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP 50000 --MAX_FILE_HANDLES_FOR_READ_ENDS_MAP 8000 --SORTING_COLLECTION_SIZE_RATIO 0.25 --TAG_DUPLICATE_SET_MEMBERS false --REMOVE_SEQUENCING_DUPLICATES false --TAGGING_POLICY DontTag --CLEAR_DT true --DUPLEX_UMI false --FLOW_MODE false --FLOW_DUP_STRATEGY FLOW_QUALITY_SUM_STRATEGY --USE_END_IN_UNPAIRED_READS false --USE_UNPAIRED_CLIPPED_END false --UNPAIRED_END_UNCERTAINTY 0 --UNPAIRED_START_UNCERTAINTY 0 --FLOW_SKIP_FIRST_N_FLOWS 0 --FLOW_Q_IS_KNOWN_END false --FLOW_EFFECTIVE_QUALITY_THRESHOLD 15 --ADD_PG_TAG_TO_READS true --REMOVE_DUPLICATES false --ASSUME_SORTED false --DUPLICATE_SCORING_STRATEGY SUM_OF_BASE_QUALITIES --PROGRAM_RECORD_ID MarkDuplicates --PROGRAM_GROUP_NAME MarkDuplicates --READ_NAME_REGEX <optimized capture of last three ':' separated fields as numeric values> --OPTICAL_DUPLICATE_PIXEL_DISTANCE 100 --MAX_OPTICAL_DUPLICATE_SET_SIZE 300000 --VERBOSITY INFO --QUIET false --COMPRESSION_LEVEL 5 --MAX_RECORDS_IN_RAM 500000 --CREATE_MD5_FILE false --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false\n",
      "[Wed Oct 30 09:45:39 PDT 2024] Executing as jrich@dator on Linux 3.10.0-1127.13.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 17.0.12+7; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:3.2.0-4-ge0475183b-SNAPSHOT\n",
      "INFO\t2024-10-30 09:45:39\tMarkDuplicates\tStart of doWork freeMemory: 377799136; totalMemory: 402653184; maxMemory: 32178700288\n",
      "INFO\t2024-10-30 09:45:39\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-10-30 09:45:39\tMarkDuplicates\tWill retain up to 116589493 data points before spilling to disk.\n",
      "INFO\t2024-10-30 09:45:40\tMarkDuplicates\tRead 0 records. 0 pairs never matched.\n",
      "INFO\t2024-10-30 09:45:40\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 829401096; totalMemory: 1795162112; maxMemory: 32178700288\n",
      "INFO\t2024-10-30 09:45:40\tMarkDuplicates\tWill retain up to 1005584384 duplicate indices before spilling to disk.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 7164017040; totalMemory: 15250489344; maxMemory: 32178700288\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tMarking 0 records as duplicates.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-10-30 09:45:44\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tBefore output close freeMemory: 593794568; totalMemory: 620756992; maxMemory: 32178700288\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-10-30 09:45:45\tMarkDuplicates\tAfter output close freeMemory: 207980752; totalMemory: 234881024; maxMemory: 32178700288\n",
      "[Wed Oct 30 09:45:45 PDT 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.11 minutes.\n",
      "Runtime.totalMemory()=234881024\n"
     ]
    }
   ],
   "source": [
    "!$java -jar $picard_jar MarkDuplicates \\\n",
    "      --INPUT $merged_bam \\\n",
    "      --OUTPUT $marked_duplicates_bam \\\n",
    "      --METRICS_FILE $marked_dup_metrics_txt \\\n",
    "      --CREATE_INDEX true \\\n",
    "      --VALIDATION_STRINGENCY SILENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. SplitNCigarReads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4221.63s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar SplitNCigarReads -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk/alignment/marked_duplicates.bam -O /home/jrich/data/varseek_data/gatk/alignment/split_n_cigar_reads.bam\n",
      "10:09:19.678 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:09:19.869 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "10:09:19.875 INFO  SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:09:19.875 INFO  SplitNCigarReads - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:09:19.875 INFO  SplitNCigarReads - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:09:19.876 INFO  SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:09:19.878 INFO  SplitNCigarReads - Start Date/Time: October 30, 2024 at 10:09:19 AM PDT\n",
      "10:09:19.878 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "10:09:19.878 INFO  SplitNCigarReads - ------------------------------------------------------------\n",
      "10:09:19.879 INFO  SplitNCigarReads - HTSJDK Version: 4.1.1\n",
      "10:09:19.880 INFO  SplitNCigarReads - Picard Version: 3.2.0\n",
      "10:09:19.880 INFO  SplitNCigarReads - Built for Spark Version: 3.5.0\n",
      "10:09:19.880 INFO  SplitNCigarReads - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:09:19.881 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:09:19.881 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:09:19.881 INFO  SplitNCigarReads - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:09:19.882 INFO  SplitNCigarReads - Deflater: IntelDeflater\n",
      "10:09:19.882 INFO  SplitNCigarReads - Inflater: IntelInflater\n",
      "10:09:19.882 INFO  SplitNCigarReads - GCS max retries/reopens: 20\n",
      "10:09:19.882 INFO  SplitNCigarReads - Requester pays: disabled\n",
      "10:09:19.883 INFO  SplitNCigarReads - Initializing engine\n",
      "10:09:20.091 INFO  SplitNCigarReads - Done initializing engine\n",
      "10:09:20.126 INFO  ProgressMeter - Starting traversal\n",
      "10:09:20.127 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "10:09:20.204 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "10:09:20.233 INFO  OverhangFixingManager - Overhang Fixing Manager saved 0 reads in the first pass\n",
      "10:09:20.235 INFO  SplitNCigarReads - Starting traversal pass 2\n",
      "10:09:20.278 INFO  SplitNCigarReads - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "10:09:20.279 INFO  ProgressMeter -             unmapped              0.0                 10000        3973509.9\n",
      "10:09:20.279 INFO  ProgressMeter - Traversal complete. Processed 10000 total reads in 0.0 minutes.\n",
      "10:09:20.490 INFO  SplitNCigarReads - Shutting down engine\n",
      "[October 30, 2024 at 10:09:20 AM PDT] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "_ = pysam.faidx(reference_genome_fasta)\n",
    "\n",
    "!$gatk SplitNCigarReads \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $marked_duplicates_bam \\\n",
    "    -O $split_n_cigar_reads_bam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. BaseRecalibrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar IndexFeatureFile -I /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens_filtered.vcf\n",
      "09:45:53.197 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "09:45:53.343 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:45:53.348 INFO  IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "09:45:53.348 INFO  IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "09:45:53.348 INFO  IndexFeatureFile - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "09:45:53.349 INFO  IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "09:45:53.349 INFO  IndexFeatureFile - Start Date/Time: October 30, 2024 at 9:45:53 AM PDT\n",
      "09:45:53.349 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:45:53.349 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:45:53.350 INFO  IndexFeatureFile - HTSJDK Version: 4.1.1\n",
      "09:45:53.350 INFO  IndexFeatureFile - Picard Version: 3.2.0\n",
      "09:45:53.351 INFO  IndexFeatureFile - Built for Spark Version: 3.5.0\n",
      "09:45:53.351 INFO  IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "09:45:53.351 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "09:45:53.352 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "09:45:53.352 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "09:45:53.352 INFO  IndexFeatureFile - Deflater: IntelDeflater\n",
      "09:45:53.352 INFO  IndexFeatureFile - Inflater: IntelInflater\n",
      "09:45:53.352 INFO  IndexFeatureFile - GCS max retries/reopens: 20\n",
      "09:45:53.353 INFO  IndexFeatureFile - Requester pays: disabled\n",
      "09:45:53.353 INFO  IndexFeatureFile - Initializing engine\n",
      "09:45:53.353 INFO  IndexFeatureFile - Done initializing engine\n",
      "09:45:53.508 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens_filtered.vcf\n",
      "09:45:53.518 INFO  ProgressMeter - Starting traversal\n",
      "09:45:53.518 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Records Processed   Records/Minute\n",
      "09:46:03.524 INFO  ProgressMeter -           1:48353498              0.2               5565000       33390000.0\n",
      "09:46:13.520 INFO  ProgressMeter -          1:102416382              0.3              11586000       34756262.2\n",
      "09:46:23.521 INFO  ProgressMeter -          1:185265466              0.5              18006000       36009599.4\n",
      "09:46:33.520 INFO  ProgressMeter -          1:242476451              0.7              24463000       36692665.4\n",
      "09:46:43.521 INFO  ProgressMeter -          10:50386559              0.8              30627000       36750930.0\n",
      "09:46:53.520 INFO  ProgressMeter -         10:105979246              1.0              36811000       36809773.0\n",
      "09:47:00.077 INFO  IndexFeatureFile - Shutting down engine\n",
      "[October 30, 2024 at 9:47:00 AM PDT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 1.12 minutes.\n",
      "Runtime.totalMemory()=3003121664\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: Error while trying to create index for /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens_filtered.vcf. Error was: htsjdk.tribble.TribbleException: The provided VCF file is malformed at approximately line number 40956999: empty alleles are not permitted in VCF records\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n",
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar IndexFeatureFile -I /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\n",
      "09:47:02.545 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "09:47:02.682 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:47:02.686 INFO  IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "09:47:02.687 INFO  IndexFeatureFile - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "09:47:02.687 INFO  IndexFeatureFile - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "09:47:02.687 INFO  IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "09:47:02.687 INFO  IndexFeatureFile - Start Date/Time: October 30, 2024 at 9:47:02 AM PDT\n",
      "09:47:02.687 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:47:02.687 INFO  IndexFeatureFile - ------------------------------------------------------------\n",
      "09:47:02.688 INFO  IndexFeatureFile - HTSJDK Version: 4.1.1\n",
      "09:47:02.689 INFO  IndexFeatureFile - Picard Version: 3.2.0\n",
      "09:47:02.689 INFO  IndexFeatureFile - Built for Spark Version: 3.5.0\n",
      "09:47:02.689 INFO  IndexFeatureFile - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "09:47:02.689 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "09:47:02.689 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "09:47:02.690 INFO  IndexFeatureFile - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "09:47:02.690 INFO  IndexFeatureFile - Deflater: IntelDeflater\n",
      "09:47:02.690 INFO  IndexFeatureFile - Inflater: IntelInflater\n",
      "09:47:02.690 INFO  IndexFeatureFile - GCS max retries/reopens: 20\n",
      "09:47:02.690 INFO  IndexFeatureFile - Requester pays: disabled\n",
      "09:47:02.691 INFO  IndexFeatureFile - Initializing engine\n",
      "09:47:02.691 INFO  IndexFeatureFile - Done initializing engine\n",
      "09:47:02.845 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\n",
      "09:47:02.855 INFO  ProgressMeter - Starting traversal\n",
      "09:47:02.856 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Records Processed   Records/Minute\n",
      "09:47:12.873 INFO  ProgressMeter -           1:83653295              0.2               2413000       14467872.5\n",
      "09:47:22.866 INFO  ProgressMeter -          1:211375897              0.3               5328000       15977609.0\n",
      "09:47:32.866 INFO  ProgressMeter -          10:66413279              0.5               8370000       16734979.5\n",
      "09:47:42.867 INFO  ProgressMeter -          11:34146646              0.7              11476000       17209267.5\n",
      "09:47:52.869 INFO  ProgressMeter -           12:5172334              0.8              14614000       17532592.2\n",
      "09:48:02.871 INFO  ProgressMeter -         12:122582751              1.0              17933000       17928816.6\n",
      "09:48:12.871 INFO  ProgressMeter -          14:22355553              1.2              21238000       18200359.9\n",
      "09:48:22.872 INFO  ProgressMeter -          15:50554621              1.3              24622000       18463038.2\n",
      "09:48:32.872 INFO  ProgressMeter -          16:64746009              1.5              27914000       18606025.6\n",
      "09:48:42.872 INFO  ProgressMeter -            18:495631              1.7              31232000       18736202.2\n",
      "09:48:52.874 INFO  ProgressMeter -          19:38984742              1.8              34643000       18893262.0\n",
      "09:49:02.874 INFO  ProgressMeter -           2:85641824              2.0              38010000       19002149.7\n",
      "09:49:12.875 INFO  ProgressMeter -          2:207891948              2.2              41291000       19054599.7\n",
      "09:49:22.876 INFO  ProgressMeter -          21:27575920              2.3              44619000       19119833.7\n",
      "09:49:32.875 INFO  ProgressMeter -           3:54667383              2.5              48045000       19215566.0\n",
      "09:49:42.877 INFO  ProgressMeter -          3:169982600              2.7              51354000       19255222.8\n",
      "09:49:52.877 INFO  ProgressMeter -           4:81829292              2.8              54700000       19303497.8\n",
      "09:50:02.884 INFO  ProgressMeter -            5:5666137              3.0              58095000       19362095.7\n",
      "09:50:12.884 INFO  ProgressMeter -          5:123880941              3.2              61485000       19413557.0\n",
      "09:50:22.883 INFO  ProgressMeter -           6:56931579              3.3              64871000       19458673.1\n",
      "09:50:32.884 INFO  ProgressMeter -            7:2132126              3.5              68234000       19492829.5\n",
      "09:50:42.885 INFO  ProgressMeter -          7:116884457              3.7              71606000       19526423.9\n",
      "09:50:52.884 INFO  ProgressMeter -           8:59265992              3.8              74888000       19533622.0\n",
      "09:51:02.885 INFO  ProgressMeter -           9:18718139              4.0              78158000       19537139.3\n",
      "09:51:12.888 INFO  ProgressMeter -           X:26258275              4.2              81492000       19555655.1\n",
      "09:51:20.999 INFO  ProgressMeter -           Y:28612448              4.3              84346966       19604783.3\n",
      "09:51:20.999 INFO  ProgressMeter - Traversal complete. Processed 84346966 total records in 4.3 minutes.\n",
      "09:51:21.240 INFO  IndexFeatureFile - Successfully wrote index to /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf.idx\n",
      "09:51:21.241 INFO  IndexFeatureFile - Shutting down engine\n",
      "[October 30, 2024 at 9:51:21 AM PDT] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 4.31 minutes.\n",
      "Runtime.totalMemory()=3456106496\n",
      "Tool returned:\n",
      "/home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf.idx\n"
     ]
    }
   ],
   "source": [
    "# -I in old version, -F in new version\n",
    "!$gatk IndexFeatureFile \\\n",
    "    -I $ensembl_germline_vcf_filtered\n",
    "\n",
    "!$gatk IndexFeatureFile \\\n",
    "    -I $genomes1000_vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4267.43s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar BaseRecalibrator -I /home/jrich/data/varseek_data/gatk/alignment/split_n_cigar_reads.bam -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa --use-original-qualities --known-sites /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens_filtered.vcf --known-sites /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf -O /home/jrich/data/varseek_data/gatk/alignment/recal_data.table\n",
      "10:10:05.471 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:10:05.641 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "10:10:05.647 INFO  BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:10:05.647 INFO  BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:10:05.647 INFO  BaseRecalibrator - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:10:05.647 INFO  BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:10:05.649 INFO  BaseRecalibrator - Start Date/Time: October 30, 2024 at 10:10:05 AM PDT\n",
      "10:10:05.649 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "10:10:05.649 INFO  BaseRecalibrator - ------------------------------------------------------------\n",
      "10:10:05.650 INFO  BaseRecalibrator - HTSJDK Version: 4.1.1\n",
      "10:10:05.651 INFO  BaseRecalibrator - Picard Version: 3.2.0\n",
      "10:10:05.651 INFO  BaseRecalibrator - Built for Spark Version: 3.5.0\n",
      "10:10:05.651 INFO  BaseRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:10:05.652 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:10:05.652 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:10:05.652 INFO  BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:10:05.652 INFO  BaseRecalibrator - Deflater: IntelDeflater\n",
      "10:10:05.653 INFO  BaseRecalibrator - Inflater: IntelInflater\n",
      "10:10:05.653 INFO  BaseRecalibrator - GCS max retries/reopens: 20\n",
      "10:10:05.653 INFO  BaseRecalibrator - Requester pays: disabled\n",
      "10:10:05.653 INFO  BaseRecalibrator - Initializing engine\n",
      "10:10:05.863 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/homo_sapiens_filtered.vcf\n",
      "10:10:05.900 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\n",
      "10:10:06.066 WARN  IndexUtils - Feature file \"file:///home/jrich/data/varseek_data/reference/ensembl_grch37_release93/1000GENOMES-phase_3.vcf\" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file\n",
      "10:10:06.138 INFO  BaseRecalibrator - Done initializing engine\n",
      "10:10:06.143 INFO  BaseRecalibrationEngine - The covariates being used here: \n",
      "10:10:06.144 INFO  BaseRecalibrationEngine - \tReadGroupCovariate\n",
      "10:10:06.144 INFO  BaseRecalibrationEngine - \tQualityScoreCovariate\n",
      "10:10:06.144 INFO  BaseRecalibrationEngine - \tContextCovariate\n",
      "10:10:06.144 INFO  BaseRecalibrationEngine - \tCycleCovariate\n",
      "10:10:06.147 INFO  ProgressMeter - Starting traversal\n",
      "10:10:06.148 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "10:10:06.178 INFO  BaseRecalibrator - 5000 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "0 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "5000 total reads filtered out of 5000 reads processed\n",
      "10:10:06.179 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "10:10:06.179 INFO  ProgressMeter - Traversal complete. Processed 0 total reads in 0.0 minutes.\n",
      "10:10:06.179 INFO  BaseRecalibrator - Calculating quantized quality scores...\n",
      "10:10:06.189 INFO  BaseRecalibrator - Writing recalibration report...\n",
      "10:10:06.221 INFO  BaseRecalibrator - ...done!\n",
      "10:10:06.223 INFO  BaseRecalibrator - BaseRecalibrator was able to recalibrate 0 reads\n",
      "10:10:06.223 INFO  BaseRecalibrator - Shutting down engine\n",
      "[October 30, 2024 at 10:10:06 AM PDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!$gatk BaseRecalibrator \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    --use-original-qualities \\\n",
    "    --known-sites $ensembl_germline_vcf_filtered \\\n",
    "    --known-sites $genomes1000_vcf \\\n",
    "    -O $recal_data_table\n",
    "\n",
    "# -known-sites ${dbSNP_vcf} \\\n",
    "# -known-sites ${sep=\" --known-sites \" known_indels_sites_VCFs}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Apply Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4302.62s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar ApplyBQSR --add-output-sam-program-record -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk/alignment/split_n_cigar_reads.bam --use-original-qualities --bqsr-recal-file /home/jrich/data/varseek_data/gatk/alignment/recal_data.table -O /home/jrich/data/varseek_data/gatk/alignment/recalibrated.bam\n",
      "10:10:40.522 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:10:40.666 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "10:10:40.671 INFO  ApplyBQSR - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:10:40.671 INFO  ApplyBQSR - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:10:40.671 INFO  ApplyBQSR - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:10:40.671 INFO  ApplyBQSR - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:10:40.672 INFO  ApplyBQSR - Start Date/Time: October 30, 2024 at 10:10:40 AM PDT\n",
      "10:10:40.672 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "10:10:40.672 INFO  ApplyBQSR - ------------------------------------------------------------\n",
      "10:10:40.673 INFO  ApplyBQSR - HTSJDK Version: 4.1.1\n",
      "10:10:40.673 INFO  ApplyBQSR - Picard Version: 3.2.0\n",
      "10:10:40.673 INFO  ApplyBQSR - Built for Spark Version: 3.5.0\n",
      "10:10:40.673 INFO  ApplyBQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:10:40.674 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:10:40.674 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:10:40.674 INFO  ApplyBQSR - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:10:40.674 INFO  ApplyBQSR - Deflater: IntelDeflater\n",
      "10:10:40.674 INFO  ApplyBQSR - Inflater: IntelInflater\n",
      "10:10:40.675 INFO  ApplyBQSR - GCS max retries/reopens: 20\n",
      "10:10:40.675 INFO  ApplyBQSR - Requester pays: disabled\n",
      "10:10:40.675 INFO  ApplyBQSR - Initializing engine\n",
      "10:10:40.942 INFO  ApplyBQSR - Done initializing engine\n",
      "10:10:40.983 INFO  ProgressMeter - Starting traversal\n",
      "10:10:40.984 INFO  ProgressMeter -        Current Locus  Elapsed Minutes       Reads Processed     Reads/Minute\n",
      "10:10:41.070 INFO  ApplyBQSR - Shutting down engine\n",
      "[October 30, 2024 at 10:10:41 AM PDT] org.broadinstitute.hellbender.tools.walkers.bqsr.ApplyBQSR done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n",
      "java.lang.IllegalStateException: The covariates table is missing ReadGroup unit1 in RecalTable0\n",
      "\tat org.broadinstitute.hellbender.utils.Utils.validate(Utils.java:823)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.keyForReadGroup(ReadGroupCovariate.java:81)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.covariates.ReadGroupCovariate.recordValues(ReadGroupCovariate.java:53)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.covariates.StandardCovariateList.recordAllValuesInStorage(StandardCovariateList.java:133)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:546)\n",
      "\tat org.broadinstitute.hellbender.utils.recalibration.RecalUtils.computeCovariates(RecalUtils.java:527)\n",
      "\tat org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:145)\n",
      "\tat org.broadinstitute.hellbender.transformers.BQSRReadTransformer.apply(BQSRReadTransformer.java:27)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:179)\n",
      "\tat java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:197)\n",
      "\tat java.base/java.util.Iterator.forEachRemaining(Iterator.java:133)\n",
      "\tat java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1845)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:509)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:499)\n",
      "\tat java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150)\n",
      "\tat java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173)\n",
      "\tat java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234)\n",
      "\tat java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:596)\n",
      "\tat org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:98)\n",
      "\tat org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1098)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:149)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:198)\n",
      "\tat org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:217)\n",
      "\tat org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:166)\n",
      "\tat org.broadinstitute.hellbender.Main.mainEntry(Main.java:209)\n",
      "\tat org.broadinstitute.hellbender.Main.main(Main.java:306)\n"
     ]
    }
   ],
   "source": [
    "!$gatk ApplyBQSR \\\n",
    "    --add-output-sam-program-record \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $split_n_cigar_reads_bam \\\n",
    "    --use-original-qualities \\\n",
    "    --bqsr-recal-file $recal_data_table \\\n",
    "    -O $recalibrated_bam\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. AnalyzeCovariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar AnalyzeCovariates -bqsr /home/jrich/data/varseek_data/gatk/alignment/recal_data.table -plots /home/jrich/data/varseek_data/gatk/alignment/AnalyzeCovariates.pdf\n",
      "09:51:28.874 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "09:51:29.024 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "09:51:29.028 INFO  AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "09:51:29.029 INFO  AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "09:51:29.029 INFO  AnalyzeCovariates - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "09:51:29.029 INFO  AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "09:51:29.029 INFO  AnalyzeCovariates - Start Date/Time: October 30, 2024 at 9:51:28 AM PDT\n",
      "09:51:29.029 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "09:51:29.029 INFO  AnalyzeCovariates - ------------------------------------------------------------\n",
      "09:51:29.030 INFO  AnalyzeCovariates - HTSJDK Version: 4.1.1\n",
      "09:51:29.031 INFO  AnalyzeCovariates - Picard Version: 3.2.0\n",
      "09:51:29.031 INFO  AnalyzeCovariates - Built for Spark Version: 3.5.0\n",
      "09:51:29.031 INFO  AnalyzeCovariates - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "09:51:29.031 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "09:51:29.032 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "09:51:29.032 INFO  AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "09:51:29.032 INFO  AnalyzeCovariates - Deflater: IntelDeflater\n",
      "09:51:29.032 INFO  AnalyzeCovariates - Inflater: IntelInflater\n",
      "09:51:29.032 INFO  AnalyzeCovariates - GCS max retries/reopens: 20\n",
      "09:51:29.033 INFO  AnalyzeCovariates - Requester pays: disabled\n",
      "09:51:29.033 INFO  AnalyzeCovariates - Initializing engine\n",
      "09:51:29.033 INFO  AnalyzeCovariates - Done initializing engine\n",
      "09:51:29.034 INFO  AnalyzeCovariates - Shutting down engine\n",
      "[October 30, 2024 at 9:51:29 AM PDT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.00 minutes.\n",
      "Runtime.totalMemory()=285212672\n",
      "USAGE: AnalyzeCovariates [arguments]\n",
      "\n",
      "Evaluate and compare base quality score recalibration (BQSR) tables\n",
      "Version:4.6.0.0\n",
      "\n",
      "Optional Arguments:\n",
      "\n",
      "--after-report-file,-after <File>\n",
      "                              file containing the BQSR second-pass report file  Default value: null. \n",
      "\n",
      "--arguments_file <File>       read one or more arguments files and add them to the command line  This argument may be\n",
      "                              specified 0 or more times. Default value: null. \n",
      "\n",
      "--before-report-file,-before <File>\n",
      "                              file containing the BQSR first-pass report file  Default value: null. \n",
      "\n",
      "--bqsr-recal-file,-bqsr <File>Input covariates table file for on-the-fly base quality score recalibration  Default\n",
      "                              value: null. \n",
      "\n",
      "--gatk-config-file <String>   A configuration file to use with the GATK.  Default value: null. \n",
      "\n",
      "--gcs-max-retries,-gcs-retries <Integer>\n",
      "                              If the GCS bucket channel errors out, how many times it will attempt to re-initiate the\n",
      "                              connection  Default value: 20. \n",
      "\n",
      "--gcs-project-for-requester-pays <String>\n",
      "                              Project to bill when accessing \"requester pays\" buckets. If unset, these buckets cannot be\n",
      "                              accessed.  User must have storage.buckets.get permission on the bucket being accessed. \n",
      "                              Default value: . \n",
      "\n",
      "--help,-h <Boolean>           display the help message  Default value: false. Possible values: {true, false} \n",
      "\n",
      "--ignore-last-modification-times <Boolean>\n",
      "                              do not emit warning messages related to suspicious last modification time order of inputs \n",
      "                              Default value: false. Possible values: {true, false} \n",
      "\n",
      "--intermediate-csv-file,-csv <File>\n",
      "                              location of the csv intermediate file  Default value: null. \n",
      "\n",
      "--plots-report-file,-plots <File>\n",
      "                              location of the output report  Default value: null. \n",
      "\n",
      "--QUIET <Boolean>             Whether to suppress job-summary info on System.err.  Default value: false. Possible\n",
      "                              values: {true, false} \n",
      "\n",
      "--tmp-dir <GATKPath>          Temp directory to use.  Default value: null. \n",
      "\n",
      "--use-jdk-deflater,-jdk-deflater <Boolean>\n",
      "                              Whether to use the JdkDeflater (as opposed to IntelDeflater)  Default value: false.\n",
      "                              Possible values: {true, false} \n",
      "\n",
      "--use-jdk-inflater,-jdk-inflater <Boolean>\n",
      "                              Whether to use the JdkInflater (as opposed to IntelInflater)  Default value: false.\n",
      "                              Possible values: {true, false} \n",
      "\n",
      "--verbosity <LogLevel>        Control verbosity of logging.  Default value: INFO. Possible values: {ERROR, WARNING,\n",
      "                              INFO, DEBUG} \n",
      "\n",
      "--version <Boolean>           display the version number for this tool  Default value: false. Possible values: {true,\n",
      "                              false} \n",
      "\n",
      "\n",
      "Advanced Arguments:\n",
      "\n",
      "--showHidden <Boolean>        display hidden arguments  Default value: false. Possible values: {true, false} \n",
      "\n",
      "\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: Argument BQSR has a bad value: input report '/home/jrich/data/varseek_data/gatk/alignment/recal_data.table' does not exist or is unreachable\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    }
   ],
   "source": [
    "!$gatk AnalyzeCovariates \\\n",
    "    -bqsr $recal_data_table \\\n",
    "    -plots $covariates_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8a. HaplotypeCaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4384.11s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx4g -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar HaplotypeCaller -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz --standard-min-confidence-threshold-for-calling 20 -dont-use-soft-clipped-bases\n",
      "10:12:02.609 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:12:02.793 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "10:12:02.798 INFO  HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:12:02.798 INFO  HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:12:02.799 INFO  HaplotypeCaller - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:12:02.799 INFO  HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:12:02.799 INFO  HaplotypeCaller - Start Date/Time: October 30, 2024 at 10:12:02 AM PDT\n",
      "10:12:02.799 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "10:12:02.800 INFO  HaplotypeCaller - ------------------------------------------------------------\n",
      "10:12:02.801 INFO  HaplotypeCaller - HTSJDK Version: 4.1.1\n",
      "10:12:02.801 INFO  HaplotypeCaller - Picard Version: 3.2.0\n",
      "10:12:02.801 INFO  HaplotypeCaller - Built for Spark Version: 3.5.0\n",
      "10:12:02.802 INFO  HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:12:02.802 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:12:02.802 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:12:02.803 INFO  HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:12:02.803 INFO  HaplotypeCaller - Deflater: IntelDeflater\n",
      "10:12:02.803 INFO  HaplotypeCaller - Inflater: IntelInflater\n",
      "10:12:02.804 INFO  HaplotypeCaller - GCS max retries/reopens: 20\n",
      "10:12:02.804 INFO  HaplotypeCaller - Requester pays: disabled\n",
      "10:12:02.804 INFO  HaplotypeCaller - Initializing engine\n",
      "10:12:03.076 INFO  HaplotypeCaller - Done initializing engine\n",
      "10:12:03.092 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "10:12:03.095 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "10:12:03.097 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "10:12:03.097 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "10:12:03.101 INFO  HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output\n",
      "10:12:03.114 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "10:12:03.177 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "10:12:03.177 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "10:12:03.178 INFO  IntelPairHmm - Available threads: 88\n",
      "10:12:03.179 INFO  IntelPairHmm - Requested threads: 4\n",
      "10:12:03.179 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "10:12:03.231 INFO  ProgressMeter - Starting traversal\n",
      "10:12:03.237 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "10:12:13.243 INFO  ProgressMeter -           1:68072701              0.2                226910        1361460.0\n",
      "10:12:23.238 INFO  ProgressMeter -          1:139184701              0.3                463950        1391850.0\n",
      "10:12:33.238 INFO  ProgressMeter -          1:212702701              0.5                709010        1418020.0\n",
      "10:12:43.237 INFO  ProgressMeter -          10:34329901              0.7                945270        1417905.0\n",
      "10:12:53.237 INFO  ProgressMeter -         10:101352901              0.8               1168680        1402416.0\n",
      "10:13:03.238 INFO  ProgressMeter -          11:36897001              1.0               1405610        1405610.0\n",
      "10:13:13.237 INFO  ProgressMeter -         11:104034001              1.2               1629400        1396628.6\n",
      "10:13:23.237 INFO  ProgressMeter -          12:39326401              1.3               1863730        1397797.5\n",
      "10:13:33.237 INFO  ProgressMeter -         12:107969401              1.5               2092540        1395026.7\n",
      "10:13:43.237 INFO  ProgressMeter -          13:45157501              1.7               2329340        1397604.0\n",
      "10:13:53.237 INFO  ProgressMeter -         13:112870501              1.8               2555050        1393663.6\n",
      "10:14:03.237 INFO  ProgressMeter -          14:64672501              2.0               2778290        1389145.0\n",
      "10:14:13.237 INFO  ProgressMeter -          15:28554901              2.2               3015730        1391875.4\n",
      "10:14:23.237 INFO  ProgressMeter -          15:96888901              2.3               3243510        1390075.7\n",
      "10:14:33.237 INFO  ProgressMeter -          16:65652301              2.5               3481160        1392464.0\n",
      "10:14:43.237 INFO  ProgressMeter -          17:40868401              2.7               3699730        1387398.8\n",
      "10:14:53.237 INFO  ProgressMeter -          18:24485101              2.8               3915770        1382036.5\n",
      "10:15:03.238 INFO  ProgressMeter -          19:13652701              3.0               4139920        1379973.3\n",
      "10:15:13.237 INFO  ProgressMeter -           2:24993601              3.2               4374820        1381522.1\n",
      "10:15:23.238 INFO  ProgressMeter -           2:89970601              3.3               4591410        1377423.0\n",
      "10:15:33.237 INFO  ProgressMeter -          2:155742601              3.5               4810650        1374471.4\n",
      "10:15:43.237 INFO  ProgressMeter -          2:222054601              3.7               5031690        1372279.1\n",
      "10:15:53.237 INFO  ProgressMeter -          20:44879101              3.8               5251770        1370027.0\n",
      "10:16:03.237 INFO  ProgressMeter -           22:3920401              4.0               5485760        1371440.0\n",
      "10:16:13.237 INFO  ProgressMeter -           3:15684601              4.2               5695990        1367037.6\n",
      "10:16:23.237 INFO  ProgressMeter -           3:79896601              4.3               5910030        1363853.1\n",
      "10:16:33.237 INFO  ProgressMeter -          3:140739601              4.5               6112840        1358408.9\n",
      "10:16:43.237 INFO  ProgressMeter -            4:2720101              4.7               6312850        1352753.6\n",
      "10:16:53.237 INFO  ProgressMeter -           4:71558101              4.8               6542310        1353581.4\n",
      "10:17:03.237 INFO  ProgressMeter -          4:136799101              5.0               6759780        1351956.0\n",
      "10:17:13.237 INFO  ProgressMeter -            5:9064801              5.2               6971180        1349260.6\n",
      "10:17:23.237 INFO  ProgressMeter -           5:76147801              5.3               7194790        1349023.1\n",
      "10:17:33.237 INFO  ProgressMeter -          5:144862801              5.5               7423840        1349789.1\n",
      "10:17:43.237 INFO  ProgressMeter -           6:35101501              5.7               7661020        1351944.7\n",
      "10:17:53.237 INFO  ProgressMeter -           6:95791501              5.8               7863320        1347997.7\n",
      "10:18:03.237 INFO  ProgressMeter -          6:163438501              6.0               8088810        1348135.0\n",
      "10:18:13.237 INFO  ProgressMeter -           7:62946301              6.2               8324220        1349873.5\n",
      "10:18:23.237 INFO  ProgressMeter -          7:129477301              6.3               8545990        1349366.8\n",
      "10:18:33.237 INFO  ProgressMeter -           8:41444401              6.5               8783010        1351232.3\n",
      "10:18:43.237 INFO  ProgressMeter -          8:109592401              6.7               9010170        1351525.5\n",
      "10:18:53.237 INFO  ProgressMeter -           9:34535101              6.8               9247860        1353345.4\n",
      "10:19:03.237 INFO  ProgressMeter -          9:102140101              7.0               9473210        1353315.7\n",
      "10:19:13.237 INFO  ProgressMeter -           X:31667701              7.2               9709070        1354754.0\n",
      "10:19:23.237 INFO  ProgressMeter -           X:99533701              7.3               9935290        1354812.3\n",
      "10:19:33.237 INFO  ProgressMeter -           Y:13647001              7.5              10166570        1355542.7\n",
      "10:19:40.725 INFO  HaplotypeCaller - 0 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "0 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "0 total reads filtered out of 0 reads processed\n",
      "10:19:40.725 INFO  ProgressMeter -      GL000207.1:1501              7.6              10339389        1356021.0\n",
      "10:19:40.726 INFO  ProgressMeter - Traversal complete. Processed 10339389 total regions in 7.6 minutes.\n",
      "10:19:40.729 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0\n",
      "10:19:40.730 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0\n",
      "10:19:40.730 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.00 sec\n",
      "10:19:40.731 INFO  HaplotypeCaller - Shutting down engine\n",
      "[October 30, 2024 at 10:19:40 AM PDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 7.64 minutes.\n",
      "Runtime.totalMemory()=1126170624\n"
     ]
    }
   ],
   "source": [
    "!$gatk --java-options \"-Xmx4g\" HaplotypeCaller  \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $haplotypecaller_unfiltered_vcf \\\n",
    "    --standard-min-confidence-threshold-for-calling 20 \\\n",
    "    -dont-use-soft-clipped-bases \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.5a. MergeVcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_vcf = haplotypecaller_merged.vcf\n",
    "# \n",
    "# !$java -jar $picard_jar MergeVcfs \\\n",
    "#     --INPUT $vcf1 \\\n",
    "#     --INPUT $vcf2 \\\n",
    "#     --OUTPUT $merged_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9a. VariantFiltration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5675.94s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar VariantFiltration -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk/vcfs/haplotypecaller/haplotypecaller_output_filtered.vcf.gz --window 35 --cluster 3 --filter-name FS --filter FS > 30.0 --filter-name QD --filter QD < 2.0\n",
      "10:33:33.819 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:33:33.966 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "10:33:33.970 INFO  VariantFiltration - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:33:33.970 INFO  VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:33:33.971 INFO  VariantFiltration - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:33:33.971 INFO  VariantFiltration - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:33:33.971 INFO  VariantFiltration - Start Date/Time: October 30, 2024 at 10:33:33 AM PDT\n",
      "10:33:33.971 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "10:33:33.971 INFO  VariantFiltration - ------------------------------------------------------------\n",
      "10:33:33.972 INFO  VariantFiltration - HTSJDK Version: 4.1.1\n",
      "10:33:33.972 INFO  VariantFiltration - Picard Version: 3.2.0\n",
      "10:33:33.973 INFO  VariantFiltration - Built for Spark Version: 3.5.0\n",
      "10:33:33.973 INFO  VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:33:33.973 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:33:33.973 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:33:33.974 INFO  VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:33:33.974 INFO  VariantFiltration - Deflater: IntelDeflater\n",
      "10:33:33.974 INFO  VariantFiltration - Inflater: IntelInflater\n",
      "10:33:33.974 INFO  VariantFiltration - GCS max retries/reopens: 20\n",
      "10:33:33.974 INFO  VariantFiltration - Requester pays: disabled\n",
      "10:33:33.975 INFO  VariantFiltration - Initializing engine\n",
      "10:33:34.194 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk/vcfs/haplotypecaller/haplotypecaller_output_unfiltered.g.vcf.gz\n",
      "10:33:34.235 INFO  VariantFiltration - Done initializing engine\n",
      "10:33:34.332 INFO  ProgressMeter - Starting traversal\n",
      "10:33:34.333 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "10:33:34.337 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "10:33:34.338 INFO  ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.\n",
      "10:33:34.340 INFO  VariantFiltration - Shutting down engine\n",
      "[October 30, 2024 at 10:33:34 AM PDT] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# cosmic_vcf = \"\"\n",
    "\n",
    "!$gatk VariantFiltration \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $haplotypecaller_unfiltered_vcf \\\n",
    "    -O $haplotypecaller_filtered_vcf \\\n",
    "    --window 35 \\\n",
    "    --cluster 3 \\\n",
    "    --filter-name \"FS\" \\\n",
    "    --filter \"FS > 30.0\" \\\n",
    "    --filter-name \"QD\" \\\n",
    "    --filter \"QD < 2.0\"\n",
    "\n",
    "    # --mask $cosmic_vcf \\\n",
    "    # --mask-name \"COSMIC\" \\\n",
    "    # --filter-not-in-mask \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10a. Do the filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$gatk SelectVariants \\\n",
    "     -V $haplotypecaller_filtered_vcf \\\n",
    "     --exclude-filtered true \\\n",
    "     -O $haplotypecaller_filtered_applied_vcf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8b. Mutect2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4850.19s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar Mutect2 -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -I /home/jrich/data/varseek_data/gatk/alignment/recalibrated.bam -O /home/jrich/data/varseek_data/gatk/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz --min-base-quality-score 20\n",
      "10:19:48.078 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:19:48.217 INFO  Mutect2 - ------------------------------------------------------------\n",
      "10:19:48.222 INFO  Mutect2 - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:19:48.222 INFO  Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:19:48.222 INFO  Mutect2 - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:19:48.223 INFO  Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:19:48.223 INFO  Mutect2 - Start Date/Time: October 30, 2024 at 10:19:48 AM PDT\n",
      "10:19:48.223 INFO  Mutect2 - ------------------------------------------------------------\n",
      "10:19:48.223 INFO  Mutect2 - ------------------------------------------------------------\n",
      "10:19:48.224 INFO  Mutect2 - HTSJDK Version: 4.1.1\n",
      "10:19:48.224 INFO  Mutect2 - Picard Version: 3.2.0\n",
      "10:19:48.224 INFO  Mutect2 - Built for Spark Version: 3.5.0\n",
      "10:19:48.225 INFO  Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:19:48.225 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:19:48.225 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:19:48.225 INFO  Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:19:48.225 INFO  Mutect2 - Deflater: IntelDeflater\n",
      "10:19:48.226 INFO  Mutect2 - Inflater: IntelInflater\n",
      "10:19:48.226 INFO  Mutect2 - GCS max retries/reopens: 20\n",
      "10:19:48.226 INFO  Mutect2 - Requester pays: disabled\n",
      "10:19:48.227 INFO  Mutect2 - Initializing engine\n",
      "10:19:48.501 INFO  Mutect2 - Done initializing engine\n",
      "10:19:48.522 INFO  NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_utils.so\n",
      "10:19:48.525 INFO  NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so\n",
      "10:19:48.528 INFO  IntelSmithWaterman - Using CPU-supported AVX-512 instructions\n",
      "10:19:48.528 INFO  SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation\n",
      "10:19:48.544 INFO  NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so\n",
      "10:19:48.584 INFO  IntelPairHmm - Using CPU-supported AVX-512 instructions\n",
      "10:19:48.584 INFO  IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM\n",
      "10:19:48.585 INFO  IntelPairHmm - Available threads: 88\n",
      "10:19:48.585 INFO  IntelPairHmm - Requested threads: 4\n",
      "10:19:48.585 INFO  PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation\n",
      "10:19:48.642 INFO  ProgressMeter - Starting traversal\n",
      "10:19:48.643 INFO  ProgressMeter -        Current Locus  Elapsed Minutes     Regions Processed   Regions/Minute\n",
      "10:19:58.648 INFO  ProgressMeter -           1:39653701              0.2                132180         793080.0\n",
      "10:20:08.644 INFO  ProgressMeter -           1:94028701              0.3                313430         940290.0\n",
      "10:20:18.643 INFO  ProgressMeter -          1:150065701              0.5                500220        1000440.0\n",
      "10:20:28.644 INFO  ProgressMeter -          1:207608701              0.7                692030        1038045.0\n",
      "10:20:38.643 INFO  ProgressMeter -          10:12144901              0.8                871320        1045584.0\n",
      "10:20:48.643 INFO  ProgressMeter -          10:69675901              1.0               1063090        1063090.0\n",
      "10:20:58.643 INFO  ProgressMeter -         10:118962901              1.2               1227380        1052040.0\n",
      "10:21:08.643 INFO  ProgressMeter -          11:37362001              1.3               1407160        1055370.0\n",
      "10:21:18.643 INFO  ProgressMeter -          11:92781001              1.5               1591890        1061260.0\n",
      "10:21:28.643 INFO  ProgressMeter -          12:13073401              1.7               1776220        1065732.0\n",
      "10:21:38.643 INFO  ProgressMeter -          12:72206401              1.8               1973330        1076361.8\n",
      "10:21:48.644 INFO  ProgressMeter -         12:117263401              2.0               2123520        1061760.0\n",
      "10:21:58.643 INFO  ProgressMeter -          13:39019501              2.2               2308880        1065636.9\n",
      "10:22:08.643 INFO  ProgressMeter -          13:92863501              2.3               2488360        1066440.0\n",
      "10:22:18.643 INFO  ProgressMeter -          14:28462501              2.5               2657590        1063036.0\n",
      "10:22:28.643 INFO  ProgressMeter -          14:84058501              2.7               2842910        1066091.3\n",
      "10:22:38.644 INFO  ProgressMeter -          15:34416901              2.8               3035270        1071271.8\n",
      "10:22:48.643 INFO  ProgressMeter -          15:88605901              3.0               3215900        1071966.7\n",
      "10:22:58.643 INFO  ProgressMeter -          16:44142301              3.2               3409460        1076671.6\n",
      "10:23:08.643 INFO  ProgressMeter -           17:2309401              3.3               3571200        1071360.0\n",
      "10:23:18.643 INFO  ProgressMeter -          17:57701401              3.5               3755840        1073097.1\n",
      "10:23:28.643 INFO  ProgressMeter -          18:35165101              3.7               3951370        1077646.4\n",
      "10:23:38.643 INFO  ProgressMeter -          19:15554701              3.8               4146260        1081633.0\n",
      "10:23:48.643 INFO  ProgressMeter -           2:16521601              4.0               4346580        1086645.0\n",
      "10:23:58.643 INFO  ProgressMeter -           2:74319601              4.2               4539240        1089417.6\n",
      "10:24:08.643 INFO  ProgressMeter -          2:123312601              4.3               4702550        1085203.8\n",
      "10:24:18.643 INFO  ProgressMeter -          2:174708601              4.5               4873870        1083082.2\n",
      "10:24:28.643 INFO  ProgressMeter -          2:225531601              4.7               5043280        1080702.9\n",
      "10:24:38.643 INFO  ProgressMeter -          20:36977101              4.8               5225430        1081123.4\n",
      "10:24:48.643 INFO  ProgressMeter -          21:33690301              5.0               5424560        1084912.0\n",
      "10:24:58.643 INFO  ProgressMeter -          22:41213401              5.2               5610070        1085820.0\n",
      "10:25:08.643 INFO  ProgressMeter -           3:44178601              5.3               5790970        1085806.9\n",
      "10:25:18.644 INFO  ProgressMeter -           3:97272601              5.5               5967950        1085081.8\n",
      "10:25:28.644 INFO  ProgressMeter -          3:147132601              5.7               6134150        1082497.1\n",
      "10:25:38.643 INFO  ProgressMeter -          3:197562601              5.8               6302250        1080385.7\n",
      "10:25:48.645 INFO  ProgressMeter -           4:52994101              6.0               6480430        1080068.7\n",
      "10:25:58.645 INFO  ProgressMeter -           4:79730101              6.2               6569550        1065329.6\n",
      "10:26:08.645 INFO  ProgressMeter -          4:108734101              6.3               6666230        1052559.9\n",
      "10:26:18.645 INFO  ProgressMeter -          4:145445101              6.5               6788600        1044397.3\n",
      "10:26:28.645 INFO  ProgressMeter -            5:3589801              6.7               6952930        1042936.9\n",
      "10:26:38.645 INFO  ProgressMeter -           5:61819801              6.8               7147030        1045904.3\n",
      "10:26:48.645 INFO  ProgressMeter -          5:106225801              7.0               7295050        1042147.5\n",
      "10:26:58.644 INFO  ProgressMeter -          5:149107801              7.2               7437990        1037856.7\n",
      "10:27:08.644 INFO  ProgressMeter -           6:11116501              7.3               7581070        1033779.9\n",
      "10:27:18.644 INFO  ProgressMeter -           6:66502501              7.5               7765690        1035423.0\n",
      "10:27:28.644 INFO  ProgressMeter -          6:118528501              7.7               7939110        1035533.8\n",
      "10:27:38.644 INFO  ProgressMeter -            7:1461301              7.8               8119270        1036500.3\n",
      "10:27:48.644 INFO  ProgressMeter -           7:60639301              8.0               8316530        1039564.1\n",
      "10:27:58.644 INFO  ProgressMeter -          7:113487301              8.2               8492690        1039919.1\n",
      "10:28:08.644 INFO  ProgressMeter -            8:8189401              8.3               8672160        1040657.1\n",
      "10:28:18.645 INFO  ProgressMeter -           8:68138401              8.5               8871990        1043761.5\n",
      "10:28:28.644 INFO  ProgressMeter -          8:122597401              8.7               9053520        1044634.9\n",
      "10:28:38.644 INFO  ProgressMeter -           9:34046101              8.8               9246230        1046741.0\n",
      "10:28:48.644 INFO  ProgressMeter -           9:89405101              9.0               9430760        1047860.3\n",
      "10:28:58.644 INFO  ProgressMeter -            X:2855701              9.2               9613030        1048692.3\n",
      "10:29:08.644 INFO  ProgressMeter -           X:60233701              9.3               9804290        1050457.8\n",
      "10:29:18.644 INFO  ProgressMeter -          X:104177701              9.5               9950770        1047447.6\n",
      "10:29:28.644 INFO  ProgressMeter -          X:148802701              9.7              10099520        1044776.1\n",
      "10:29:38.645 INFO  ProgressMeter -           Y:51051001              9.8              10291250        1046566.0\n",
      "10:29:41.433 INFO  Mutect2 - 0 read(s) filtered by: MappingQualityReadFilter \n",
      "0 read(s) filtered by: MappingQualityAvailableReadFilter \n",
      "0 read(s) filtered by: MappingQualityNotZeroReadFilter \n",
      "0 read(s) filtered by: MappedReadFilter \n",
      "0 read(s) filtered by: NotSecondaryAlignmentReadFilter \n",
      "0 read(s) filtered by: NotDuplicateReadFilter \n",
      "0 read(s) filtered by: PassesVendorQualityCheckReadFilter \n",
      "0 read(s) filtered by: NonChimericOriginalAlignmentReadFilter \n",
      "0 read(s) filtered by: NonZeroReferenceLengthAlignmentReadFilter \n",
      "0 read(s) filtered by: ReadLengthReadFilter \n",
      "0 read(s) filtered by: GoodCigarReadFilter \n",
      "0 read(s) filtered by: WellformedReadFilter \n",
      "0 total reads filtered out of 0 reads processed\n",
      "10:29:41.433 INFO  ProgressMeter -      GL000207.1:1501              9.9              10339389        1046514.5\n",
      "10:29:41.434 INFO  ProgressMeter - Traversal complete. Processed 10339389 total regions in 9.9 minutes.\n",
      "10:29:41.447 INFO  VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0\n",
      "10:29:41.447 INFO  PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0\n",
      "10:29:41.447 INFO  SmithWatermanAligner - Total compute time in native Smith-Waterman : 0.00 sec\n",
      "10:29:41.449 INFO  Mutect2 - Shutting down engine\n",
      "[October 30, 2024 at 10:29:41 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 9.89 minutes.\n",
      "Runtime.totalMemory()=2885681152\n",
      "Tool returned:\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# consider adding --disable-read-filter\n",
    "!$gatk Mutect2 \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -I $recalibrated_bam \\\n",
    "    -O $mutect2_unfiltered_vcf \\\n",
    "    --panel-of-normals $panel_of_normals_vcf \\\n",
    "    --min-base-quality-score 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9b. FilterMutectCalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5731.66s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GATK jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar\n",
      "Running:\n",
      "    java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar FilterMutectCalls -R /home/jrich/data/varseek_data/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa -V /home/jrich/data/varseek_data/gatk/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz -O /home/jrich/data/varseek_data/gatk/vcfs/mutect2/mutect2_output_filtered.vcf.gz\n",
      "10:34:30.141 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/jrich/opt/gatk-4.6.0.0/gatk-package-4.6.0.0-local.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "10:34:30.387 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "10:34:30.392 INFO  FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.6.0.0\n",
      "10:34:30.393 INFO  FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/\n",
      "10:34:30.393 INFO  FilterMutectCalls - Executing as jrich@dator on Linux v3.10.0-1127.13.1.el7.x86_64 amd64\n",
      "10:34:30.393 INFO  FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v17.0.12+7\n",
      "10:34:30.393 INFO  FilterMutectCalls - Start Date/Time: October 30, 2024 at 10:34:30 AM PDT\n",
      "10:34:30.393 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "10:34:30.394 INFO  FilterMutectCalls - ------------------------------------------------------------\n",
      "10:34:30.394 INFO  FilterMutectCalls - HTSJDK Version: 4.1.1\n",
      "10:34:30.395 INFO  FilterMutectCalls - Picard Version: 3.2.0\n",
      "10:34:30.395 INFO  FilterMutectCalls - Built for Spark Version: 3.5.0\n",
      "10:34:30.395 INFO  FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2\n",
      "10:34:30.396 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false\n",
      "10:34:30.396 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true\n",
      "10:34:30.396 INFO  FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false\n",
      "10:34:30.396 INFO  FilterMutectCalls - Deflater: IntelDeflater\n",
      "10:34:30.396 INFO  FilterMutectCalls - Inflater: IntelInflater\n",
      "10:34:30.397 INFO  FilterMutectCalls - GCS max retries/reopens: 20\n",
      "10:34:30.397 INFO  FilterMutectCalls - Requester pays: disabled\n",
      "10:34:30.397 INFO  FilterMutectCalls - Initializing engine\n",
      "10:34:30.568 INFO  FeatureManager - Using codec VCFCodec to read file file:///home/jrich/data/varseek_data/gatk/vcfs/mutect2/mutect2_output_unfiltered.g.vcf.gz\n",
      "10:34:30.598 INFO  FilterMutectCalls - Done initializing engine\n",
      "10:34:30.658 WARN  SomaticClusteringModel - No callable sites found in Mutect stats.  Running without the full somatic clustering model.  Something is seriously wrong!\n",
      "10:34:30.664 INFO  ProgressMeter - Starting traversal\n",
      "10:34:30.664 INFO  ProgressMeter -        Current Locus  Elapsed Minutes    Variants Processed  Variants/Minute\n",
      "10:34:30.665 INFO  FilterMutectCalls - Starting pass 0 through the variants\n",
      "10:34:30.668 INFO  FilterMutectCalls - Finished pass 0 through the variants\n",
      "10:34:30.690 INFO  FilterMutectCalls - Starting pass 1 through the variants\n",
      "10:34:30.691 INFO  FilterMutectCalls - Finished pass 1 through the variants\n",
      "10:34:30.692 INFO  FilterMutectCalls - Starting pass 2 through the variants\n",
      "10:34:30.693 INFO  FilterMutectCalls - Finished pass 2 through the variants\n",
      "10:34:30.693 INFO  FilterMutectCalls - Starting pass 3 through the variants\n",
      "10:34:30.694 INFO  FilterMutectCalls - Finished pass 3 through the variants\n",
      "10:34:30.760 INFO  FilterMutectCalls - No variants filtered by: AllowAllVariantsVariantFilter\n",
      "10:34:30.762 INFO  FilterMutectCalls - 0 read(s) filtered by: AllowAllReadsReadFilter \n",
      "\n",
      "10:34:30.763 INFO  ProgressMeter -             unmapped              0.0                     0              0.0\n",
      "10:34:30.763 INFO  ProgressMeter - Traversal complete. Processed 0 total variants in 0.0 minutes.\n",
      "10:34:30.768 INFO  FilterMutectCalls - Shutting down engine\n",
      "[October 30, 2024 at 10:34:30 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.01 minutes.\n",
      "Runtime.totalMemory()=285212672\n"
     ]
    }
   ],
   "source": [
    "# # if multiple stats files:\n",
    "# !$gatk MergeMutectStats -stats unfiltered1.vcf.stats -stats unfiltered2.vcf.stats -O unfiltered.vcf.stats\n",
    "\n",
    "# stats_file = f\"{mutect2_unfiltered_vcf}.stats\"\n",
    "# --stats $stats_file\n",
    "!$gatk FilterMutectCalls \\\n",
    "    -R $reference_genome_fasta \\\n",
    "    -V $mutect2_unfiltered_vcf \\\n",
    "    -O $mutect2_filtered_vcf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W::vcf_parse] Contig '1' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig '2' is not defined in the header. (Quick workaround: index the file with tabix.)\n",
      "[W::vcf_parse] Contig 'X' is not defined in the header. (Quick workaround: index the file with tabix.)\n"
     ]
    }
   ],
   "source": [
    "# def create_sample_vcf(output_path):\n",
    "#     with open(output_path, \"w\") as vcf_file:\n",
    "#         # Write VCF headers\n",
    "#         vcf_file.write(\"##fileformat=VCFv4.2\\n\")\n",
    "#         vcf_file.write(\"##source=SampleVCFGenerator\\n\")\n",
    "#         vcf_file.write(\"##reference=GRCh37\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=DP,Number=1,Type=Integer,Description=\\\"Total Depth\\\">\\n\")\n",
    "#         vcf_file.write(\"##INFO=<ID=AF,Number=A,Type=Float,Description=\\\"Allele Frequency\\\">\\n\")\n",
    "#         vcf_file.write(\"##FILTER=<ID=PASS,Description=\\\"All filters passed\\\">\\n\")\n",
    "#         vcf_file.write(\"##FORMAT=<ID=GT,Number=1,Type=String,Description=\\\"Genotype\\\">\\n\")\n",
    "#         vcf_file.write(\"#CHROM\\tPOS\\tID\\tREF\\tALT\\tQUAL\\tFILTER\\tINFO\\tFORMAT\\tsample1\\n\")\n",
    "        \n",
    "#         # Write sample variant entries\n",
    "#         variants = [\n",
    "#             (\"1\", 123456, \".\", \"G\", \"A\", 50, \"PASS\", \"DP=100;AF=0.5\", \"GT\", \"0/1\"),\n",
    "#             (\"1\", 234567, \".\", \"C\", \"T\", 60, \"PASS\", \"DP=200;AF=0.3\", \"GT\", \"1/1\"),\n",
    "#             (\"2\", 345678, \".\", \"T\", \"G\", 70, \"PASS\", \"DP=150;AF=0.1\", \"GT\", \"0/1\"),\n",
    "#             (\"X\", 456789, \".\", \"A\", \"C\", 80, \"PASS\", \"DP=120;AF=0.05\", \"GT\", \"0/0\")\n",
    "#         ]\n",
    "        \n",
    "#         for chrom, pos, var_id, ref, alt, qual, fltr, info, fmt, sample in variants:\n",
    "#             vcf_file.write(f\"{chrom}\\t{pos}\\t{var_id}\\t{ref}\\t{alt}\\t{qual}\\t{fltr}\\t{info}\\t{fmt}\\t{sample}\\n\")\n",
    "\n",
    "# # Usage\n",
    "# create_sample_vcf(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")\n",
    "\n",
    "# df_sample = vcf_to_dataframe(\"/home/jrich/data/varseek_data/gatk/sample.vcf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert gatk output vcf to pandas df\n",
    "def vcf_to_dataframe(vcf_file):\n",
    "    \"\"\"Convert a VCF file to a Pandas DataFrame.\"\"\"\n",
    "    vcf = pysam.VariantFile(vcf_file)\n",
    "    \n",
    "    # List to store VCF rows\n",
    "    vcf_data = []\n",
    "    \n",
    "    # Fetch each record in the VCF\n",
    "    for record in vcf.fetch():\n",
    "        # For each record, extract the desired fields\n",
    "        vcf_row = {\n",
    "            'CHROM': record.chrom,\n",
    "            'POS': record.pos,\n",
    "            'ID': record.id,\n",
    "            'REF': record.ref,\n",
    "            'ALT': ','.join(record.alts),  # ALT can be multiple\n",
    "        }\n",
    "        \n",
    "        # Append the row to the list\n",
    "        vcf_data.append(vcf_row)\n",
    "    \n",
    "    # Convert the list to a Pandas DataFrame\n",
    "    df = pd.DataFrame(vcf_data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Convert VCF to DataFrame\n",
    "df_hap = vcf_to_dataframe(haplotypecaller_filtered_applied_vcf)\n",
    "df_mut = vcf_to_dataframe(mutect2_filtered_vcf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in COSMIC tsv with columns CHROM, POS, ID, REF, ALT\n",
    "cosmic_df = pd.read_csv(cosmic_tsv, sep=\"\\t\", usecols=[\"Mutation genome position GRCh37\", \"GENOMIC_WT_ALLELE_SEQ\", \"GENOMIC_MUT_ALLELE_SEQ\", \"ACCESSION_NUMBER\", \"Mutation CDS\", \"MUTATION_URL\"])\n",
    "\n",
    "if mutation_source == \"cdna\":\n",
    "    cosmic_cdna_info_df = pd.read_csv(cosmic_cdna_info_csv, usecols=[\"mutation_id\", \"mutation\"])\n",
    "    cosmic_cdna_info_df = cosmic_cdna_info_df.rename(columns={\"mutation\": \"Mutation cDNA\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df = add_mutation_type(cosmic_df, \"Mutation CDS\")\n",
    "\n",
    "cosmic_df[\"ACCESSION_NUMBER\"] = cosmic_df[\"ACCESSION_NUMBER\"].str.split(\".\").str[0]\n",
    "\n",
    "cosmic_df[['CHROM', 'GENOME_POS']] = cosmic_df['Mutation genome position GRCh37'].str.split(':', expand=True)\n",
    "# cosmic_df['CHROM'] = cosmic_df['CHROM'].apply(convert_chromosome_value_to_int_when_possible)\n",
    "cosmic_df[['POS', 'GENOME_END_POS']] = cosmic_df['GENOME_POS'].str.split('-', expand=True)\n",
    "\n",
    "cosmic_df = cosmic_df.rename(\n",
    "    columns={\n",
    "        \"GENOMIC_WT_ALLELE_SEQ\": \"REF\",\n",
    "        \"GENOMIC_MUT_ALLELE_SEQ\": \"ALT\",\n",
    "        \"MUTATION_URL\": \"mutation_id\"\n",
    "    }\n",
    ")\n",
    "\n",
    "if mutation_source == \"cds\":\n",
    "    cosmic_df['ID'] = cosmic_df['ACCESSION_NUMBER'] + \":\" + cosmic_df['Mutation CDS']\n",
    "elif mutation_source == \"cdna\":\n",
    "    cosmic_df[\"mutation_id\"] = cosmic_df[\"mutation_id\"].str.extract(r\"id=(\\d+)\")\n",
    "    cosmic_df['mutation_id'] = cosmic_df['mutation_id'].astype(int, errors='raise')\n",
    "    cosmic_df = cosmic_df.merge(cosmic_cdna_info_df[['mutation_id', 'Mutation cDNA']], on='mutation_id', how='left')\n",
    "    cosmic_df['ID'] = cosmic_df['ACCESSION_NUMBER'] + \":\" + cosmic_df['Mutation cDNA']\n",
    "    cosmic_df.drop(columns=[\"Mutation cDNA\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_145075/2323330122.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  gtf_df = pd.read_csv(reference_genome_gtf, sep='\\t', comment='#', header=None, names=[\n"
     ]
    }
   ],
   "source": [
    "# # commented out because this was only used when considering strand below for reverse-complementing, but the line below is irrelevant now\n",
    "# gtf_df = pd.read_csv(reference_genome_gtf, sep='\\t', comment='#', header=None, names=[\n",
    "# 'seqname', 'source', 'feature', 'start', 'end', 'score', 'strand', 'frame', 'attribute'])\n",
    "\n",
    "# gtf_df = gtf_df[gtf_df['feature'] == 'transcript']\n",
    "\n",
    "# gtf_df['transcript_id'] = gtf_df['attribute'].str.extract('transcript_id \"([^\"]+)\"')\n",
    "\n",
    "# gtf_df = gtf_df.dropna(subset=['transcript_id'])\n",
    "\n",
    "# gtf_df = gtf_df[['transcript_id', 'strand']].rename(\n",
    "#     columns={'transcript_id': 'ACCESSION_NUMBER'})\n",
    "\n",
    "# cosmic_df = pd.merge(cosmic_df, gtf_df, on='ACCESSION_NUMBER', how='left')\n",
    "# cosmic_df['strand'] = cosmic_df['strand'].fillna('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df = cosmic_df.dropna(subset=['CHROM', 'POS'])\n",
    "cosmic_df = cosmic_df.dropna(subset=['ID'])  # a result of intron mutations and COSMIC duplicates that get dropped before cDNA determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 246.94it/s]\n",
      "100%|| 7/7 [00:00<00:00, 1920.59it/s]\n",
      "1it [00:00, 1161.54it/s]\n",
      "1it [00:00, 1250.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# reference_genome_fasta\n",
    "reference_genome = pysam.FastaFile(reference_genome_fasta)\n",
    "\n",
    "def get_nucleotide_from_reference(chromosome, position):\n",
    "    # pysam is 0-based, so subtract 1 from the position\n",
    "    return reference_genome.fetch(chromosome, int(position) - 1, int(position))\n",
    "\n",
    "def get_complement(nucleotide_sequence):\n",
    "    return ''.join([complement[nuc] for nuc in nucleotide_sequence])\n",
    "\n",
    "# Insertion, get original nucleotide (not in COSMIC df)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'insertion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'insertion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['POS'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Deletion, get new nucleotide (not in COSMIC df)\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) != 1) & (cosmic_df['mutation_type'] == 'deletion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['POS']) - 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Duplication\n",
    "cosmic_df.loc[cosmic_df['mutation_type'] == 'duplication', 'original_nucleotide'] = cosmic_df.loc[cosmic_df['ID'].str.contains('dup', na=False), 'ALT'].str[-1]\n",
    "\n",
    "# deal with start of 1, insertion\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'insertion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['GENOME_END_POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'insertion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['GENOME_END_POS'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# deal with start of 1, deletion\n",
    "cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), 'original_nucleotide'\n",
    "] = cosmic_df.loc[\n",
    "    (cosmic_df['POS'].astype(int) == 1) & (cosmic_df['mutation_type'] == 'deletion'), ['CHROM', 'POS']\n",
    "].progress_apply(\n",
    "    lambda row: get_nucleotide_from_reference(row['CHROM'], int(row['GENOME_END_POS']) + 1),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# # deal with (-) strand - commented out because the vcf should all be relative to the forward strand, not the cdna\n",
    "# cosmic_df.loc[cosmic_df['strand'] == '-', 'original_nucleotide'] = cosmic_df.loc[cosmic_df['strand'] == '-', 'original_nucleotide'].apply(get_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ins and dup, starting position not 1\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'ref_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'alt_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide'] + cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) != 1)), 'ALT']\n",
    "\n",
    "# ins and dup, starting position 1\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'ref_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'alt_updated'] = cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'ALT'] + cosmic_df.loc[(((cosmic_df['mutation_type'] == 'insertion') | (cosmic_df['mutation_type'] == 'duplication')) & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "\n",
    "\n",
    "# del, starting position not 1\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'ref_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide'] + cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'REF']\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'alt_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) != 1)), 'original_nucleotide']\n",
    "\n",
    "# del, starting position 1\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'ref_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'REF'] + cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']\n",
    "cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'alt_updated'] = cosmic_df.loc[((cosmic_df['mutation_type'] == 'deletion') & (cosmic_df['POS'].astype(int) == 1)), 'original_nucleotide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic_df['ref_updated'] = cosmic_df['ref_updated'].fillna(cosmic_df['REF'])\n",
    "cosmic_df['alt_updated'] = cosmic_df['alt_updated'].fillna(cosmic_df['ALT'])\n",
    "cosmic_df.rename(columns={'ALT': 'alt_cosmic', 'alt_updated': 'ALT', 'REF': 'ref_cosmic', 'ref_updated': 'REF'}, inplace=True)\n",
    "cosmic_df.drop(columns=[\"Mutation genome position GRCh37\", \"GENOME_POS\", \"GENOME_END_POS\", \"ACCESSION_NUMBER\", \"Mutation CDS\", \"mutation_id\", 'ref_cosmic', 'alt_cosmic', 'original_nucleotide', 'mutation_type'], inplace=True)  # 'strand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rows_with_na = cosmic_df.isna().any(axis=1).sum()\n",
    "assert num_rows_with_na == 0, f\"Number of rows with NA values: {num_rows_with_na}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in unique_mcrs_df\n",
    "unique_mcrs_df = pd.read_csv(unique_mcrs_df_path)\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_vk', 'FP': 'FP_vk', 'TN': 'TN_vk', 'FN': 'FN_vk'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  take the intersection of COSMIC and STAR dfs based on CHROM, POS, REF, ALT - but keep the ID from the COSMIC vcf\n",
    "mut_cosmic_merged_df = pd.merge(df_mut, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "mut_cosmic_merged_df = mut_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_mut = set(mut_cosmic_merged_df['ID'])\n",
    "\n",
    "\n",
    "\n",
    "hap_cosmic_merged_df = pd.merge(df_hap, cosmic_df, \n",
    "                     on=['CHROM', 'POS', 'REF', 'ALT'], \n",
    "                     how='inner',\n",
    "                     suffixes=('_df1', '_df2'))\n",
    "\n",
    "hap_cosmic_merged_df = hap_cosmic_merged_df.drop(columns=['ID_df1']).rename(columns={'ID_df2': 'ID'})\n",
    "\n",
    "id_set_hap = set(hap_cosmic_merged_df['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_mutations_mutect = len(df_mut)\n",
    "number_of_cosmic_mutations_mutect = len(mut_cosmic_merged_df)\n",
    "number_of_mutations_haplotypecaller = len(df_hap)\n",
    "number_of_cosmic_mutations_haplotypecaller = len(hap_cosmic_merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_mutect2'] = unique_mcrs_df['reference_header'].isin(id_set_mut)  #!!! ensure 'reference_header' is correct here  # keep in mind that my IDs are the mutation headers (ENST...), NOT mcrs headers or mcrs ids\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_mutect2'])\n",
    "\n",
    "mutect_stat_path = f\"{gatk_parent}/reference_metrics_mutect2.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = mutect_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_mutect2'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_mutect2.png\")\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'mutect_fp_{i}' for i in range(1, number_of_mutations_mutect - number_of_cosmic_mutations_mutect + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(mutect_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_mutect2.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_mutect2', 'FP': 'FP_gatk_mutect2', 'TN': 'TN_gatk_mutect2', 'FN': 'FN_gatk_mutect2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['mutation_detected_gatk_haplotypecaller'] = unique_mcrs_df['reference_header'].isin(id_set_hap)\n",
    "\n",
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['mutation_detected_gatk_haplotypecaller'])\n",
    "\n",
    "haplotypecaller_stat_path = f\"{gatk_parent}/reference_metrics_haplotypecaller.txt\"\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = False, out = haplotypecaller_stat_path)\n",
    "draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['mutation_detected_gatk_haplotypecaller'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_cosmic_only_haplotypecaller.png\")\n",
    "\n",
    "\n",
    "\n",
    "noncosmic_mutation_id_set = {f'haplotypecaller_fp_{i}' for i in range(1, number_of_mutations_haplotypecaller - number_of_cosmic_mutations_haplotypecaller + 1)}\n",
    "positive_set_including_noncosmic_mutations = positive_set.union(noncosmic_mutation_id_set)\n",
    "\n",
    "FP_including_noncosmic = metric_dictionary_reference['FP'] + len(positive_set_including_noncosmic_mutations)\n",
    "accuracy, sensitivity, specificity = calculate_sensitivity_specificity(metric_dictionary_reference['TP'], metric_dictionary_reference['TP'], FP_including_noncosmic, metric_dictionary_reference['TP'])\n",
    "\n",
    "with open(haplotypecaller_stat_path, \"a\") as file:\n",
    "    file.write(f\"FP including non-cosmic: {FP_including_noncosmic}\\n\")\n",
    "    file.write(f\"accuracy including non-cosmic: {accuracy}\\n\")\n",
    "    file.write(f\"specificity including non-cosmic: {specificity}\\n\")\n",
    "\n",
    "create_venn_diagram(true_set, positive_set_including_noncosmic_mutations, TN = metric_dictionary_reference['TN'], out_path = f\"{gatk_parent}/venn_diagram_reference_including_noncosmics_haplotypecaller.png\")\n",
    "\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which GATK is reliable\n",
    "\n",
    "unique_mcrs_df.rename(columns={'TP': 'TP_gatk_haplotypecaller', 'FP': 'FP_gatk_haplotypecaller', 'TN': 'TN_gatk_haplotypecaller', 'FN': 'FN_gatk_haplotypecaller'}, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cartf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

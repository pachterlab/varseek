{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import varseek as vk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose=True\n",
    "w=54  # window size for varseek build (should be at least 1 less than kallisto k)\n",
    "k=59\n",
    "k_standard = 31\n",
    "threads = 8\n",
    "remove_Ns = True\n",
    "strandedness = False  # strandedness for gget mutate and the building of the kb index (True = strandedness matters i.e., treat f and rc as 2 different sequences; False = strandedness does not matter i.e., treat f and rc as the same \n",
    "\n",
    "# vk build\n",
    "cosmic_version = 100  # COSMIC version for gget cosmic\n",
    "insertion_size_limit = None\n",
    "# os.environ['COSMIC_EMAIL'] = 'your_email'  # to avoid being prompted for email in varseek build\n",
    "# os.environ['COSMIC_PASSWORD'] = 'your_password'  # to avoid being prompted for password in varseek build\n",
    "\n",
    "# vk info\n",
    "columns_to_include=\"all\"\n",
    "dlist_reference_source = \"ensembl_grch37_release93\"  # ensembl_grchNUMBER_releaseNUMBER or t2t - eg ensembl_grch37_release93\n",
    "near_splice_junction_threshold=10\n",
    "save_exploded_df=True\n",
    "\n",
    "# vk filter\n",
    "fasta_filters = [\n",
    "    \"dlist_substring-equal=none\",  # filter out mutations which are a substring of the reference genome\n",
    "    \"pseudoaligned_to_human_reference_despite_not_truly_aligning-isnottrue\",  # filter out mutations which pseudoaligned to human genome despite not truly aligning\n",
    "    \"dlist-equal=none\",  #*** erase eventually when I want to d-list  # filter out mutations which are capable of being d-listed (given that I filter out the substrings above)\n",
    "    \"number_of_kmers_with_overlap_to_other_mcrs_items_in_mcrs_reference-max=999999\",  # filter out mutations which overlap with other MCRSs in the reference\n",
    "    \"number_of_mcrs_items_with_overlapping_kmers_in_mcrs_reference-max=999999\",  # filter out mutations which overlap with other MCRSs in the reference\n",
    "    \"longest_homopolymer_length-max=999999\",  # filters out MCRSs with repeating single nucleotide - eg 6\n",
    "    \"triplet_complexity-min=0\"  # filters out MCRSs with repeating triplets - eg 0.2\n",
    "]\n",
    "\n",
    "# kb ref\n",
    "dlist = False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Paths\n",
    "out_dir_base = \"/home/jrich/data/varseek_data_fresh\"\n",
    "run_name = \"vk_build_pipeline_grch37_nov16\"\n",
    "\n",
    "# vk build\n",
    "mutations = \"/home/jrich/data/varseek_data_fresh/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37_mutation_workflow_with_cdna.csv\"  # \"cosmic_cmc\"  # file path to mutations csv/tsv file OR one of the supported databases\n",
    "sequences = \"/home/jrich/data/varseek_data_fresh/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.cdna.all.fa\"  # cdna  # file path to reference sequence fasta file OR, only if 'mutations' is in the supported databases, one of the following options is also supported: \"cds\", \"cdna\", \"genome\", \"cdna_and_genome\" - sequences for gget mutate\n",
    "\n",
    "# vk info\n",
    "bowtie_path=\"/home/jrich/opt/bowtie2-2.5.4/bowtie2-2.5.4-linux-x86_64\"\n",
    "mutations_csv=\"/home/jrich/data/varseek_data_fresh/reference/cosmic/CancerMutationCensus_AllData_Tsv_v100_GRCh37/CancerMutationCensus_AllData_v100_GRCh37_with_cdna.csv\"\n",
    "reference_cdna_fasta=\"/home/jrich/data/varseek_data_fresh/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.cdna.all.fa\"  # the one that matches up to mutation df annotations\n",
    "reference_genome_fasta=\"/home/jrich/data/varseek_data_fresh/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.dna.primary_assembly.fa\"  # the one that matches up to mutation df annotations\n",
    "gtf_path=\"/home/jrich/data/varseek_data_fresh/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.87.gtf\"  # the one that matches up to mutation df annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic variable initializations based on provided hyperparameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir_notebook = os.path.join(out_dir_base, run_name)\n",
    "reference_out_dir = os.path.join(out_dir_base, \"reference\")\n",
    "\n",
    "os.makedirs(out_dir_base, exist_ok=True)\n",
    "os.makedirs(out_dir_notebook, exist_ok=True)\n",
    "os.makedirs(reference_out_dir, exist_ok=True)\n",
    "\n",
    "if remove_Ns:\n",
    "    max_ambiguous_vk = 0\n",
    "else:\n",
    "    max_ambiguous_vk = None\n",
    "\n",
    "merge_identical_rc = not strandedness\n",
    "\n",
    "vk_build_mcrs_fa_path = os.path.join(out_dir_notebook, \"mcrs.fa\")\n",
    "update_df_out = os.path.join(out_dir_notebook, \"mutation_metadata_df.csv\")\n",
    "os.makedirs(out_dir_notebook, exist_ok=True)\n",
    "\n",
    "assert k >= w + 1, \"k must be greater than or equal to w + 1\"\n",
    "\n",
    "id_to_header_csv=os.path.join(out_dir_notebook, \"id_to_header_mapping.csv\")\n",
    "mutation_metadata_df_out_path_vk_info = os.path.join(out_dir_notebook, \"mutation_metadata_df_updated_vk_info.csv\")\n",
    "mutation_index = f\"{out_dir_notebook}/mutation_reference.idx\"\n",
    "dlist_fasta = f\"{out_dir_notebook}/dlist.fa\"\n",
    "wt_mcrs_index = f\"{out_dir_notebook}/wt_mcrs_reference.idx\"\n",
    "\n",
    "\n",
    "mcrs_fasta_vk_filter = os.path.join(out_dir_notebook, \"mcrs_filtered.fa\")\n",
    "output_metadata_df_vk_filter = os.path.join(out_dir_notebook, \"mutation_metadata_df_filtered.csv\")\n",
    "dlist_fasta_vk_filter = os.path.join(out_dir_notebook, \"dlist_filtered.fa\")\n",
    "wt_mcrs_fa_vk_filter = os.path.join(out_dir_notebook, \"mcrs_wt_filtered.fa\")\n",
    "t2g_vk_filter = os.path.join(out_dir_notebook, \"t2g_filtered.txt\")\n",
    "t2g_wt_vk_filter = os.path.join(out_dir_notebook, \"t2g_wt_filtered.txt\")\n",
    "id_to_header_csv_vk_filter = os.path.join(out_dir_notebook, \"id_to_header_mapping_filtered.csv\")\n",
    "\n",
    "if dlist:\n",
    "    dlist_kb_argument = dlist_fasta_vk_filter\n",
    "else:\n",
    "    dlist_kb_argument = \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vk build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vk.build(\n",
    "    sequences=sequences,\n",
    "    mutations=mutations,\n",
    "    out=out_dir_notebook,\n",
    "    reference_out=reference_out_dir,\n",
    "    w=w,\n",
    "    k=k,\n",
    "    insertion_size_limit=insertion_size_limit,\n",
    "    remove_seqs_with_wt_kmers=True,\n",
    "    optimize_flanking_regions=True,\n",
    "    min_seq_len=k,\n",
    "    max_ambiguous=max_ambiguous_vk,\n",
    "    merge_identical=True,\n",
    "    merge_identical_rc=merge_identical_rc,\n",
    "    cosmic_email = os.getenv('COSMIC_EMAIL'),\n",
    "    cosmic_password = os.getenv('COSMIC_PASSWORD'),\n",
    "    create_t2g=True,\n",
    "    create_wt_mcrs_counterpart_fa=True,\n",
    "    update_df=True,\n",
    "    update_df_out=update_df_out,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vk info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vk.info(\n",
    "    mutations = vk_build_mcrs_fa_path,\n",
    "    updated_df=update_df_out,\n",
    "    id_to_header_csv=id_to_header_csv,  # if none then assume no swapping occurred\n",
    "    columns_to_include=columns_to_include,\n",
    "    mcrs_id_column=\"mcrs_id\",\n",
    "    mcrs_sequence_column=\"mutant_sequence\",\n",
    "    mcrs_source_column=\"mcrs_source\",  # if input df has concatenated cdna and header MCRS's, then I want to know whether it came from cdna or genome\n",
    "    seqid_cdna_column=\"seq_ID\",  # if input df has concatenated cdna and header MCRS's, then I want a way of mapping from cdna to genome  # TODO: implement these 4 column name arguments\n",
    "    seqid_genome_column=\"chromosome\",  # if input df has concatenated cdna and header MCRS's, then I want a way of mapping from cdna to genome\n",
    "    mutation_cdna_column=\"mutation\",  # if input df has concatenated cdna and header MCRS's, then I want a way of mapping from cdna to genome\n",
    "    mutation_genome_column=\"mutation_genome\",  # if input df has concatenated cdna and header MCRS's, then I want a way of mapping from cdna to genome\n",
    "    gtf=gtf_path,  # for distance to nearest splice junction\n",
    "    mutation_metadata_df_out_path=mutation_metadata_df_out_path_vk_info,\n",
    "    out_dir_notebook=out_dir_notebook,\n",
    "    reference_out_dir=reference_out_dir,\n",
    "    dlist_reference_source=dlist_reference_source,\n",
    "    ref_prefix=\"index\",\n",
    "    w=w,\n",
    "    remove_Ns=remove_Ns,\n",
    "    strandedness=strandedness,\n",
    "    bowtie_path=bowtie_path,\n",
    "    near_splice_junction_threshold=near_splice_junction_threshold,\n",
    "    threads=threads,\n",
    "    reference_cdna_fasta=reference_cdna_fasta,\n",
    "    reference_genome_fasta=reference_genome_fasta,\n",
    "    mutations_csv=mutations_csv,\n",
    "    save_exploded_df=save_exploded_df,\n",
    "    verbose=verbose,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vk filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "vk.filter(mutation_metadata_df_path = mutation_metadata_df_out_path_vk_info,\n",
    "          output_mcrs_fasta=mcrs_fasta_vk_filter,\n",
    "          output_metadata_df=output_metadata_df_vk_filter,\n",
    "          dlist_fasta=dlist_fasta,\n",
    "          output_dlist_fasta=dlist_fasta_vk_filter,\n",
    "          output_wt_mcrs_fa=wt_mcrs_fa_vk_filter,\n",
    "          create_t2g=True,\n",
    "          output_t2g=t2g_vk_filter,\n",
    "          output_t2g_wt=t2g_wt_vk_filter,\n",
    "          id_to_header_csv=id_to_header_csv,\n",
    "          output_id_to_header_csv=id_to_header_csv_vk_filter,\n",
    "          verbose=True,\n",
    "          return_df=False,\n",
    "          filters = fasta_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kb ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "if not os.path.exists(mutation_index):\n",
    "    kb_ref_command = [\"kb\", \"ref\", \"--workflow\", \"custom\", \"-t\", str(threads), \"-i\", mutation_index, \"--d-list\", dlist_kb_argument, \"-k\", str(k), mcrs_fasta_vk_filter]\n",
    "    subprocess.run(kb_ref_command, check=True)\n",
    "\n",
    "if not os.path.exists(wt_mcrs_index) and os.path.exists(wt_mcrs_fa_vk_filter):\n",
    "    kb_ref_command = [\"kb\", \"ref\", \"--workflow\", \"custom\", \"-t\", str(threads), \"-i\", wt_mcrs_index, \"--d-list\", \"None\", \"-k\", str(k), wt_mcrs_fa_vk_filter]\n",
    "    subprocess.run(kb_ref_command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-19 11:32:43,683]    INFO [ref_custom] Indexing /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_nov16/mcrs_filtered.fa to /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_nov16/mutation_reference_31.idx\n",
      "[2024-11-19 11:45:08,280]    INFO [ref_custom] Finished creating custom index\n"
     ]
    }
   ],
   "source": [
    "# mutation_index_31 = f\"{out_dir_notebook}/mutation_reference_31.idx\"\n",
    "# if not os.path.exists(mutation_index_31):\n",
    "#     kb_ref_command = [\"kb\", \"ref\", \"--workflow\", \"custom\", \"-t\", str(16), \"-i\", mutation_index_31, \"--d-list\", dlist_kb_argument, \"-k\", str(31), mcrs_fasta_vk_filter]\n",
    "#     subprocess.run(kb_ref_command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: kb ref on T2T reference genome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-18 11:22:04,574]    INFO [ref] Preparing /home/jrich/data/varseek_data_fresh/reference/T2T/GCF_009914755.1/GCF_009914755.1_T2T-CHM13v2.0_genomic.fna, /home/jrich/data/varseek_data_fresh/reference/T2T/GCF_009914755.1/genomic.gtf\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# import subprocess\n",
    "# out_dir_base = \"/home/jrich/data/varseek_data_fresh\"\n",
    "# reference_out_dir = os.path.join(out_dir_base, \"reference\")\n",
    "# threads = 16\n",
    "# k_standard = 31\n",
    "\n",
    "# from varseek.utils import download_t2t_reference_files\n",
    "# t2t_folder = f\"{reference_out_dir}/T2T/GCF_009914755.1\"\n",
    "# t2t_kb_folder = f\"{t2t_folder}/kb_index\"\n",
    "# standard_index = f\"{t2t_kb_folder}/index.idx\"\n",
    "# standard_t2g = f\"{t2t_kb_folder}/t2g.txt\"\n",
    "# standard_f1 = f\"{t2t_kb_folder}/f1.fa\"\n",
    "\n",
    "# if not os.path.exists(standard_index) or not os.path.exists(standard_t2g):\n",
    "#     os.makedirs(t2t_kb_folder, exist_ok=True)\n",
    "#     t2t_genome = f\"{t2t_folder}/GCF_009914755.1_T2T-CHM13v2.0_genomic.fna\"\n",
    "#     t2t_gtf = f\"{t2t_folder}/genomic.gtf\"\n",
    "    \n",
    "#     if not os.path.exists(t2t_genome) or not os.path.exists(t2t_gtf):\n",
    "#         os.makedirs(t2t_folder, exist_ok=True)\n",
    "#         t2t_genome, t2t_cdna, t2t_gtf = download_t2t_reference_files(t2t_folder)\n",
    "\n",
    "#     kb_ref_standard_command = f\"kb ref -k {k_standard} -i {standard_index} -g {standard_t2g} -f1 {standard_f1} -t {threads} {t2t_genome} {t2t_gtf}\"\n",
    "#     result = subprocess.run(kb_ref_standard_command, shell=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "varseek2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from varseek.utils import explode_df\n",
    "\n",
    "# mutation_metadata_df_path = \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_metadata_df_updated_vk_info.csv\"\n",
    "# mutation_metadata_df_out_path_exploded = \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_metadata_df_updated_vk_info_exploded.csv\"\n",
    "# columns_to_explode = [\"header\",\"order\",\"seq_ID\",\"mutation\",\"mutation_type\",\"wt_sequence\",\"nucleotide_positions\",\"actual_mutation\",\"mutation_cds\",\"mutation_aa\",\"GENOMIC_MUTATION_ID\",\"chromosome\",\"strand\",\"mutation_genome\",\"gene_name\",\"mutation_id\",\"start_mutation_position\",\"end_mutation_position\",\"nucleotide_positions_cdna\",\"actual_mutation_cdna\",\"start_mutation_position_cdna\",\"end_mutation_position_cdna\",\"header_genome\",\"header_cdna\",\"header_cds\",\"nucleotide_positions_genome\",\"actual_mutation_genome\",\"start_mutation_position_genome\",\"end_mutation_position_genome\",\"distance_to_nearest_splice_junction\",\"is_near_splice_junction_10\",\"nearby_mutations\",\"nearby_mutations_count\",\"has_a_nearby_mutation\"]\n",
    "\n",
    "# mutation_metadata_df = pd.read_csv(mutation_metadata_df_path)\n",
    "# mutation_metadata_df_exploded = explode_df(mutation_metadata_df, columns_to_explode)\n",
    "# mutation_metadata_df_exploded.to_csv(mutation_metadata_df_out_path_exploded, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import varseek as vk\n",
    "import os\n",
    "import sys\n",
    "import anndata as ad\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from varseek.utils import build_random_genome_read_df, fasta_to_fastq, create_mutant_t2g, fasta_to_fastq, find_genes_with_aligned_reads_for_kb_extract, calculate_metrics, create_stratified_metric_bar_plot, create_venn_diagram, get_header_set_from_fastq, plot_histogram, synthetic_data_summary_plot, plot_basic_bar_plot_from_dict, draw_confusion_matrix, check_for_read_kmer_in_mcrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_length = 150\n",
    "strand = None  # None for strand-agnostic (randomly-selected), \"f\" for forward, \"r\" for reverse, \"both\" for both - make sure this matches the reference genome (kropp build command) - strand = True -> \"f\" or \"r\" here; strand = False -> None or \"both\" here - note that the strand is randomly selected per *transcript*, such that all drawn reads will come from the same strand no matter what\n",
    "add_noise=False\n",
    "error_rate=0\n",
    "max_errors=0\n",
    "seq_id_column=\"seq_ID\"\n",
    "mut_column=\"mutation\"\n",
    "threads = 32\n",
    "\n",
    "\n",
    "dlist_kb_argument = \"None\"  # path to dlist fasta file or \"None\" (including the quotes)\n",
    "k = 55\n",
    "\n",
    "run_kb_extract_slow = True\n",
    "run_kb_extract_in_notebook = True\n",
    "number_of_parallel_processes = 32  # used iff run_kb_extract_in_notebook == True\n",
    "chunk_size = 3000  # used iff run_kb_extract_in_notebook == True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Paths\n",
    "out_dir_notebook=\"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp\"\n",
    "\n",
    "#!!!CHANGE TO GRCH37 (commented)\n",
    "mutation_metadata_df = \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_t2t/mutation_metadata_df_updated_vk_info_exploded.csv\" # \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_metadata_df_updated_vk_info_exploded.csv\"\n",
    "#!!!CHANGE TO GRCH37 (commented)\n",
    "\n",
    "sequences = \"/home/jrich/data/varseek_data_fresh/reference/ensembl_grch37_release93/Homo_sapiens.GRCh37.cdna.all.fa\"\n",
    "reference_out_dir = \"/home/jrich/data/varseek_data_fresh/reference\"\n",
    "mutation_index = \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx\"\n",
    "mutation_t2g = \"/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/t2g_filtered.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_reads_fastQ = f\"{out_dir_notebook}/synthetic_reads.fq\"\n",
    "out_dir_vk_build = f\"{out_dir_notebook}/vk_build\"\n",
    "\n",
    "kb_count_out = f\"{out_dir_notebook}/kb_count_out\"\n",
    "kb_extract_out_total = f\"{out_dir_notebook}/kb_extract_out_total\"\n",
    "kb_extract_out_total_mm = f\"{out_dir_notebook}/kb_extract_out_total_mm\"\n",
    "kb_extract_out_all_slow = f\"{out_dir_notebook}/kb_extract_out_all_slow\"\n",
    "\n",
    "os.makedirs(out_dir_notebook, exist_ok=True)\n",
    "\n",
    "if strand is None or strand == \"both\":\n",
    "    strand_kb_extract = \"unstranded\"\n",
    "elif strand == \"f\":\n",
    "    strand_kb_extract = \"forward\"\n",
    "elif strand == \"r\":\n",
    "    strand_kb_extract = \"reverse\"\n",
    "\n",
    "mutation_metadata_df_out = mutation_metadata_df.replace(\".csv\", \"_with_synthetic_read_info.csv\")\n",
    "read_df_out = synthetic_reads_fastQ.replace(\".fq\", \".csv\")\n",
    "\n",
    "seed=42\n",
    "read_df = None\n",
    "mutation_metadata_df_path = mutation_metadata_df\n",
    "adata_path = f\"{kb_count_out}/counts_unfiltered/adata.h5ad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run notebook 1 up through kb ref, or run the following commands\n",
    "# vk build\n",
    "# vk info with save_exploded_df=True\n",
    "# vk filter\n",
    "# kb ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple synthetic reads - erase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_134811/3237759037.py:4: DtypeWarning: Columns (12,52,67,69) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  mutation_metadata_df = pd.read_csv(mutation_metadata_df_path)\n"
     ]
    }
   ],
   "source": [
    "#!!! TEMP\n",
    "import varseek\n",
    "mutation_metadata_df_path = mutation_metadata_df\n",
    "mutation_metadata_df = pd.read_csv(mutation_metadata_df_path)\n",
    "\n",
    "sim_data_df_path = \"/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/vk_build/sim_data_df.csv\"\n",
    "sim_data_df = pd.read_csv(sim_data_df_path, usecols=[\"header\", \"mutant_sequence\", \"wt_sequence\"])\n",
    "\n",
    "sim_data_df.rename(\n",
    "    columns={\n",
    "        \"mutant_sequence\": \"mutant_sequence_read_parent\",\n",
    "        \"wt_sequence\": \"wt_sequence_read_parent\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "sim_data_df[\"mutant_sequence_read_parent_rc\"] = sim_data_df[\"mutant_sequence_read_parent\"].apply(varseek.varseek_build.reverse_complement)\n",
    "sim_data_df[\"mutant_sequence_read_parent_length\"] = sim_data_df[\"mutant_sequence_read_parent\"].str.len()\n",
    "\n",
    "sim_data_df[\"wt_sequence_read_parent_rc\"] = sim_data_df[\"wt_sequence_read_parent\"].apply(varseek.varseek_build.reverse_complement)\n",
    "sim_data_df[\"wt_sequence_read_parent_length\"] = sim_data_df[\"wt_sequence_read_parent\"].str.len()\n",
    "\n",
    "mutation_metadata_df = pd.merge(\n",
    "    mutation_metadata_df,\n",
    "    sim_data_df[\n",
    "        [\n",
    "            \"header\",\n",
    "            \"mutant_sequence_read_parent\",\n",
    "            \"mutant_sequence_read_parent_rc\",\n",
    "            \"mutant_sequence_read_parent_length\",\n",
    "            \"wt_sequence_read_parent\",\n",
    "            \"wt_sequence_read_parent_rc\",\n",
    "            \"wt_sequence_read_parent_length\",\n",
    "        ]\n",
    "    ],\n",
    "    on=\"header\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_read_parent\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove the module from sys.modules\n",
    "if 'varseek.sim' in sys.modules:\n",
    "    del sys.modules['varseek.sim']\n",
    "\n",
    "# Import the module and reload it\n",
    "import varseek.varseek_sim\n",
    "importlib.reload(varseek.varseek_sim)\n",
    "import varseek as vk\n",
    "\n",
    "# instead of using vk.sim() as before, I must explicitely use vk.varseek_sim.sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:00:57 - INFO - Initial number of mutations: 5344110\n",
      "15:01:24 - INFO - Filtered 60168 mutations dlist with equal none - 5283942 mutations remaining\n",
      "15:01:31 - INFO - Filtered 160733 mutations kmer_overlap_in_mcrs_reference with isfalse False - 5123209 mutations remaining\n",
      "15:01:55 - INFO - Output fasta file with filtered mutations: None\n",
      "15:01:55 - INFO - t2g file containing mutated sequences created at None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'composition'\n",
      "Wrote 59197 mutations to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n"
     ]
    }
   ],
   "source": [
    "#!!! TEMP\n",
    "read_fq_path_specific = f\"{out_dir_notebook}/synthetic_reads.fq\"\n",
    "\n",
    "conditions = ['dlist-equal=none', 'kmer_overlap_in_mcrs_reference-isfalse']\n",
    "\n",
    "\n",
    "if not os.path.exists(mutation_metadata_df_out) and not os.path.exists(read_df_out):\n",
    "    simulated_df_dict = vk.varseek_sim.sim(\n",
    "        mutation_metadata_df = mutation_metadata_df,\n",
    "        fastq_output_path = synthetic_reads_fastQ,\n",
    "        sample_type=\"m\",\n",
    "        number_of_mutations_to_sample=200,\n",
    "        strand=strand,\n",
    "        number_of_reads_per_sample=\"all\",  # not used when number_of_reads_per_sample_m and number_of_reads_per_sample_w are provided\n",
    "        read_length=read_length,\n",
    "        seed=seed,\n",
    "        add_noise=add_noise,\n",
    "        error_rate=error_rate,\n",
    "        max_errors=max_errors,\n",
    "        with_replacement=False,\n",
    "        sequences=sequences,\n",
    "        mutation_metadata_df_path=mutation_metadata_df_path,\n",
    "        seq_id_column=seq_id_column,\n",
    "        mut_column=mut_column,\n",
    "        reference_out_dir=reference_out_dir,\n",
    "        out_dir_vk_build=out_dir_vk_build,\n",
    "        filters=conditions,\n",
    "        read_df_out=read_df_out,\n",
    "        mutation_metadata_df_out=mutation_metadata_df_out,\n",
    "    )\n",
    "\n",
    "    read_df, mutation_metadata_df = simulated_df_dict[\"read_df\"], simulated_df_dict[\"mutation_metadata_df\"]\n",
    "else:\n",
    "    read_df = pd.read_csv(read_df_out)\n",
    "    mutation_metadata_df = pd.read_csv(mutation_metadata_df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complex synthetic reads - uncomment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_mutations_to_sample = 100\n",
    "# m_list = [1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64, 128, 256, 512]\n",
    "# w_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 16, 32, 64, 128, 256, 512]\n",
    "# conditions = ['mutation_type-equal=substitution', 'mutation_type-notequal=substitution', 'dlist-equal=none', 'dlist-notequal=none', 'kmer_overlap_in_mcrs_reference-isfalse', 'kmer_overlap_in_mcrs_reference-istrue', 'is_near_splice_junction_10-isfalse', 'is_near_splice_junction_10-istrue']\n",
    "\n",
    "# random.shuffle(m_list)\n",
    "# random.shuffle(w_list)\n",
    "\n",
    "# if not os.path.exists(mutation_metadata_df_out) and not os.path.exists(read_df_out):\n",
    "#     for m in m_list:\n",
    "#         for w in w_list:\n",
    "#             for condition in conditions:\n",
    "#                 read_fq_path_specific = synthetic_reads_fastQ.replace(\".fq\", f\"_m{m}_w{w}_{condition.replace('=', '_')}.fq\")\n",
    "#                 condition_added_list = [condition, 'included_in_synthetic_reads-isnottrue']\n",
    "                \n",
    "#                 simulated_df_dict = vk.sim(\n",
    "#                     mutation_metadata_df = mutation_metadata_df,\n",
    "#                     fastq_output_path = read_fq_path_specific,\n",
    "#                     fastq_parent_path = synthetic_reads_fastQ,\n",
    "#                     read_df_parent=read_df,\n",
    "#                     sample_type=\"all\",\n",
    "#                     number_of_mutations_to_sample=number_of_mutations_to_sample,\n",
    "#                     strand=strand,\n",
    "#                     number_of_reads_per_sample=None,  # not used when number_of_reads_per_sample_m and number_of_reads_per_sample_w are provided\n",
    "#                     number_of_reads_per_sample_m=m,\n",
    "#                     number_of_reads_per_sample_w=w,\n",
    "#                     read_length=read_length,\n",
    "#                     seed=seed,\n",
    "#                     add_noise=add_noise,\n",
    "#                     error_rate=error_rate,\n",
    "#                     max_errors=max_errors,\n",
    "#                     with_replacement=False,\n",
    "#                     filters=condition_added_list,\n",
    "#                     sequences=sequences,\n",
    "#                     mutation_metadata_df_path=mutation_metadata_df_path,\n",
    "#                     seq_id_column=seq_id_column,\n",
    "#                     mut_column=mut_column,\n",
    "#                     reference_out_dir=reference_out_dir,\n",
    "#                     out_dir_vk_build=out_dir_vk_build,\n",
    "#                 )\n",
    "\n",
    "#                 mutation_metadata_df, read_df = simulated_df_dict['mutation_metadata_df'], simulated_df_dict['read_df']\n",
    "# else:\n",
    "#     read_df = pd.read_csv(read_df_out)\n",
    "#     mutation_metadata_df = pd.read_csv(mutation_metadata_df_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random genome - uncomment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # do kv sim with random genome\n",
    "# mutation_metadata_df['start_position_for_which_read_contains_mutation_cdna'] = mutation_metadata_df['start_mutation_position_cdna'] - read_length + 1\n",
    "# mutation_metadata_df['start_position_for_which_read_contains_mutation_genome'] = mutation_metadata_df['start_mutation_position_genome'] - read_length + 1\n",
    "\n",
    "# number_of_random_reads_cdna = 10\n",
    "# number_of_random_reads_genome = 10\n",
    "\n",
    "# # read_df = build_random_genome_read_df(reference_fasta_file_path = reference_cdna_fasta, mutation_metadata_df = mutation_metadata_df, read_df = read_df, n = number_of_random_reads_cdna, read_length = read_length, input_type = \"transcriptome\", strand = None)\n",
    "# # read_df = build_random_genome_read_df(reference_fasta_file_path = reference_genome_fasta, mutation_metadata_df = mutation_metadata_df, read_df = read_df, n = number_of_random_reads_genome, read_length = read_length, input_type = \"genome\", strand = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-08 15:15:00,944]    INFO [count] Using index /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx to generate BUS file to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out from\n",
      "[2024-11-08 15:15:00,944]    INFO [count]         /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:15:42,291]    INFO [count] Sorting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/output.bus to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/tmp/output.s.bus\n",
      "[2024-11-08 15:15:45,299]    INFO [count] Inspecting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/tmp/output.s.bus\n",
      "[2024-11-08 15:15:46,405]    INFO [count] Generating count matrix /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/counts_unfiltered/cells_x_genes from BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/tmp/output.s.bus\n",
      "[2024-11-08 15:16:10,021]    INFO [count] Writing gene names to file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/counts_unfiltered/cells_x_genes.genes.names.txt\n",
      "[2024-11-08 15:16:16,841] WARNING [count] 5259437 gene IDs do not have corresponding valid gene names. These genes will use their gene IDs instead.\n",
      "[2024-11-08 15:16:18,027]    INFO [count] Reading matrix /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/counts_unfiltered/cells_x_genes.mtx\n",
      "[2024-11-08 15:16:35,486]    INFO [count] Writing matrix to h5ad /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_count_out/counts_unfiltered/adata.h5ad\n"
     ]
    }
   ],
   "source": [
    "# kb count\n",
    "if not os.path.exists(kb_count_out) or len(os.listdir(kb_count_out)) == 0:\n",
    "    #!!! add \"--num\", if this stays around\n",
    "    kb_count_command = [\"kb\", \"count\", \"-t\", str(threads), \"-k\", str(k), \"-i\", mutation_index, \"-g\", mutation_t2g, \"-x\", \"bulk\", \"--h5ad\", \"--parity\", \"single\", \"-o\", kb_count_out, synthetic_reads_fastQ]\n",
    "    subprocess.run(kb_count_command, check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lay out kb extract commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-11-08 15:16:55,562]   DEBUG [main] Printing verbose output\n",
      "[2024-11-08 15:16:57,767]   DEBUG [main] kallisto binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64\n",
      "[2024-11-08 15:16:57,767]   DEBUG [main] bustools binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools\n",
      "[2024-11-08 15:16:57,767]   DEBUG [main] Creating `/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp` directory\n",
      "[2024-11-08 15:16:57,773]   DEBUG [main] Namespace(list=False, command='extract', tmp=None, keep_tmp=False, verbose=True, fastq='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq', i='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx', targets=None, target_type='gene', extract_all=False, extract_all_fast=True, extract_all_unmapped=False, mm=False, g='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/t2g_filtered.txt', o='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total', t=32, strand='unstranded', aa=False, N=None, kallisto='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64', bustools='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools', opt_off=False, k=55)\n",
      "[2024-11-08 15:16:59,536]    INFO [extract] Performing alignment using kallisto...\n",
      "[2024-11-08 15:16:59,536]    INFO [extract] Using index /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx to generate BUS file to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp from\n",
      "[2024-11-08 15:16:59,536]    INFO [extract]         /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:16:59,536]   DEBUG [extract] kallisto_k64 bus -i /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp -x bulk -t 32 --num --unstranded /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:16:59,638]   DEBUG [extract] \n",
      "[2024-11-08 15:17:08,859]   DEBUG [extract] [index] k-mer length: 55\n",
      "[2024-11-08 15:17:28,694]   DEBUG [extract] [index] number of targets: 5,259,437\n",
      "[2024-11-08 15:17:28,795]   DEBUG [extract] [index] number of k-mers: 287,444,853\n",
      "[2024-11-08 15:17:28,795]   DEBUG [extract] [quant] running in single-end mode\n",
      "[2024-11-08 15:17:28,795]   DEBUG [extract] [quant] will process file 1: /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:17:32,202]   DEBUG [extract] [quant] finding pseudoalignments for all files ... done\n",
      "[2024-11-08 15:17:32,202]   DEBUG [extract] [quant] processed 59,197 reads, 29,569 reads pseudoaligned\n",
      "[2024-11-08 15:17:36,512]   DEBUG [extract] \n",
      "[2024-11-08 15:17:43,374]    INFO [extract] Alignment complete. Beginning extraction of reads using bustools...\n",
      "[2024-11-08 15:17:43,375]   DEBUG [extract] Removing equivalence classes that map to multiple genes from /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output.bus\n",
      "[2024-11-08 15:17:43,375]   DEBUG [extract] Fetching equivalence classes that map to multiple genes...\n",
      "[2024-11-08 15:21:28,344]   DEBUG [extract] Found the following equivalence classes that map to multiple genes: \n",
      "[2024-11-08 15:21:29,217]   DEBUG [extract] No equivalence classes that map to multiple genes found.\n",
      "[2024-11-08 15:21:29,217]    INFO [extract] Sorting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output.bus to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output_extracted_sorted.bus\n",
      "[2024-11-08 15:21:29,218]   DEBUG [extract] bustools sort -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output_extracted_sorted.bus -T tmp -t 8 -m 2G --flags /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output.bus\n",
      "[2024-11-08 15:21:30,923]   DEBUG [extract] all fits in buffer\n",
      "[2024-11-08 15:21:32,225]   DEBUG [extract] Read in 29569 BUS records\n",
      "[2024-11-08 15:21:32,225]   DEBUG [extract] reading time 0s\n",
      "[2024-11-08 15:21:32,226]   DEBUG [extract] sorting time 0s\n",
      "[2024-11-08 15:21:32,226]   DEBUG [extract] writing time 0s\n",
      "[2024-11-08 15:21:32,226]    INFO [extract] Extracting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output_extracted_sorted.bus to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/all\n",
      "[2024-11-08 15:21:32,226]   DEBUG [extract] bustools extract -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/all -f /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq -N 1 /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp/output_extracted_sorted.bus\n",
      "[2024-11-08 15:21:33,429]   DEBUG [extract] Read in 29569 BUS records\n",
      "[2024-11-08 15:21:33,430]   DEBUG [main] Removing `/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total/tmp` directory\n",
      "[2024-11-08 15:21:34,880]   DEBUG [main] Printing verbose output\n",
      "[2024-11-08 15:21:37,087]   DEBUG [main] kallisto binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64\n",
      "[2024-11-08 15:21:37,087]   DEBUG [main] bustools binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools\n",
      "[2024-11-08 15:21:37,087]   DEBUG [main] Creating `/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp` directory\n",
      "[2024-11-08 15:21:37,092]   DEBUG [main] Namespace(list=False, command='extract', tmp=None, keep_tmp=False, verbose=True, fastq='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq', i='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx', targets=None, target_type='gene', extract_all=False, extract_all_fast=True, extract_all_unmapped=False, mm=True, g='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/t2g_filtered.txt', o='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm', t=32, strand='unstranded', aa=False, N=None, kallisto='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64', bustools='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools', opt_off=False, k=55)\n",
      "[2024-11-08 15:21:38,823]    INFO [extract] Performing alignment using kallisto...\n",
      "[2024-11-08 15:21:38,823]    INFO [extract] Using index /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx to generate BUS file to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp from\n",
      "[2024-11-08 15:21:38,823]    INFO [extract]         /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:21:38,823]   DEBUG [extract] kallisto_k64 bus -i /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp -x bulk -t 32 --num --unstranded /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:21:38,925]   DEBUG [extract] \n",
      "[2024-11-08 15:21:47,344]   DEBUG [extract] [index] k-mer length: 55\n",
      "[2024-11-08 15:22:07,786]   DEBUG [extract] [index] number of targets: 5,259,437\n",
      "[2024-11-08 15:22:07,887]   DEBUG [extract] [index] number of k-mers: 287,444,853\n",
      "[2024-11-08 15:22:07,887]   DEBUG [extract] [quant] running in single-end mode\n",
      "[2024-11-08 15:22:07,887]   DEBUG [extract] [quant] will process file 1: /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:22:11,294]   DEBUG [extract] [quant] finding pseudoalignments for all files ... done\n",
      "[2024-11-08 15:22:11,295]   DEBUG [extract] [quant] processed 59,197 reads, 29,569 reads pseudoaligned\n",
      "[2024-11-08 15:22:16,105]   DEBUG [extract] \n",
      "[2024-11-08 15:22:22,878]    INFO [extract] Alignment complete. Beginning extraction of reads using bustools...\n",
      "[2024-11-08 15:22:22,878]    INFO [extract] Sorting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output.bus to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output_extracted_sorted.bus\n",
      "[2024-11-08 15:22:22,878]   DEBUG [extract] bustools sort -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output_extracted_sorted.bus -T tmp -t 8 -m 2G --flags /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output.bus\n",
      "[2024-11-08 15:22:24,584]   DEBUG [extract] all fits in buffer\n",
      "[2024-11-08 15:22:25,886]   DEBUG [extract] Read in 29569 BUS records\n",
      "[2024-11-08 15:22:25,886]   DEBUG [extract] reading time 0.01s\n",
      "[2024-11-08 15:22:25,886]   DEBUG [extract] sorting time 0s\n",
      "[2024-11-08 15:22:25,886]   DEBUG [extract] writing time 0s\n",
      "[2024-11-08 15:22:25,886]    INFO [extract] Extracting BUS file /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output_extracted_sorted.bus to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/all\n",
      "[2024-11-08 15:22:25,887]   DEBUG [extract] bustools extract -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/all -f /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq -N 1 /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp/output_extracted_sorted.bus\n",
      "[2024-11-08 15:22:27,090]   DEBUG [extract] Read in 29569 BUS records\n",
      "[2024-11-08 15:22:27,090]   DEBUG [main] Removing `/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_total_mm/tmp` directory\n",
      "[2024-11-08 15:22:28,339]   DEBUG [main] Printing verbose output\n",
      "[2024-11-08 15:22:30,545]   DEBUG [main] kallisto binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64\n",
      "[2024-11-08 15:22:30,545]   DEBUG [main] bustools binary located at /home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools\n",
      "[2024-11-08 15:22:30,545]   DEBUG [main] Creating `/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_all_slow/tmp` directory\n",
      "[2024-11-08 15:22:30,551]   DEBUG [main] Namespace(list=False, command='extract', tmp=None, keep_tmp=False, verbose=True, fastq='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq', i='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx', targets=None, target_type='gene', extract_all=True, extract_all_fast=False, extract_all_unmapped=False, mm=True, g='/home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/t2g_filtered.txt', o='/home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_all_slow', t=32, strand='unstranded', aa=False, N=None, kallisto='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/kallisto/kallisto_k64', bustools='/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools', opt_off=False, k=55)\n",
      "[2024-11-08 15:22:32,253]    INFO [extract] Performing alignment using kallisto...\n",
      "[2024-11-08 15:22:32,253]    INFO [extract] Using index /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx to generate BUS file to /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_all_slow/tmp from\n",
      "[2024-11-08 15:22:32,253]    INFO [extract]         /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:22:32,253]   DEBUG [extract] kallisto_k64 bus -i /home/jrich/data/varseek_data_fresh/vk_build_pipeline_grch37_ensembl93/mutation_reference.idx -o /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/kb_extract_out_all_slow/tmp -x bulk -t 32 --num --unstranded /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:22:32,355]   DEBUG [extract] \n",
      "[2024-11-08 15:22:41,474]   DEBUG [extract] [index] k-mer length: 55\n",
      "[2024-11-08 15:23:01,407]   DEBUG [extract] [index] number of targets: 5,259,437\n",
      "[2024-11-08 15:23:01,608]   DEBUG [extract] [index] number of k-mers: 287,444,853\n",
      "[2024-11-08 15:23:01,608]   DEBUG [extract] [quant] running in single-end mode\n",
      "[2024-11-08 15:23:01,608]   DEBUG [extract] [quant] will process file 1: /home/jrich/data/varseek_data_fresh/vk_sim_2024nov24_temp/synthetic_reads.fq\n",
      "[2024-11-08 15:23:05,216]   DEBUG [extract] [quant] finding pseudoalignments for all files ... done\n",
      "[2024-11-08 15:23:05,216]   DEBUG [extract] [quant] processed 59,197 reads, 29,569 reads pseudoaligned\n",
      "[2024-11-08 15:23:09,326]   DEBUG [extract] \n",
      "[2024-11-08 15:23:15,495]    INFO [extract] Alignment complete. Beginning extraction of reads using bustools...\n"
     ]
    }
   ],
   "source": [
    "# run kb extract script\n",
    "if not os.path.exists(kb_extract_out_total):\n",
    "    kb_extract_crude_command = f\"kb extract --extract_all_fast --strand {strand_kb_extract} --verbose -k {k} -t {threads} -o {kb_extract_out_total} -i {mutation_index} -g {mutation_t2g} {synthetic_reads_fastQ}\"\n",
    "    if run_kb_extract_in_notebook:\n",
    "        try:\n",
    "            result = subprocess.run(kb_extract_crude_command, shell=True, check=True, text=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"An error occurred:\")\n",
    "            print(e)\n",
    "            print(\"Standard Error Output:\")\n",
    "            print(e.stderr)\n",
    "    else:\n",
    "        print(kb_extract_crude_command)\n",
    "\n",
    "if not os.path.exists(kb_extract_out_total_mm):\n",
    "    kb_extract_crude_opposite_mm_command = f\"kb extract --extract_all_fast --strand {strand_kb_extract} --mm --verbose -k {k} -t {threads} -o {kb_extract_out_total_mm} -i {mutation_index} -g {mutation_t2g} {synthetic_reads_fastQ}\"\n",
    "    if run_kb_extract_in_notebook:\n",
    "        try:\n",
    "            result = subprocess.run(kb_extract_crude_opposite_mm_command, shell=True, check=True, text=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"An error occurred:\")\n",
    "            print(e)\n",
    "            print(\"Standard Error Output:\")\n",
    "            print(e.stderr)\n",
    "    else:\n",
    "        print(kb_extract_crude_opposite_mm_command)\n",
    "\n",
    "\n",
    "if run_kb_extract_slow and not os.path.exists(kb_extract_out_all_slow):\n",
    "    # TODO: ensure that this is the same as listing each MCRS individually\n",
    "    kb_extract_command = f\"kb extract --strand {strand_kb_extract} --verbose -k {k} --mm -t {threads} --extract_all -o {kb_extract_out_all_slow} -i {mutation_index} -g {mutation_t2g} {synthetic_reads_fastQ}\"\n",
    "    # # removed {multimapped_line} in favor of always doing --mm because I can just filter out multimapped reads later\n",
    "    # # can replace --targets {mcrs_string_with_aligned_reads} with --extract_all for the same final effect, but it will output all files at once rather than one at a time (not good if I want to check progress throughout or break up for multithreading, but it can avoid the issue where mcrs_string_with_aligned_reads is too many characters)\n",
    "    # # adata_path = f\"{kb_count_out}/counts_unfiltered/adata.h5ad\"\n",
    "    # # mapped_mutations_string = find_genes_with_aligned_reads_for_kb_extract(adata_path)\n",
    "    # # mcrs_set_with_aligned_reads = set(mapped_mutations_string.split())\n",
    "    # mcrs_string_with_aligned_reads = ' '.join(f\"'{x}'\" for x in mcrs_set_with_aligned_reads)\n",
    "    # kb_extract_command = f\"kb extract --verbose -k {k} --mm -t {threads} --targets {mcrs_string_with_aligned_reads} -o {kb_extract_out_all_slow} -i {mutation_index} -g {mutation_t2g} {synthetic_reads_fastQ}\"\n",
    "    if run_kb_extract_in_notebook:\n",
    "        try:\n",
    "            result = subprocess.run(kb_extract_command, shell=True, check=True, text=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"An error occurred:\")\n",
    "            print(e)\n",
    "            print(\"Standard Error Output:\")\n",
    "            print(e.stderr)\n",
    "    else:\n",
    "        print(kb_extract_command)\n",
    "\n",
    "if not run_kb_extract_in_notebook:    \n",
    "    print(\"Run the following command in tmux to extract reads in a multithreaded fashion:\")\n",
    "    print(f\"python3 /home/jrich/Desktop/CART_prostate_sc/src/run_kb_extract.py -k {k} -t {threads} --strand {strand_kb_extract} --parallel {number_of_parallel_processes} --chunk {chunk_size} --adata {adata_path} --fastq {synthetic_reads_fastQ} -i {mutation_index} -g {mutation_t2g} --no-mm-fast-out {kb_extract_out_total} --mm-fast-out {kb_extract_out_total_mm} --slow-out {kb_extract_out_all_slow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (not os.path.exists(kb_extract_out_total) or (run_kb_extract_slow and not os.path.exists(kb_extract_out_all_slow))):\n",
    "    raise Exception(\"kb extract has not been run. Please run it before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY BUS MY BUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from varseek.utils import make_bus_df\n",
    "kb_count_out_mm = f\"{out_dir_notebook}/kb_count_out_mm\"\n",
    "if not os.path.exists(kb_count_out_mm) or len(os.listdir(kb_count_out_mm)) == 0:\n",
    "    kb_count_command = [\"kb\", \"count\", \"-t\", str(threads), \"--mm\", \"-k\", str(k), \"-i\", mutation_index, \"-g\", mutation_t2g, \"-x\", \"bulk\", \"--num\", \"--h5ad\", \"--parity\", \"single\", \"-o\", kb_count_out_mm, synthetic_reads_fastQ]\n",
    "    subprocess.run(kb_count_command, check=True)\n",
    "\n",
    "bus_df = make_bus_df(kallisto_out = kb_count_out_mm, fastq_file = synthetic_reads_fastQ, t2g_file = mutation_t2g, mm = True, union = False, assay = \"bulk\", bustools = \"/home/jrich/miniconda3/envs/varseek/lib/python3.10/site-packages/kb_python/bins/linux/bustools/bustools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: edit this below - mcrs_df is output of vk info, and mutation_metadata_df is exploded output of vk_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add columns to mcrs_df for any_noisy_reads and all_noisy_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_path = f\"{kb_count_out}/counts_unfiltered/adata.h5ad\"\n",
    "adata = ad.read_h5ad(adata_path)\n",
    "\n",
    "mapped_mutations_string = find_genes_with_aligned_reads_for_kb_extract(adata_path)\n",
    "\n",
    "mcrs_set_with_aligned_reads = set(mapped_mutations_string.split())\n",
    "\n",
    "# Find the indices of non-zero values in adata.X\n",
    "non_zero_indices = np.nonzero(adata.X)\n",
    "\n",
    "# Get the non-zero values\n",
    "non_zero_values = np.squeeze(np.asarray(adata.X[non_zero_indices])).astype(int)\n",
    "\n",
    "# Get the corresponding gene names\n",
    "mcrs_headers = adata.var.index[non_zero_indices[1]].to_numpy().flatten()\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "result_df = pd.DataFrame({\n",
    "    'mcrs_header': mcrs_headers,\n",
    "    'number_of_reads_aligned_to_this_item': non_zero_values\n",
    "})\n",
    "\n",
    "mutation_metadata_df = mutation_metadata_df.merge(result_df, on='mcrs_header', how='left')\n",
    "mutation_metadata_df['received_an_aligned_read'] = ~pd.isna(mutation_metadata_df['number_of_reads_aligned_to_this_item'])\n",
    "\n",
    "# # set to int - will need to do Int64 to work\n",
    "# mutation_metadata_df['number_of_reads_mutant'] = mutation_metadata_df['number_of_reads_mutant'].astype(int)\n",
    "# mutation_metadata_df['number_of_reads_wt'] = mutation_metadata_df['number_of_reads_wt'].astype(int)\n",
    "# mutation_metadata_df['number_of_reads_aligned_to_this_item'] = mutation_metadata_df['number_of_reads_aligned_to_this_item'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_value_to_list(header, indices_list):\n",
    "    return [f\"{header}_{index}\" for index in indices_list]\n",
    "\n",
    "mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == False) | (pd.isna(mutation_metadata_df['list_of_read_starting_indices_mutant'])), 'list_of_read_starting_indices_mutant_copy'] = mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == False) | (pd.isna(mutation_metadata_df['list_of_read_starting_indices_mutant'])), 'list_of_read_starting_indices_mutant']\n",
    "mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == True) & (~pd.isna(mutation_metadata_df['list_of_read_starting_indices_mutant'])), 'list_of_read_starting_indices_mutant_copy'] = mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == True) & (~pd.isna(mutation_metadata_df['list_of_read_starting_indices_mutant']))].apply(lambda row: concatenate_value_to_list(row['header'], row['list_of_read_starting_indices_mutant']), axis=1)\n",
    "\n",
    "\n",
    "mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == False) | (pd.isna(mutation_metadata_df['list_of_read_starting_indices_wt'])), 'list_of_read_starting_indices_wt_copy'] = mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == False) | (pd.isna(mutation_metadata_df['list_of_read_starting_indices_wt'])), 'list_of_read_starting_indices_wt']\n",
    "mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == True) & (~pd.isna(mutation_metadata_df['list_of_read_starting_indices_wt'])), 'list_of_read_starting_indices_wt_copy'] = mutation_metadata_df.loc[(mutation_metadata_df['concatenated_headers_in_mcrs'] == True) & (~pd.isna(mutation_metadata_df['list_of_read_starting_indices_wt']))].apply(lambda row: concatenate_value_to_list(row['header'], row['list_of_read_starting_indices_wt']), axis=1)\n",
    "\n",
    "\n",
    "agg_dict = {\n",
    "    'included_in_synthetic_reads_mutant': 'any',  # OR across rows\n",
    "    'included_in_synthetic_reads_wt': 'any',      # OR across rows\n",
    "    'number_of_reads_wt': 'sum',                  # Sum across rows\n",
    "    'number_of_reads_mutant': 'sum'               # Sum across rows\n",
    "}\n",
    "\n",
    "for col in mutation_metadata_df.columns:\n",
    "    if col not in agg_dict and col != 'mcrs_header':  # Skip 'mcrs_header'\n",
    "        agg_dict[col] = 'first'\n",
    "\n",
    "unique_mcrs_df_original_columns = mutation_metadata_df.columns\n",
    "unique_mcrs_df = mutation_metadata_df.groupby('mcrs_header').agg(agg_dict).reset_index()\n",
    "unique_mcrs_df = unique_mcrs_df[unique_mcrs_df_original_columns]\n",
    "\n",
    "unique_mcrs_df['tumor_purity'] = unique_mcrs_df['number_of_reads_mutant'] / unique_mcrs_df['number_of_reads_wt']\n",
    "\n",
    "unique_mcrs_df['tumor_purity'] = np.where(\n",
    "    np.isnan(unique_mcrs_df['tumor_purity']), \n",
    "    np.nan,  # Keep NaN as NaN\n",
    "    unique_mcrs_df['tumor_purity']  # Keep the result for valid divisions\n",
    ")\n",
    "\n",
    "unique_mcrs_df = unique_mcrs_df[['mcrs_header', 'mcrs_sequence', 'mcrs_mutation_type', 'mcrs_sequence_length', 'dlist', 'number_of_alignments_to_normal_human_reference_cdna', 'number_of_alignments_to_normal_human_reference_genome', 'number_of_kmers_with_overlap_to_other_mcrs_items_in_mcrs_reference', 'number_of_mcrs_items_with_overlapping_kmers_in_mcrs_reference', 'kmer_overlap_in_mcrs_reference', 'distance_to_nearest_splice_junction', 'is_near_splice_junction', 'included_in_synthetic_reads_wt', 'included_in_synthetic_reads_mutant', 'received_an_aligned_read', 'number_of_reads_wt', 'number_of_reads_mutant', 'tumor_purity', 'list_of_read_starting_indices_wt_copy', 'list_of_read_starting_indices_mutant_copy', 'number_of_reads_aligned_to_this_item', 'concatenated_headers_in_mcrs']]\n",
    "unique_mcrs_df.rename(columns={'list_of_read_starting_indices_wt_copy': 'list_of_read_starting_indices_wt', 'list_of_read_starting_indices_mutant_copy': 'list_of_read_starting_indices_mutant'}, inplace=True)\n",
    "unique_mcrs_df_included_in_synthetic_reads = unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_wt'] | unique_mcrs_df['included_in_synthetic_reads_mutant']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for unique_read_df_column in [\"region_included_in_mcrs_reference\"]:\n",
    "    synthetic_data_summary_plot(read_df, unique_read_df_column, out_path = f\"{plot_output_folder}/synthetic_data_summary_{unique_read_df_column}.png\")\n",
    "\n",
    "for unique_mcrs_df_column in [\"mcrs_mutation_type\", \"distance_to_nearest_splice_junction\", \"number_of_kmers_with_overlap_to_other_mcrs_items_in_mcrs_reference\", \"number_of_mcrs_items_with_overlapping_kmers_in_mcrs_reference\", \"number_of_alignments_to_normal_human_reference_cdna\", \"number_of_alignments_to_normal_human_reference_genome\", \"dlist\", \"number_of_reads_mutant\", \"number_of_reads_wt\", \"tumor_purity\"]:\n",
    "    synthetic_data_summary_plot(unique_mcrs_df_included_in_synthetic_reads, unique_mcrs_df_column, out_path = f\"{plot_output_folder}/synthetic_data_summary_{unique_mcrs_df_column}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective of reads\n",
    "\n",
    "Big picture - especially useful when only mutant reads (tells us FNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {kb_count_out}/run_info.json | grep -E '\"n_targets\"|\"n_processed\"|\"n_pseudoaligned\"|\"n_unique\"|\"p_pseudoaligned\"|\"p_unique\"'\n",
    "\n",
    "with open(f\"{kb_count_out}/run_info.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "total_reads = data.get(\"n_processed\", None)\n",
    "n_pseudoaligned = data.get(\"n_pseudoaligned\", None)\n",
    "n_unique = data.get(\"n_unique\", None)\n",
    "n_multimapped = n_pseudoaligned - n_unique\n",
    "\n",
    "if check_assertions:\n",
    "    assert total_reads == n_pseudoaligned, \"Total reads and pseudoaligned reads do not match\"\n",
    "    assert total_reads == n_unique, \"Total reads and unique reads do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kb_extract_all_fastq = f\"{kb_extract_out_total}/all/1.fastq.gz\"\n",
    "aligned_reads_kb_extract = get_header_set_from_fastq(kb_extract_all_fastq)\n",
    "\n",
    "read_df['aligned_somewhere'] = read_df['read_header'].isin(aligned_reads_kb_extract)\n",
    "read_df['did_not_align_anywhere'] = ~read_df['aligned_somewhere']\n",
    "\n",
    "read_df['TP'] = (read_df['mutant_read'] & read_df['aligned_somewhere'])\n",
    "read_df['FP'] = (~read_df['mutant_read'] & read_df['aligned_somewhere'])\n",
    "read_df['FN'] = (read_df['mutant_read'] & ~read_df['aligned_somewhere'])\n",
    "read_df['TN'] = (~read_df['mutant_read'] & ~read_df['aligned_somewhere'])\n",
    "\n",
    "metric_dictionary_reads = calculate_metrics(read_df, header_name = \"read_header\", check_assertions = check_assertions, out = f\"{plot_output_folder}/reads_metrics_crude.txt\")\n",
    "draw_confusion_matrix(metric_dictionary_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_set = set(read_df.loc[read_df['mutant_read'], 'read_header'])\n",
    "positive_set = set(read_df.loc[read_df['aligned_somewhere'], 'read_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reads['TN'], mm = n_multimapped, out_path = f\"{plot_output_folder}/venn_diagram_read_crude.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_extract_all_fastq_opposite_mm = f\"{kb_extract_out_total_opposite_mm}/all/1.fastq.gz\"\n",
    "aligned_reads_kb_extract_opposite_mm = get_header_set_from_fastq(kb_extract_all_fastq_opposite_mm)\n",
    "\n",
    "multimapped_reads = aligned_reads_kb_extract.symmetric_difference(aligned_reads_kb_extract_opposite_mm)\n",
    "read_df['multimapped'] = read_df['read_header'].isin(multimapped_reads)\n",
    "print(f\"Multimapped reads ({n_multimapped}): {multimapped_reads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = check_for_read_kmer_in_mcrs(read_df, unique_mcrs_df, k, strand = strandedness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df_fn = read_df[read_df['FN']]\n",
    "\n",
    "# Step 1: Filter by read_contains_kmer_in_mcrs is True\n",
    "read_df_fn = read_df_fn[read_df_fn['read_contains_kmer_in_mcrs']]\n",
    "\n",
    "# Step 2: Filter by read_index between 10 and 140\n",
    "read_df_fn = read_df_fn[(read_df_fn['read_index'] > 10) & (read_df_fn['read_index'] < 140)]\n",
    "\n",
    "# Step 3: Filter by multimapped being False\n",
    "read_df_fn = read_df_fn[read_df_fn['multimapped'] == False]\n",
    "\n",
    "# Step 4: Join read_df with unique_mcrs_df on 'mcrs_header'\n",
    "merged_df = read_df_fn.merge(unique_mcrs_df[['mcrs_header', 'number_of_kmers_with_overlap_to_other_mcrs_items_in_mcrs_reference', 'dlist', 'mcrs_sequence_length']], on='mcrs_header', how='left')\n",
    "\n",
    "# Step 5: Filter by unique_mcrs_df conditions\n",
    "read_df_fn = merged_df[\n",
    "    (merged_df['number_of_kmers_with_overlap_to_other_mcrs_items_in_mcrs_reference'] == 0) &\n",
    "    (merged_df['dlist'] == \"none\") &\n",
    "    (merged_df['mcrs_sequence_length'] >= 2 * k - 1)\n",
    "]\n",
    "\n",
    "# Step 6: Drop any columns added during the merge that you don’t need in the final DataFrame\n",
    "unexplainable_fn_reads = read_df_fn[read_df.columns]  # Keeps only the original read_df columns\n",
    "\n",
    "print(\"Number of unexplainable FN reads: \", len(unexplainable_fn_reads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(kb_extract_out_total):\n",
    "    create_stratified_metric_bar_plot(read_df, 'mcrs_mutation_type', 'accuracy', overall_metric = metric_dictionary_reads['accuracy'], log_x_axis = False, display_numbers = True, out_path = f\"{plot_output_folder}/accuracy_vs_mcrs_mutation_type_read_perspective.png\")\n",
    "    #* add more here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sense of the kb extract output\n",
    "Update metrics now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_kb_extract_slow:\n",
    "    df_extract_combined = pd.DataFrame(columns=['read_header', 'mcrs_header_to_which_the_read_aligned'])\n",
    "\n",
    "    # add some code here to check where these map\n",
    "    for subdir in os.listdir(kb_extract_out_all_slow):\n",
    "        subdir_path = os.path.join(kb_extract_out_all_slow, subdir)\n",
    "        if os.path.isdir(subdir_path):\n",
    "            fastq_file = os.path.join(subdir_path, '1.fastq.gz')\n",
    "            if os.path.exists(fastq_file):\n",
    "                # Run get_header_set_from_fastq for the fastq file\n",
    "                aligned_reads_kb_extract = get_header_set_from_fastq(fastq_file)\n",
    "                df_temp = pd.DataFrame(aligned_reads_kb_extract, columns=['read_header'])\n",
    "                df_temp['mcrs_header_to_which_the_read_aligned'] = subdir  # Add subdirectory info\n",
    "                df_extract_combined = pd.concat([df_extract_combined, df_temp], ignore_index=True)  # Concatenate the new DataFrame with df_extract_combined\n",
    "\n",
    "    if not include_multimapped_reads:\n",
    "        # remove multimapped reads\n",
    "        df_extract_combined = df_extract_combined[~df_extract_combined['read_header'].isin(multimapped_reads)]\n",
    "    else:\n",
    "        # combines MCRSs for multimapped reads into a list - untested\n",
    "        df_extract_combined = df_extract_combined.groupby('read_header')['mcrs_header_to_which_the_read_aligned'].apply(list).reset_index()\n",
    "\n",
    "\n",
    "    read_df = read_df.merge(df_extract_combined, on='read_header', how='left')\n",
    "    read_df['aligned_to_correct_mcrs'] = (read_df['mcrs_header'] == read_df['mcrs_header_to_which_the_read_aligned'])\n",
    "\n",
    "    read_df.rename(columns={'TP': 'TP_crude', 'TN': 'TN_crude', 'FP': 'FP_crude', 'FN': 'FN_crude'}, inplace=True)\n",
    "\n",
    "    read_df['TP'] = (read_df['mutant_read'] & read_df['aligned_to_correct_mcrs'])\n",
    "    read_df['FP'] = (~read_df['mutant_read'] & read_df['aligned_to_correct_mcrs'])\n",
    "    read_df['FN'] = (read_df['mutant_read'] & ~read_df['aligned_to_correct_mcrs'])\n",
    "    read_df['TN'] = (~read_df['mutant_read'] & ~read_df['aligned_to_correct_mcrs'])\n",
    "\n",
    "    metric_dictionary_reads_crude = metric_dictionary_reads.copy()\n",
    "    metric_dictionary_reads = calculate_metrics(read_df, header_name = \"read_header\", check_assertions = check_assertions, out = f\"{plot_output_folder}/read_metrics.txt\")\n",
    "    draw_confusion_matrix(metric_dictionary_reads)\n",
    "\n",
    "    true_set = set(read_df.loc[read_df['mutant_read'], 'read_header'])\n",
    "    positive_set = set(read_df.loc[read_df['aligned_to_correct_mcrs'], 'read_header'])\n",
    "    create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reads['TN'], mm = n_multimapped, out_path = f\"{plot_output_folder}/venn_diagram_read.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective of reference items\n",
    "\n",
    "Reference analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['received_an_aligned_read'])\n",
    "unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['received_an_aligned_read'])\n",
    "unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['received_an_aligned_read'])\n",
    "unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['received_an_aligned_read'])\n",
    "\n",
    "metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = check_assertions, out = f\"{plot_output_folder}/reference_metrics_crude.txt\")\n",
    "draw_confusion_matrix(metric_dictionary_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['received_an_aligned_read'], 'mcrs_header'])\n",
    "create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{plot_output_folder}/venn_diagram_reference_crude.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unexplainable_references = 0\n",
    "for header in metric_dictionary_reference['FNs']:\n",
    "    print(f\"Header {header}\")\n",
    "    did_not_align_anywhere = (read_df[read_df['mcrs_header'] == header])['FN_crude'].all()\n",
    "    print(f\"All did not align anywhere for {header}: {did_not_align_anywhere}\")\n",
    "    did_not_align_to_correct_position = (read_df[read_df['mcrs_header'] == header])['FN'].all()\n",
    "    print(f\"All did not align to correct mcrs for {header}: {did_not_align_to_correct_position}\")\n",
    "    multimapped = (read_df[read_df['mcrs_header'] == header])['multimapped'].all()\n",
    "    print(f\"All multimapped for {header}: {multimapped}\")\n",
    "    if not did_not_align_anywhere and not did_not_align_to_correct_position and not multimapped:\n",
    "        unexplainable_references += 1\n",
    "\n",
    "if unexplainable_references > 0:\n",
    "    print(f\"Unexplainable references: {unexplainable_references}\")\n",
    "else:\n",
    "    print(\"All explainable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, out_path = f\"{plot_output_folder}/accuracy_vs_number_of_reads_mutant.png\")\n",
    "#* add more here\n",
    "\n",
    "#!!! create similar plots for y in {sensitivity, specificity}, and x in {number_of_reads_wt, tumor_purity} and determine cutoffs for which varseek is reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_read_df = read_df[read_df['aligned_somewhere'] == True]\n",
    "mcrs_counts = aligned_read_df.groupby('mcrs_header').size().reset_index(name='number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere')\n",
    "\n",
    "unique_mcrs_df = unique_mcrs_df.merge(mcrs_counts, on='mcrs_header', how='left')\n",
    "unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere'] = unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere'].fillna(0).astype(int)\n",
    "unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_did_not_align_anywhere'] = unique_mcrs_df['number_of_reads_mutant'] - unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere']\n",
    "\n",
    "mutant_mask = unique_mcrs_df['included_in_synthetic_reads_mutant'] == True\n",
    "wt_mask = unique_mcrs_df['included_in_synthetic_reads_wt'] == True\n",
    "\n",
    "# Perform the calculation only on the selected rows\n",
    "unique_mcrs_df.loc[mutant_mask, 'number_of_reads_belonging_to_the_mcrs_item_that_did_not_align_anywhere'] = (\n",
    "    unique_mcrs_df.loc[mutant_mask, 'number_of_reads_mutant'] - unique_mcrs_df.loc[mutant_mask, 'number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere']\n",
    ")\n",
    "\n",
    "unique_mcrs_df.loc[wt_mask, 'number_of_reads_belonging_to_the_mcrs_item_that_did_not_align_anywhere'] = (\n",
    "    unique_mcrs_df.loc[wt_mask, 'number_of_reads_wt'] - unique_mcrs_df.loc[wt_mask, 'number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere']\n",
    ")\n",
    "\n",
    "unique_mcrs_df['mutation_expression_prediction_error'] = unique_mcrs_df['number_of_reads_aligned_to_this_item'] - unique_mcrs_df['number_of_reads_mutant']  # positive means overpredicted, negative means underpredicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_kb_extract_slow:\n",
    "    # Step 1: Group by 'mcrs_header' and count 'aligned_to_correct_mcrs' (sum will count True as 1, False as 0)\n",
    "    aligned_counts = read_df.groupby('mcrs_header')['aligned_to_correct_mcrs'].sum().reset_index()\n",
    "\n",
    "    # Rename the column to something meaningful, like 'correct_alignment_count'\n",
    "    aligned_counts.rename(columns={'aligned_to_correct_mcrs': 'number_of_reads_belonging_to_this_mcrs_item_that_mapped_here_correctly'}, inplace=True)\n",
    "\n",
    "    # Step 2: Merge the counts with unique_mcrs_df on the 'mcrs_header' column\n",
    "    unique_mcrs_df = pd.merge(unique_mcrs_df, aligned_counts, on='mcrs_header', how='left')\n",
    "\n",
    "    # Fill NaN values with 0 in case some mcrs_header values in unique_mcrs_df do not appear in read_df\n",
    "    unique_mcrs_df['number_of_reads_belonging_to_this_mcrs_item_that_mapped_here_correctly'].fillna(0, inplace=True)\n",
    "\n",
    "    unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'] = unique_mcrs_df['number_of_reads_belonging_to_this_mcrs_item_that_mapped_here_correctly'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_kb_extract_slow:\n",
    "    # Step 1: Group by 'mcrs_header_to_which_the_read_aligned' and collect 'read_header' into lists\n",
    "    reads_mapped = read_df.groupby('mcrs_header_to_which_the_read_aligned')['read_header'].apply(list).reset_index()\n",
    "\n",
    "    # Rename the column to 'reads_mapped_to_this_reference_item' for clarity\n",
    "    reads_mapped.rename(columns={'read_header': 'reads_mapped_to_this_reference_item'}, inplace=True)\n",
    "\n",
    "    # Step 2: Merge the list of read headers with unique_mcrs_df on the 'mcrs_header' column\n",
    "    unique_mcrs_df = pd.merge(unique_mcrs_df, reads_mapped, left_on='mcrs_header', right_on='mcrs_header_to_which_the_read_aligned', how='left')\n",
    "    unique_mcrs_df.drop(columns='mcrs_header_to_which_the_read_aligned', inplace=True)\n",
    "\n",
    "    # Fill NaN values with empty lists in case there are no matching read headers for some mcrs_header values\n",
    "    unique_mcrs_df['reads_mapped_to_this_reference_item'] = unique_mcrs_df['reads_mapped_to_this_reference_item'].apply(lambda x: x if isinstance(x, list) else [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_kb_extract_slow:\n",
    "    unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere'] = unique_mcrs_df['number_of_reads_belonging_to_the_mcrs_item_that_aligned_somewhere'].astype(bool)\n",
    "\n",
    "    unique_mcrs_df.rename(columns={'TP': 'TP_crude', 'TN': 'TN_crude', 'FP': 'FP_crude', 'FN': 'FN_crude'}, inplace=True)\n",
    "\n",
    "    unique_mcrs_df['TP'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'])\n",
    "    unique_mcrs_df['FP'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'])\n",
    "    unique_mcrs_df['FN'] = (unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'])\n",
    "    unique_mcrs_df['TN'] = (~unique_mcrs_df['included_in_synthetic_reads_mutant'] & ~unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'])\n",
    "\n",
    "    metric_dictionary_reference = calculate_metrics(unique_mcrs_df, header_name = \"mcrs_header\", check_assertions = check_assertions, out = f\"{plot_output_folder}/reference_metrics.txt\")\n",
    "    draw_confusion_matrix(metric_dictionary_reference)\n",
    "\n",
    "    true_set = set(unique_mcrs_df.loc[unique_mcrs_df['included_in_synthetic_reads_mutant'], 'mcrs_header'])\n",
    "    positive_set = set(unique_mcrs_df.loc[unique_mcrs_df['received_an_aligned_read_from_one_of_its_corresponding_reads'], 'mcrs_header'])\n",
    "    create_venn_diagram(true_set, positive_set, TN = metric_dictionary_reference['TN'], out_path = f\"{plot_output_folder}/venn_diagram_reference.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_kb_extract_slow:\n",
    "    unique_mcrs_df['number_of_reads_belonging_to_this_mcrs_item_that_did_not_align_correctly'] = unique_mcrs_df['number_of_reads_mutant'] - unique_mcrs_df['number_of_reads_belonging_to_this_mcrs_item_that_mapped_here_correctly']\n",
    "    unique_mcrs_df['number_of_reads_aligned_to_this_mcrs_item_that_aligned_incorrectly'] = unique_mcrs_df['number_of_reads_aligned_to_this_item'] - unique_mcrs_df['number_of_reads_belonging_to_this_mcrs_item_that_mapped_here_correctly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histogram(unique_mcrs_df.loc[~unique_mcrs_df['TN']], 'mutation_expression_prediction_error', log_scale = False, out_path = f\"{plot_output_folder}/histogram_mutation_expression_prediction_error_linear_axis.png\")\n",
    "plot_histogram(unique_mcrs_df.loc[~unique_mcrs_df['TN']], 'mutation_expression_prediction_error', log_scale = True, out_path = f\"{plot_output_folder}/histogram_mutation_expression_prediction_error_log_axis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_dictionary_reference['mutation_expression_prediction_error_abs_mean'] = unique_mcrs_df.loc[~unique_mcrs_df['TN'], 'mutation_expression_prediction_error'].abs().mean()\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'number_of_reads_mutant', 'expression_error', overall_metric = metric_dictionary_reference['mutation_expression_prediction_error_abs_mean'], log_x_axis = False, out_path = f\"{plot_output_folder}/expression_error_vs_number_of_reads_mutant.png\")\n",
    "create_stratified_metric_bar_plot(unique_mcrs_df, 'distance_to_nearest_splice_junction', 'accuracy', overall_metric = metric_dictionary_reference['accuracy'], log_x_axis = False, bins = [-1, 0, 1, 5, 10, 50, 100, float('inf')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mcrs_df_out_path = f\"{synthetic_reads_parent}/unique_mcrs_df.csv\"\n",
    "unique_mcrs_df.to_csv(unique_mcrs_df_out_path, index=False)\n",
    "\n",
    "read_df_out_path = f\"{synthetic_reads_parent}/read_df.csv\"\n",
    "read_df.to_csv(read_df_out_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(read_df.columns)\n",
    "print(unique_mcrs_df.columns)\n",
    "print(mutation_metadata_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no_noise_read_metrics = \"\"\n",
    "# substitution_noise_read_metrics = \"\"\n",
    "# deletion_noise_read_metrics = \"\"\n",
    "# insertion_noise_read_metrics = \"\"\n",
    "# all_noise_read_metrics = \"\"\n",
    "# metric = \"accuracy\"\n",
    "\n",
    "\n",
    "\n",
    "# accuracy_dict = {}\n",
    "# accuracy_dict['No Noise'] = retrieve_value_from_metric_file(metric, no_noise_read_metrics)\n",
    "# accuracy_dict['Substitution Noise'] = retrieve_value_from_metric_file(metric, substitution_noise_read_metrics)\n",
    "# accuracy_dict['Deletion Noise'] = retrieve_value_from_metric_file(metric, deletion_noise_read_metrics)\n",
    "# accuracy_dict['Insertion Noise'] = retrieve_value_from_metric_file(metric, insertion_noise_read_metrics)\n",
    "# accuracy_dict['All Noise'] = retrieve_value_from_metric_file(metric, all_noise_read_metrics)\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "plot_basic_bar_plot_from_dict(accuracy_dict, y_axis=metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kvar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
